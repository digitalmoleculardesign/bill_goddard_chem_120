\chapter{Molecular Symmetry}

\section{Introduction}
In Chapter 2, we found that for a molecule with inversion symmetry, 
all eigenstates are either symmetric, $g$, or antisymmetric, $u$, 
under inversion $i \psi_g = + \psi_g$ and $i \psi_u = - \psi_u$.  
Such symmetry information allows general considerations of the states 
of molecules, and often greatly simplifies the theoretical, or 
experimental, analysis of a system.  The most powerful theorems about 
symmetry are systemized under the title of group theory.  For most 
considerations, in chemistry and physics, it is the one aspect of 
group theory known as the theory of group representations that is 
important.  For Chemistry 120, we will make some use of molecular 
symmetry and of group representations.  However, these fields are 
peripheral to our main subject matter.  Consequently, we will only 
summarize here those aspects to be used in this course.  More complete 
discussions and proofs of some theorems are included in the Appendices.

A good, simple reference for learning the basic ideas of group 
representations, and how to apply these ideas to molecular 
problems,$^1$ and other useful references$^2$ can be found, which is 
also an introduction, but with emphasis on the fundamentals$^3$ and 
which is a more rigorous, more complete treatment, including a number 
of advanced concepts.

\section{Basic Concepts of Groups}

\subsection{Symmetry Group}

The symmetry group for a Hamiltonian $H$ is the set of symmetry 
transformations $G$ such that every element $R$ of $G$ commutes with 
$H$, $RH = HR$.  Each such $R$ is referred to as a symmetry operation.

There are two types of symmetries that will be generally useful 
here.  First, permutation of the electrons or of equivalent nuclei, and 
second, spatial transformation, rotations, inversions, reflections, 
and translations, that result in merely permuting equivalent nuclei.  
In order to be more precise about these symmetries, we must consider 
the  specific forms of the wavefunctions and Hamiltonians to be solved.

\subsubsection{The Electronic and Nuclear Wavefunctions}

As discussed in Chapter 8, the Hamiltonian for a molecule has the form
\begin{equation}
H = T^e + T^n + V^{en} + V^{ee} + V^{nn},
\label{chap16-eqno1a}
\end{equation}
where
\begin{eqnarray}
T^e &=& \sum_{i=1}^N - {1 \over 2} \nabla^2_i\cr
T^n &=& \sum_{I=1}^Q - {1 \over 2M_I} \nabla^2_I\cr
V^{en} &=& \sum^Q_{I=1} \left( \sum^N_{i=1} - {Z_I \over r_I} 
\right)\cr
V^{ee} &=& \sum^N_{i>j=1} {1 \over r_{ij}}\cr
V^{nn} &=& \sum^Q_{I>J=1} {Z_IZ_J \over r_{IJ}}
\end{eqnarray}
and, $N$ and $Q$ are the number of electrons and nuclei, 
respectively.  The total wavefunction $\Psi(r_1 ... r_N, R_1 ... 
R_Q)$ is the eigenfunction of
\begin{equation}
H \Psi = E \Psi.
\label{chap16-eqno1b}
\end{equation}

As discussed in detail, in Chapter 7, we take the total wavefunction 
to have the form $\Psi = \Psi^{e \ell} \Psi^{nuclear}$
the Born-Oppenheimer approximation, where $\Psi^{nuclear}$ depends 
only on the $Q$ nuclear coordinates.  The electronic wavefunctions 
$\Psi^{e \ell}(r_1, r_2, ..., r_N)$ are eigenstates of $H^{e \ell}$
\begin{equation}
H^{e \ell} \Psi^{e \ell} = E^{e \ell} \Psi^{e \ell},
\label{chap16-eqno2a}
\end{equation}
where
\begin{equation}
H^{e \ell}  = T^e + V^{en} + V^{ee}
\label{chap16-eqno2b}
\end{equation}
is the electronic Hamiltonian and where it is understood that in (2) 
the $Q$ nuclei are all fixed.  Thus, $\Psi^{e \ell}$ depends 
parametrically upon the $Q$ nuclear coordinates, and $E^{e \ell}$ is a 
function of these nuclear coordinates.  The nuclear wavefunctions
$\Psi^{nuclear}(R_1, R_2 , ..., R_Q)$ are solutions of
\begin{equation}
H^{nuclear} \Psi^{nuclear} = E \Psi^{nuclear}
\label{chap16-eqno3a}
\end{equation}
where
\begin{equation}
N^{nuclear} = T^n + V^{nn} + E^{e \ell}
\label{chap16-eqno3b}
\end{equation}

In this chapter we will usually be interested in the electronic 
wavefunctions of (2).  However, some applications will be made to 
(3).  Applications to (1) will be independent of the Born-Oppenheimer 
approximation and hence, more exact.

\subsubsection{Types of Symmetries}

The terms $T^e$, $B^{en}$, and $V^{ee}$ of (1a) are invariant under 
any of the $N!$ possible permutations, renumberings, of the $H$ 
electrons. Consequently, these $N!$ permutations of electrons are 
contained in the symmetry groups of $H^{e \ell}$ and of $H$.

Simiarly, $H^{e \ell}$ and $H$ are invariant under an permutation of 
equivalent nuclei among each other.  Actually, $H^{e \ell}$ has a 
higher symmetry here since it is invariant under any permutation of 
nuclei having the same charge, whereas for $H$ the permutated nuclei 
must have the same charge and mass.

Both $H$ and $H^{e \ell}$ are invariant under any spatial 
transformation that preserves the lengths of all inter-particle 
coordinates.  The general transformations, satisfying this condition 
are:
\begin{enumerate}
\item rotations about some axis,
\item inversion through some point,
\item reflection through some place,
\item translation along some axis,
\end{enumerate}
and the various combination of the above operations.  The 
permutational and spatial symmetries are discussed separately in 
Section 16.2 and 16.3, respectively.  First, however, we develop some 
important concepts of symmetry groups.

\subsection{Basic Spatial Symmetry Operations}

Consider a square.  A counter-clockwise rotation of 90 degrees, which 
will be denoted as $C_4$ for cyclic, leaves the square in a 
configuration indistinguishable from the original,
\begin{equation}
% missing figure!
\end{equation}
We number the counters of the square to keep track of what we are 
doing.  If the numbers were actually printed on the square there would 
be no symmetry.  Hence, we call $C_4$ a symmetry operation, of the 
square.  Applying $C_4$ again
\begin{equation}
% missing figure!
\end{equation}
gives an equivalent configuration and hence, $C^2_4$ is also a 
symmetry operation.  Continuing in this way, we find that $C^n_4 = C_4 
C_4 \cdots C_4$, for any $n$, is a symmetry operation.  Of course, 
$C^4_4$ corresponds to a rotation through 360 degrees which is 
equivalent to no rotation whatsoever.  The operation of doing nothing, 
that is, the identity operation, is denoted by $e$, for einheit, 
meaning unit in German.  Thus, we have $C^4_4 = e$ and $C_4^{n-4} = 
C^n_4$.  

There are other symmetry operations for a square such as reflections in 
a plane, denoted by sigma, $\sigma$, German for spiegel, e.g.,
\begin{equation}
% missing figure!
\end{equation}
and inversion through a point, $i$, e.g.,
\begin{equation}
% missing figure!
\end{equation}
In general, we will use the following notation for symmetry
operations:
\begin{enumerate}
\item $C_n$, counter-clockwise rotation of $(2 \pi / n)$ 
radians about some axis of symmetry
\item $\sigma$, reflection in some plane of symmetry.
\item $i$, inversion through some point or center of symmetry.
\item $S_n$, rotary reflection, rotation $C_n$ followed by a 
reflection, $\sigma_h$, in a plane perpendicular to the rotation 
axis $S_n \equiv \sigma_h C_n$.
\end{enumerate}
All of the above operations are referred to as point operations since 
they leave invariant at least one point in space.  There are a number 
of other symmetry transformations involving translation of the system 
along some axis followed, perhaps, by one or more of the above point 
operations.  Although some symmetries are of particular importance in 
discussing solids, we will ignore them here.

\subsection{The Properties of a Group}

It is clear that given two symmetry operations, ${\hat{R}}_1$ and 
${\hat{R}}_2$ for some object, the produce ${\hat{R}}_1{\hat{R}}_2$, 
denoting the application of first ${\hat R}_2$ and then ${\hat R}_1$, 
is also a symmetry operation.  For example, rotating ethylene 180 
degrees about the CC axis and then reflecting in the perpendicular 
plane bisecting the CC bond, leaves the molecule in an equivalent 
configuration
\vskip 1.25truein
\noindent
Consequently, we see that the set of all symmetry operations for any 
object is closed under multiplication.  That is, letting $G$ denote 
the set of all symmetry operations, if $R_1$ is a member of $G$, 
denoted as $R_1\epsilon G$ which is read as $R_1$, is an  element of 
$G$, and $R_2\epsilon G$, then $R_1R_2 \epsilon G$ and $R_2 R_1 
\epsilon G$.

It is also clear that the multiplication is associative, i.e. for 
$R_1$, $R_2$, $R_3 \epsilon G$, then
\begin{equation}
\left( R_1 R_2 \right) R_3 = R_1 ( R_2 R_3 ).
\label{chap16-eqno4}
\end{equation}
In our discussion, the $R_i$ are considered operations.  Thus, as 
equation such as (4) is interpreted as saying that $(R_1R_2)R_3$ 
operating on an object, leads to a result equivalent ot that obtained 
by $R_1(R_2R_3)$ operating on our object.

The identify operator, $e$, is always a member of $G$.  Since $e$ does 
nothing, we see that $Re = eR = R$.  That is, $e$ commutes with all 
elements of the group.

If $S$ and $R$ have the property that $SR = e$, we refer to $S$ as 
the inverse of $R$, and denote it as $S = R^{-1}$.  It is easy to see 
that if $R$ is a symmetry operation, then $R^{-1}$ is also a 
symmetry operation.  That is, $R \epsilon G$ implies that there is also 
another element, $R^{-1}\epsilon G$, such that $RR^{-1} = R^{-1}R=e$. 

These properties of $G$, the se of symmetry operations, correspond to 
the properties of a group, generally defined as follows.

\subsubsection{Definition of a Group}

A group, $G$, is a set of elements $\{R_i\}$ with a specified law of 
multiplication satisfying the following properties.
\begin{enumerate}
\item There exists an element $e \epsilon H$, called the 
identity, such that $eT = Re = R$ for all $R\epsilon G$.
\item For every element $R \epsilon G$, there exists an element 
$R^{-1}\epsilon G$, called the inverse of $R$, such that $RR^{-1} = 
R^{-1}R=e$.
\item The group is closed under multiplication, closure, i.e., 
if $R_1 \epsilon G$ and $R_2 \epsilon G$, then $R_1R_2 \epsilon G$.
\item The group multiplication is associative, $(R_1R_2)R_3 = 
R_1(R_2R_3)$.
\end{enumerate}

The number of elements, $g$, in the group, $G = \{e, R_2, \cdots, 
R_g\}$, is called the order of the group.

The above properties lead to severe restrictions upon the permitted 
multiplication laws, and indeed for groups of finite order there are 
only a finite number of possible groups, elements or operations.  Note, 
in particular, that the definition of a group does not impart to the 
$R_i$ any significance beyond the multiplication law.  Thus, the $R_i$ 
need not correspond to operations upon some sort of object.

Group theory is the study of the properties of groups. This theory has 
lead to a number of powerful theorems that allow classification of 
groups into different types, and provide an analysis of the forms for 
various types of groups.  We will be interested only in groups whose 
elements lead to transformations upon some set of objects.  This 
simplifies the group theory.  In addition, as described in Section 
16.4, we will be interested mainly in the special part of group 
theory known as the Theory of Group Representations.  A group can be of 
finite order, as in the case of a square, or of infinite order as 
in the case of a sphere.  An example of an important infinite group is 
the group of all rotations, about some point, in three dimensions, 
denoted as $SO(3)$.

Note that the law of multiplication need not be communitative, that 
is $R_1R_1 \not= R_2R_1$ in general.  For example,
\begin{equation}
% missing figure!
\end{equation}
and hence, $C_4 \sigma \not= \sigma C_4$.  If $R_1R_2 = R_2R_1$, we 
say that $R_1$ and $R_2$ commute.  If all elements of a group commute 
with each other, the group is referred to as an Abelian group.

Given a group $G$, we can often find a subset of the elements of $G$, 
such that this subset $G^{\prime}$ is also a group.  Such a subset is 
called a subgroup.  For example, given any group whatsoever, the 
subset $G^{\prime}=\{e\}$ is a subgroup.  A less trivial example is 
the set of all rotation about some axis is a subgroup of the group of 
all three-dimensional rotations.

Given some set of elements $S = \{R_1,R_2,\cdots ,R_3\}$ and a law of 
multiplying them, we can form a group $G$ by taking all possible 
products, any number of terms of the elements of $S$ and collecting all 
the elements so obtained into $G$.  A set of elements $S$ leading in 
this way to a group $G$, are referred to as the generators of $G$.  
For example, starting with $S = \{C_4\}$, we obtain the group $G = 
\{e,C_4,C^2_4,C^3_4\}$.  Similarly, starting with $S = \{C_2,C_3\}$ 
where $C_3^{-1}=C_2C_3C_2$, i.e., $C_2$ and $C_3$ are at right 
angles, leads to the group $G = \{e,C_3,C_3^{-1},C_2,C_2C_3, C_3C_2\}$.

\subsection{Classes}

We will find it convenient to partition each group into mutually 
exclusive sets of elements called classes, such that the elements of 
a class are closely related, conjugate, to each other.

\subsubsection{Conjugate Transformations}

First, we define conjugate.  Two elements $S$ and $T$ of a group $G$ 
are said to be conjugate if, and only if, there exists some element 
$R$ of the same group $G$, such that
\begin{equation}
S = RTR^{-1}.
\label{chap16-eqno5}
\end{equation}

Before proceeding we need to examine the reason for the special form 
of (5). Consider that
\begin{enumerate}
\item $T$ is a transformation taking any vector $v$ of some 
space $V$ into some vector $v^{\prime}$ of the space $V^{\prime}$, 
where $v^{\prime} = TV$, and that
\item $R$ transforms the vectors of the space $V$ into the 
space $W$, and the vectors of space $V^{\prime}$ into those of 
$W^{\prime}$, $w = Rv$ and $w^{\prime}=Rv^{\prime}$.  
\end{enumerate}
Then, (5) tells us that $S$ transforms the vectors of $W$ into 
$W^{\prime}$ in the same way that $T$ transforms the vectors of $V$ 
into $V^{\prime}$,
\begin{equation}
Sw=RTR^{-1}w=RT(R^{-1}w)=RTv=R(Tv)=Rv^{\prime}=w^{\prime},
\end{equation}
that is, $w^{\prime}=Sw$.  Schematically, we can visualize the process
in terms of the following diagram, Figure \ref{chap16-fig1}.


\begin{figure}
% missing figure!
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig1}
\end{figure}

The problem we pose here is, we know the effect of $T$ upon $V$, and we 
want to determine the effect of $S$ upon $W$, where $W$ is related to 
$V$ by the known relationship $R$.  Thus, we apply $R^{-1}$ to 
express $W$ in terms of $V$.  Now we can apply $T$ obtaining 
$V^{\prime}$ and then $R$ to obtain $W^{\prime}$.  The result, 
$RTR^{-1}$ leads from $W$ to $W^{\prime}$ and hence, is equivalent to 
$S$, $S = RTR^{-1}$.  As a result, such a relationship is referred to 
as a similarity transformation.  In a sense, we can consider (5) as the 
transformation of operator $T$ into operator $S$.  We write this as
\begin{equation}
R(T) = RTR^{-1} = S,
\label{chap16-eqno6}
\end{equation}
which is not to be confused with $RT=S$.

In this chapter, we will be concerned with the case in which the 
space $V$ is invariant under $G$; that is, any operation of $G$ just 
transforms the vectors of $V$ among themselves.  Thus, the spaces 
$V,V^{\prime},W$, and $W^{\prime}$ above, are all identical.  Since 
$R$ merely recombines the vectors of $V$, we can consider the 
transformation $R$ as a coordinate or basis transformation.  In this 
case, we see that transformation $T$ is similar to transformation $S$, 
differing only in the choice of coordinate system.  This view of (5) is 
valuable in analyzing for the conjugate elements of groups since we 
need only look for elements $R$ of the groups that transform the 
coordinate system for $T$ into an equivalent coordinate system for $S$. 
This will become clear in the examples.

\subsubsection{Examples}

Consider first, the group of all possible proper rotations, i.e., no 
inversions or reflections, in three dimensions, this group is denoted 
as $SO(3)$.  Any rotation can be represented by the $3 \times 3$ 
matrix $M$, corresponding to the associated transformation of the 
$x$, $y$, and $z$ axes.  These matrices are orthogonal, i.e., 
$M^{-1} = {\tilde{M}}$, and multiply in exactly the same way as do 
the rotations.  For proper rotations, they have $\det M = +1$, and 
for improper rotations $\det M = -1$.  The set of all orthogonal 
matrices, $\det M = \pm 1$, is denoted as $O(3)$ while the subset 
having $\det M = +1$ is denoted as $SO(3)$, $S$ for special.

\begin{figure}
% missing figure
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig2}
\end{figure}

If $R_{1,\varphi}$ is a rotation through angle $\varphi$, about axis
2, then $R_{1,\varphi}$ is transformed into $R_{2,\varphi}$ by the
rotation $R_{3,\varphi}$, where axis 3 is perpendicular to axis 1 and
2, and $\theta$ is the angle between axis 1 and 2.  Since positive
angles are counter-clockwise, axis 3 is up, out of the plane in Figure
\ref{chap16-fig2}.  That is,
\begin{equation}
R_{2,\varphi} = R_{3,\theta}(R_{1,\varphi}) = 
R_{3,\theta}R_{1,\varphi}R^{-1}_{3,\theta} = 
R_{3,\theta}R_{1,\varphi}R_{3,-\theta}
\label{chap16-eqno7}
\end{equation}
Thus, all rotations through the same angle $\varphi$ are conjugate.  A 
special case of the above relation is $\theta = 180$ degrees.  In this 
case, $R_{2,\varphi} =- R_{1,-\varphi}$, and hence, rotations 
$R_{1,\varphi}$ and $R_{1,-\varphi}$ in opposite directions about the 
same axis are conjugate.  On the other hand, if $\varphi^{\prime} 
\not= \pm \varphi$, there is not transformation converting $R_{1, 
\varphi}$ into $R_{2,\varphi^{\prime}}$, and hence, only rotations 
through the same angle $|\varphi|$ are conjugate.

\begin{figure}
% missing figure
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig3}
\end{figure}

Consider next, the group $O(3)$ consisting of all proper rotations
plus the inverison and all relfections.  Given any two reflections
$\sigma_1$ and $\sigma_2$ intersecting at an angle $\theta$, we can
transform $\sigma_1$ and $\sigma_2$ with the rotation $R_{3,\theta}$
where 3 is the line of intersection of two planes.  That is, $\sigma =
R_{3,\theta}(\sigma_1) = R_{3,\theta} \sigma_1 R_{3,-\theta}$.  Thus,
all reflections of $(3)$ are conjugate, but they are not conjugate
with any other type of transformation.  The inversion $i$ is
independent of the coordinate system and hence, is conjugate to no
other transformation.  Defining the rotary reflection
$S_{2,\varphi}=\sigma_2R_{2,\varphi}$ where $\sigma_2$ is the
reflection in the plane perpendicular to axis 2, we obtain direction
from (7) that $S_{2,\varphi} = R_{3,\theta}(S_{1,\varphi}) =
R_{3,\theta}S_{1,\varphi}R_{3,-\theta}$.  Thus, all rotary reflections
through the same angle $\pm \varphi$ are conjugate.

Now we consider what happens with a subgroup of the above rotation 
groups.  We will find that elements which were conjuate for the full 
rotation group may no longer be conjugate.  This occurs when the 
transformation $R$ converting $S$ into $T$, (6) is not present in the 
subgroup.

\begin{figure}
% missing figure
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig4}
\end{figure}

As an example, consider the group of symmetry operations for a square. 
Included are five reflections.  One $\sigma_h$ with the symmetry plane 
containing the square, and four  $\sigma_v , 
\sigma_v^{\prime} , \sigma_d , \sigma_d^{\prime}$, with their symmetric 
planes perpendicular to the square.
The question is which of these reflections are conjugate to each 
other?  To find out we look for an operation $R$, that would transform 
the coordinate system for one $T$, into that of the coordinate system 
for another $S$. Since $C_2$ takes the coordinate system of 
$\sigma_v$ into that for $\sigma_v^{\prime}$, we see that 
$\sigma_v^{\prime} = C_4 (\sigma_v ) = C_4 \sigma_v C_4^{-1}$ and 
hence, $\sigma_v$ and $\sigma_v^{\prime}$ are conjugate.  
Alternatively, we see that $\sigma_d$ converts $\sigma_v$ to 
$\sigma^{\prime}_v$, again indicating that $\sigma_v$ and 
$\sigma_v^{\prime}$ are conjugate.  Similarly, $C_4$ or $\sigma_v$ 
takes the coordinate system of $\sigma_d$ into that of 
$\sigma_d^{\prime}$.  Hence, $\sigma_d^{\prime} = C_4(\sigma_d) = C_4 
\sigma_d C_4^{-1}$ and, $\sigma_d$ and $\sigma_d^{\prime}$ are 
conjugate.  The question now is whether $\sigma_v$ and $\sigma_d$ are 
conjugate.  Operations connecting them are $C_8$, $\sigma_d = C_8 
(\sigma_v) = C_8 \sigma_v C_8^{-1}$ or $S_8$, $\sigma_d = S_8 ( 
\sigma_v)=S_8 \sigma_v S_8^{-1}$ but, $C_8$ and $S_8$ are not members 
of the group.  Indeed, there is no element of the group, of the 
square, that converts $\sigma_v$ into $\sigma_d$, and hence, these 
reflections are not conjugate.  On the other hand, for the group of 
the regular octogon, $C_8$ is contained in the group and $\sigma_v$ 
or $\sigma_d$ would be conjugate.  In order for $\sigma_h$ to be 
conjugate to $\sigma_v$ or $\sigma_d$, there would have to be a $C_4$ 
axis in the plane of the square, but there is not.  Or some other 
transformation, e.g., $S_4$, that would rotate the $\sigma_h$ plane 
by 90 degrees to a perpendicular position. Thus, $\sigma_h$ is not 
conjugate to any of the other reflections.

Now, suppose that symmetry of the square is reduced by painting the
left-half white and the right-half black. The group of symmetry
operations no longer includes the $C_4$ rotations and $\sigma_d$
reflections.  As a result, $\sigma_v$ and $\sigma^{\prime}_v$ are no
longer conjugate since the operations relating them, $C_4$ and
$\sigma_d$, are no longer in the group.

\subsubsection{Classes}

It is easy to show that conjugation is an equivalence relationship so 
that the elements of a group can be partitioned into mutually 
exclusive sets, the members of which are conjugate to each other.

Conjugate group elements ahve the following important properties:

\begin{enumerate}
\item Reflexive: any $R \epsilon G$ is conjugate to itself; the 
proof is $eRe^{-1}=R$.
\item Symmetric: if $S \epsilon G$ is conjugate to $T \epsilon 
G$, then $T$ is conjugate to $S$.  The proof is $RTR^{-1}=S$, thus, 
$TR^{-1}=R^{-1}S$, hence, $T=R^{-1}SR$.
\item Transitive: if $U \epsilon G$ is conjugate to $T \epsilon 
G$, and $T$ is conjugate to $S \epsilon G$, then $U$ is conjugate to 
$S$.  The proof is $T = RSR^{-1}$ and $U = PTP^{-1}$, we find that 
$U = P(RSR^{-1})P^{-1}=(PR)SR^{-1}P^{-1}=(PR)S(PR)^{-1}$.
\end{enumerate}
A relation satisfying these three conditions is an equivalence 
relation, implying that we can partition the elements of a group into 
a set of mutually conjugate elements.

\section{The Permutation Group}

Next we will discuss permutations.  Consider a green tray with four
compartments and four identical marbles.  We can rearrange the
marbles, allowing only one in each compartment, in $4!$ different
ways.  One of the arrangements can be written as
\begin{equation}
\pmatrix{1 & 2 & 3 & 4\cr
4 & 3 & 1 & 2\cr}
\label{chap16-eqno8}
\end{equation}
which means that the marble in compartment 1 goes to compartment 4, 
the marble in compartment 2 goes to compartment 3, etc.  On the other 
hand, we can number the marbles and presume that the compartments are 
all equivalent, perhaps arranges in a square.  In this case, we 
interpret (8) as marble 1 is replaced by marble 4, marble 2 is replaced 
by marble 3, etc.  We will usually use the latter convention.  The 
order of the columns in (8) is irrelevant, thus (8) is the same as
\begin{equation}
\pmatrix{1 & 4 & 2 & 3\cr
4 & 2 & 3 & 1\cr}.
\end{equation}
This can be written more economically, as $( 1 ~ 4 ~ 2 ~ 3 )$,
which says that 1 is replaced by 4 is replaced by 2 is replaced by 3 is 
replaced by 1.  This is called the cycle notation.   For example, the 
permutation
\begin{equation}
\pmatrix{1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\cr
2 & 5 & 12 & 8 & 1 & 6 & 9 & 3 & 11 & 10 & 4 & 7\cr}
\end{equation}
can be written as
\begin{equation}
(1 ~ 2 ~ 5) (3, ~ 12, ~ 7, ~ 9, ~ 11, ~ 4, ~ 8)(6)(10)
\end{equation}
the cycles of length one, e.g., (6) and (10) above, are usually 
omitted.  Note that in cycle notation, each element appears in only one 
cycle.  The starting element for a cycle is not unique, thus,
$(1 ~ 2 ~ 5) = (2 ~ 5 ~ 1) = (5 ~ 1 ~ 2)$,
however, we will generally start a cycle with the smallest element.

We must be careful about our notation in order that the permutations 
mutliply properly.  Our convention is that $\tau_3 = \tau_2 \tau_1$ 
says to first operate with $\tau_1$ and then with $\tau_2$.  Thus, if
\begin{equation}
\tau_1 = \pmatrix{1 & 2 & 3\cr
1 & 3 & 2\cr}
\end{equation}
and
\begin{equation}
\tau_2 = \pmatrix{1 & 2 & 3\cr
2 & 1 & 3\cr},
\end{equation}
then
\begin{equation}
\tau_3 = 
\pmatrix{1 & 2 & 3\cr
& & &\downarrow\cr
2 & 1 & 3\cr}
\pmatrix{1 & 2 & & 3\cr
& & \downarrow &\cr
1 & 3 & & 2\cr} =
\pmatrix{1 & 2 & 3\cr
2 & 3 & 1\cr}
\end{equation}
or equivalently, $(1 ~ 2) (2 ~ 3) = (1 ~ 2 ~ 3)$.  
If the object are numbered, this is consistent with object 1 is 
replaced by 2, etc., since
\begin{equation}
% missing figure!
\end{equation}
and the net result is
\begin{equation}
% missing figure!
\end{equation}
or 1 is replaced by 2, etc.  Occasionally it is convenient to number 
the position rather than the objects.  In order for the above 
convention on multiplication of permutations to be consistent,
we must interpret (1~2~3) as the object in 1 goes to 2, etc., 
since
\begin{equation}
% missing figure!
\end{equation}
and thus, the net result is
\begin{equation}
% missing figure!
\end{equation}
or the object in 1 goes to 2, etc.  Clearly, these conventions are 
just inverses of each other.

There are $N!$ permutations of $N$ objects, forming a group of order 
$N!$ called the symmetric group on $N$ objects, $S_N$.  The identity is
$e \equiv (1) (2) \cdots (N)$.
The inverse of a cycle is the same cycle but in the opposite order
$(ij \cdots k)^{-1}=(k \cdots ji)$.  Thus, it is easy to determine 
the inverses of a permutation.

An interchange of two objects, e.g., (35), is called the 
transposition.  A cycle can always be decomposed into a product of 
transpositions, e.g., $(1~2~7~5) = (1~2)(2~7)(7~5)$
and hence, ever 
permutation can be written as a product of transpositions.  This 
decomposition into transpositions is not unique, e.g., 
(1~2~5) = (1~2)(2~5) = (1~3)(1~3)(1~2)(2~5) = (1~3)(1~2)(2~3)(2~5), 
etc.  However, if a permutation can be written as an even number of 
transpositions, then every such decomposition contains an even number 
of transpositions, similarly for odd cases.  Such a permutation is 
called an even permutation, and those with odd number of transpositions 
are called odd permutations.

Any transposition can be decomposed into terms of the $(N-1)$ 
elementary transpositions
\begin{equation}
(1~2) , (2~3), \cdots , (N-1,N).
\label{chap16-eqno9}
\end{equation}
For example,
\begin{equation}
(2~7) = (2~3)(3~4)(4~5)(5~6)(6~7)(5~6)(4~5)(3~4)(2~3) = 
(2~3~4~5~6)(6~7)(6~5~4~3~2).
\end{equation}
Since every element of $S_N$ can be written in terms of 
transpositions, we see that the set of elementary transpositions (9) 
are generators for $S_N$.

The conjugate relationship $R(T)=RTR^{-1}=S$ works particularly easily 
with permutations.  We recall that $R$ corresponds to a basis 
transformation.  For permutations, this means that $R$ permutes the 
elements within $T$.  For example, let $T=(1~6)(2~5~9~7)(3~8)$ and 
$R = (1~5~8)$, then
\begin{eqnarray}
T &=& (1~6)(2~5~9~7)(3~8)\cr
R &\rightarrow &\cr
S &=& (5~6)(2~8~9~7)(3~1)
\end{eqnarray}
A more laborious way of calculating this is multiplying out,
$RTR^{-1} = (1~5~8)(1~6)(2~5~9~7)(3~8)(8~5~1)$,
which leads, of course, to the same result.  Thus, we see that two 
permutations of $S_N$ are in the same class if, and only if, they 
have the same cycle structure.  Some examples are:
\begin{enumerate}
\item $S_2$.  This group $S_2 = \{e,(1~2)\}$ is too trivial to 
discuss.

\item $S_3$.  Partitioning into classes, $S_3$ is 
$S_3:\{e\},\{(1~2),(2~3),(1~3)\},\{(1~2~3),(1~3~2)\}$.   Since 
(1~3) = (1~2)(2~3)(1~2),(1~2~3) = (1~2)(2~3), and (1~3~2) = 
(2~3)(1~2), we see that (1~2) and (2~3) are genertors for $S_3$.

\item $S_4$.  The $4! = 24$ elements of $S_4$ are, grouped into 
classes:
  \begin{enumerate}
    \item $\{e\}$
    \item $\{(1~2),(1~3),(1~4),(2~3),(2~4),(3~4)\}$
    \item $\{$(1 2 3), (1 3 2), (1 2 4), (1 4 2), (1 3 4), (1 4 3), 
      (2 3 4), (2 4 3)$\}$
    \item $\{$(1 2) (3 4), (1 3) (2 4), (1 4) (2 3)$\}$
    \item $\{$(1 2 3 4), (1 2 4 3), (1 3 2 4), (1 3 4 2), (1 4 2 
3), (1 4 3 2)$\}$.
  \end{enumerate}
\end{enumerate}

All these operations can be written in terms of (1~2), (2~3), and (3~4).

\subsection{Spatial Transformations}

Many spatial symmetry groups are conveniently treated in terms of 
$S_N$.  Some examples are:

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig5}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig6}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig7}
\end{figure}

\begin{enumerate}
\item $D_3$.  The group of the equilateral triangle, proper 
rotation only, is $D_3$.  Numbering the vertices as in Figure
\ref{chap16-fig5}
we see that
  \begin{enumerate}
    \item (1 2 3) corresponds to $C_3$
    \item (1 3 2) corrresponds to $C_3^{-1}$
    \item (2 3) corresponds to the $C_2$ through 1
    \item (1 3) corresponds to the $C_2$ through 2
    \item (1 2) corresponds to the $C_2$ through 3.
  \end{enumerate}
\item $T_d$.  The group of the tetrahedron is $T_d$.  Numbering the
four vertices 1, 2, 3, 4, as in Figure \ref{chap16-fig6}, we find that
  \begin{enumerate}
    \item (1 2) corresponds to a reflection of $\sigma$
    \item (1 2 3 4) corresponds to a rotary reflection $S_4$
    \item (1 2 3) corresponds to a three-fold rotation $C_3$
    \item (1 2)(3 4) corresponds to a two-fold rotation $C_2$.
  \end{enumerate}

\item $O_h$.  The group of the cube is $O_h$.

Hence, typical elements are
  \begin{enumerate}
    \item $C_3 =$ (1 6 3)(4 5 7)
    \item $C_4$ = (1 2 3 4)(5 6 7 8)
    \item $C^{\prime}_2$ = (2 6)(1 7)(3 5)(4 8)
    \item $\sigma_d$ = (1 3)(5 7)
    \item $C_c = C^2_4$ = (1 3)(2 4)(5 7)(6 8)
  \end{enumerate}
\end{enumerate}

Note, all elements of the same class have the same cycle 
structure but not vice versa.  Thus, $C_2$ and $C^{\prime}_2$ are not 
the same class.

\section{Molecular Symmetry Groups}

In this section, we will discuss some of the simple symmetry groups 
of molecules.  Since the molecule is finite in extent, the symmetry 
operation cannot lead to a net displacement of the molecule.  Hence, 
at least one point in space, the `center' of the molecule, must be 
invariant under the symmetry operation.  As a result, these groups 
are called the point groups.

\subsection{Stereographic Projections}

Following the effects of successive symmetry operations on an actual 
molecule, is often a nontrivial process.  It is frequently convenient 
to use stereographic projections in place of the molecules.  Imagine 
that the body we are rotating has a little tick mark on it, in an 
unsymmetrical location and draw a unit vector from the origin toward 
the tick mark, such as
\begin{equation}
% missing figure!
\end{equation}
By defining a reference plane, and projecting the unit vector onto
this plane, we can follow the movements of the three-dimensional
object by the two-dimensional projection, e.g., the $C_4$ rotation
about the axis perpendicular to the paper, $z$, takes the point in
Figure \ref{chap16-fig8}(a) to the point in Figure
\ref{chap16-fig8}(b).  Similarly, a $C_2$ rotation about the $x$ axis
takes Figure \ref{chap16-fig8}(a) into Figure \ref{chap16-fig8}(c).
Note that a point above the plane is denoted by a period, while a
point below the plane is denoted by a small circle.  Such points are
often denoted by the symmetry operation involved, as in Figure
\ref{chap16-fig8}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig8}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig9}
\end{figure}

As an example of using stereographic projections, consider in Figure
\ref{chap16-fig9} the produces of $C_4$ and $\sigma$, where the
$\sigma$ plane contains the $C_4$ axis.  We see that $\sigma C_4 \not=
C_4\sigma$ that is, $\sigma$ and $C_4$ do not commute.  In Figure
\ref{chap16-fig9}, the $C_4$ axis is perpendicular to the paper, the
$\sigma$ plane is perpendicular to the paper and has cut the plane of
the paper in a vertical line.

As another example, we will find the operation $R$ such that $\sigma
C_4 = R \sigma$; that is $R = \sigma C_4 \sigma^{-1} = \sigma C_4
\sigma$.  From Figure \ref{chap16-fig10}, we find that $R = C_4^{-1}$,
that is $C^{-1}_4 = \sigma C_4 \sigma$ or $\sigma C-4 = C_4^{-1}
\sigma$.  From Figure \ref{chap16-fig10}, $C_4$ and $\sigma$ are as in
Figure \ref{chap16-fig3}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig10}
\end{figure}

Another use of stereographic projects is to provide a graphic way of
generating and indicating the elements of a group.  For example,
starting with $C_4$ and applying it consecutively, we obtain the group
$C_4$ in Figure \ref{chap16-fig11}(a).  Starting with $\sigma$ and
applying it consecutively, we obtain the group $C_s$ in Figure
\ref{chap16-fig11}(b).  Starting with both $C_4$ and $\sigma$, and
combining them in all ways, we obtain $C_{4v}$ as in Figure
\ref{chap16-fig11}(c) and Figure \ref{chap16-fig11}(d).  Whether we
start with $C_4$ and then include $\sigma$, as in Figure
\ref{chap16-fig11}(c), or start with $C_s$ and then include $C_4$, as
in Figure \ref{chap16-fig11}(d), of course we end up with the same
group, $C_{4v}$.  Note that either Figure \ref{chap16-fig11}(c) or
Figure \ref{chap16-fig11}(d) shows that that $C_4$ and $\sigma$ are
the generators of $C_{4v}$, i.e., all elements of $C_{4v}$ can be
expressed in terms of combinations of $C_4$ and $\sigma$.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig11}
\end{figure}

Still, another use of sterographic projections is to determine the
types of symmetries resulting from combinations of symmetry elements.
From Figure \ref{chap16-fig11}(d), we see that the pattern of dots is
invariant under reflections, $\sigma^{\prime}$, $\sigma^{\prime
\prime}$, and $\sigma^{\prime \prime \prime}$.  From Figure
\ref{chap16-fig11}(b), we see that all operations of $C_{4v}$ are
either rotations or reflections.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig12}
\end{figure}

There is a set of conventions used for indicating the symmetry planes 
and axes of a sterogram, such as shown in Figure \ref{chap16-fig12}.
The principal axis, highest $n$, is taken perpendicular to the plane, 
and the symbols
\begin{equation}
{~~~~~~~~ \atop n=2} {~~~~~~~~ \atop 3} {\vrule height4pt width8pt 
depth4pt \atop 4} {~~~~~~~~ \atop 6}
\label{chap16-eqno10}
\end{equation}
indicate $n$-fold axis.  Improper rotations, $S_n$, are denoted 
similarly except that the symbols are empty, e.g.,
\begin{equation}
{~~~~~~~~ \atop n=4} {~~~~~~~ \atop 6}
\label{chap16-eqno11}
\end{equation}

A vertical mirror plane, $\sigma_v$, that is, a reflection plane
perpendicular to the paper, is indicated by a heavy solid line, as in
Figure \ref{chap16-fig12}.  A horizontal mirror plane, $\sigma_h$,
that is, a reflection plane in the plane of the paper, is indicated by
a solid circle for the stereogram.  A rotation axis in the plane of
the paper is indicated by a dashed line with the symbol from (10) or
(11) on the perimeter of the stereogram.  A solid line will appear if
a vertical mirror plane passes through the axis.  For example, Figure
\ref{chap16-fig13} indicates a $C_2$ in the plane.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig13}
\end{figure}

\subsection{The C$_n$ Groups}

Starting with $C_n$, we obtain other symmetry operations by repeated 
products $C^2_n = C_nC_n$ and $C^3_n = C_nC_n^2$, etc.  The products 
of two rotations, is given by
\begin{eqnarray}
C^p_n C^q_n &=& C^{p+q}_n\cr
C^q_n C^p_n &=& C_n^{p+q}
\label{chap16-eqno12a}
\end{eqnarray}
and hence, any two rotations, about the same axis, commute.  Since 
$C_n$ is a rotation through $2 \pi /n$ radians, then
\begin{equation}
C^n_n = e
\label{chap16-eqno12b}
\end{equation}
and hence, $C^{n+p}_n = C^p_n$, etc.  From (12), we see that 
$C^{n-p}_nC^p_n = e$ and hence, $C^{n-p}_n = (C^p_n)^{-1}$, that 
is, $(C^p_n)^{-1}=C^{-p}_n$.  The group generated by $C_n$ is denoted 
as {\bf C}$_n$.  It is Abelian and contains $n$ symmetry operations.  Each 
element is in a class by itself.

\subsection{The C$_{nv}$ Groups}

In Section 16.2, we found that addition of a reflection plane 
containing the rotation axis is called a vertical reflection, and is 
denoted as $\sigma_v$.

If $n = 1$, the group {\bf C}$_{1v}$ contains just two elements, {\bf 
C}$_s\{e,\sigma\}$.  This group is denoted as {\bf C}$_s$, $s$ for 
Spiegel, German for mirror.  A prototype molecule is
\begin{equation}
% missing figure!
\end{equation}
The standard convention for a planar molecule of {\bf C}$_s$ symmetry 
is to take the $x$ axis perpendicular to the plane.

We can do the same thing for any $n$, leading to a group of order 
$2n$ and, denoted as {\bf C}$_{nv}$.  The operations of {\bf C}$_{nv}$ 
are just $\{e, C_n , C^2_n, \cdots , C^{-1}_n, \sigma , \sigma C_n , 
\sigma C^2_n, \cdots , \sigma C^{n-1}_n\}$.  This is written 
symbolically as {\bf C}$_{nv} =$ {\bf C}$_x \times$ {\bf C}$_n$ 
indicating that {\bf C}$_{nv}$ contains every product of one element 
from {\bf C}$_s$ times one element of {\bf C}$_n$.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) {\bf C}$_{2v}$, (b) {\bf C}$_{3v}$, (c) {\bf C}$_{4v}$, 
(d) {\bf C}$_{6v}$.}
\label{chap16-fig14}
\end{figure}

The diagrams of some {\bf C}$_{nv}$ groups are shown in Figure
\ref{chap16-fig14}.

\subsubsection{C$_{2v}$}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig15}
\end{figure}

A prototype for the {\bf C}$_{2v}$ group is H$_2$O, which is indicated
in Figure \ref{chap16-fig15}, along with the standard convention for
the coordinate system.  The standard convention for planar {\bf
C}$_{2v}$ molecules is that $z$ is the $C_2$ axis, and $x$ is
perpendicular to the plane.$^4$ Here we see that $C_{2z}$ and
$\sigma_{xz}$ lead to an interchange of equivalent $H$ atoms.  While
$e$ and $\sigma_{yz}$ leave all atoms unchanged.

Since $\sigma_vC_2 = C_2 \sigma_v$, {\bf C}$_{2v}$ is Abelian, and 
the two reflections $\sigma_{xz}$ and $\sigma_{yz}$, are in different 
classes.

\subsubsection{C$_{3v}$}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig16}
\end{figure}

A prototype for {\bf C}$_{3v}$ is the ammonia molecule of Figure
\ref{chap16-fig16}, where $N$ is below the plane of the H's.  The
standard convention is with $z$ as the $C_3$ axis.  Applying $C_3$ to
the reflection plane $\sigma_{xz}$ leads to $\sigma^{\prime}$, see
Figure \ref{chap16-fig14}.  That is, $C_3 \left( \sigma_{xz} \right)
\equiv C_3 \sigma_{xz} C^{-1}_3 = \sigma^{\prime}$ and $C_3 \left(
\sigma^{\prime\prime} \right) \equiv C_3 \sigma^{\prime \prime}
C_3^{-1} = \sigma^{\prime \prime}$ Thus, all three reflections are in
the same class.  Since $\sigma C_3 = C_3^{-1}\sigma$, we see that
$C_3$ and $C_3^{-1}$ are in the same class.  Thus, {\bf C}$_{3v}$
partitions into classes as $\{e\}, \{C_3 , C_3^{-1}\}, \{\sigma_{xz} ,
\sigma^{\prime} , \sigma^{\prime \prime}\}$.

\subsubsection{C$_{4v}$}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig17}
\end{figure}

A prototype for {\bf C}$_{4v}$ is VCl$_5$, which has Cl atoms at the
apices of a tetragonal pyramid.  For {\bf C}$_{4v}$ molecules, $z$ is
the $C_4$ axis, and $x$ and $y$ pass closest to the off-axis atoms.
The $C_4$ operation converts $\sigma_{xz}$ into $\sigma_{yz}$, see
Figure \ref{chap16-fig14}, $C_4 \sigma_{xz}C^{-1}_4 = \sigma_{yz}$,
and $\sigma^{\prime}$ into $\sigma^{\prime \prime}$.  However, to
convert $\sigma_{xz}$ into $\sigma^{\prime}$, would require a $C_8$
rotation.  Thus, the class structure of {\bf C}$_{4v}$ is $\{e\} ,
\{C_4 , C_4^{-1}\} , \{C^2_4\}, \{\sigma_{xz} , \sigma_{yz}\} ,
\{\sigma^{\prime} , \sigma^{\prime \prime}\}$.

\subsubsection{C$_{6v}$}

The classes of {\bf C}$_{6v}$ are $\{e\}$, $\{C_6 , C_6^{-1}\}$, 
$\{C^2_6 , C_6^{-2}\} , \{C^3_6\}$, $\{\sigma_{xz} , \sigma^{\prime} , 
\sigma^{\prime \prime}\}$, $\{ \sigma_{yz}, \sigma^{\prime \prime 
\prime} , \sigma^{\prime \prime \prime \prime}\}$.

\subsection{The C$_{nh}$ Groups}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) {\bf C}$_{2h}$, (b) {\bf C}$_{3h}$, (c) {\bf C}$_{4h}$.}
\label{chap16-fig18}
\end{figure}

A second reflection operator that may be combined with {\bf C}$_n$ is
the horizontal reflection $\sigma_h$, in which the reflection plane is
perpendicular to the rotation axis.  Some examples are indicated in
Figure \ref{chap16-fig18}.  A cursory examination of Figure
\ref{chap16-fig18} might lead one to incorrectly conclude that {\bf
C}$_{nh}$ contains vertical reflections.  That is not correct as can
be seen by examining the following, both the tick mark and some line
off the axis between the tick marks.


\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig19}
\end{figure}

Starting with Figure \ref{chap16-fig19}(b) and applying $C_2$, leads
to Figure \ref{chap16-fig19}(a).  Whereas the $\sigma_v$ moving the
dot to the same spot leads to Figure \ref{chap16-fig19}(c).  Thus, the
reflection $\sigma_v$ is not equivalent to the rotation $C_2$.

In general,
\begin{equation}
C_nC_h = \sigma_h C_n
\label{chap16-eqno13}
\end{equation}
so that  {\bf C}$_{nh}$ is Abelian, every element in a different class.

The elements of {\bf C}$_{nh}$ are $\{e\}, C_n , C^2_n , \cdots , 
C_n^{n-1} , \sigma_h , \sigma_h C_n , \cdots , \sigma_h C_n^{n-1}\}$.  
The product of $\sigma_n C_h$ is the rotary reflection $S_n = 
\sigma_h C_n$.

\subsubsection{C$_{2h}$}

Considering $z$ to be along the $C_2$ axis, then $C_2$ takes $x 
\rightarrow -x$, $y \rightarrow -y$, and $z \rightarrow z$, while 
$\sigma_h$ takes $x \rightarrow x$, $y \rightarrow y$, and $z 
\rightarrow -z$.  Thus, $S_2 = \sigma_h C_2$ takes $x \rightarrow 
-x$, $y \rightarrow -y$, and $z \rightarrow -z$, and hence, every 
vector is changed to the opposite direction.  Such an operation is 
called the inversion, and denoted by $i$,
\begin{equation}
i = \sigma_h C_2 = S_2
\label{chap16-eqno14a}
\end{equation}
Since, $\sigma_h$ and $C_2$ commute, we find that
\begin{equation}
C_2 = \sigma_h i
\label{chap16-eqno14b}
\end{equation}
and
\begin{equation}
\sigma_h = i C_2
\label{chap16-eqno14c}
\end{equation}
Thus, the elements of {\bf C}$_{2h}$ are $\{e , C_2 , \sigma_h , i\}$ 
which can be generated with any one of the following sets of 
operations, $\{ C_2 , \sigma_h\}$, $\{C_2 , i\}$, and $\{ \sigma_h , 
i\}$.

Since {\bf C}$_{nh}$ with even $n$ contain $C_2$, whereas those of 
odd $n$ do not, the inversion will appear only in {\bf C}$_{nh}$ of 
even $n$.

Examples of molecules with a {\bf C}$_{2h}$ point group are 
$trans$-1,2-dichloroethylene
\begin{equation}
% missing figure!
\end{equation}
and $trans$-1,3-butadiene
\begin{equation}
% missing figure!
\end{equation}
The standard convention is to take the $z$ axis as the $C_2$ axis.  
Thus, for $trans$-1,3-butadiene, the $z$ axis is perpendicular to the 
molecular plane.  For $cis$-1,3-butadiene, which is of symmetry {\bf 
C}$_{2v}$, the standard convention is to take the $x$ axis 
perpendicular to the molecular plane.

\subsubsection{C$_{3h}$ and C$_{4h}$}

The classes of {\bf C}$_{3h}$ are $\{e\}, \{C_3 , C_3^{-1}\}, 
\{\sigma_h \}, \{S_3, S_3^{-1}\}$ while the classes of {\bf C}$_{4h}$ 
are $\{e\}, \{C_4 , C_4^{-1}\}, \{C^2_4\}, \{\sigma_h\}, \{S_4, 
S_4^{-1}\}, \{i\}$.

\subsection{The S$_n$ Groups}

Since $S_2 = i$, the group {\bf S}$_2$ consists of $\{e,i\}$ and is 
denoted as {\bf C}$_i$.  Starting with $S_3$, and taking products, we 
get, using (13), $S^n_3 = (\sigma_h)^nC^n_3$.  Hence, $S^2_3 = 
C^2_3$, $S^3_3 = \sigma_h$, $S^4_5 = C_3$, $S^5_3 = \sigma_h C^2_3 = 
S_3^{-1}$, and $S^6_3 = e$.  Thus, {\bf S}$_3$ is just the group {\bf 
C}$_{3h}$.  In general, for odd $n$, {\bf S}$_n$ is the same as {\bf 
C}$_{nh}$.

The $S_4$ operation generates $\{e\},\{S_4,S_4^{-1}\}, \{C^2_4\}$ and 
hence, leads to a new group, as do the other {\bf S}$_n$ with $n$ even.

In general, we find that $S^2_n = S_nS_n = \sigma_h C_n\sigma_hC_n = 
\sigma_h \sigma_h C_nC_n = C^2_n$.  Thus, a $S_n$ axis implies a 
$C_{n/2}$ axis.  As a result, ~~~~~~~~ is always ~~~~~~ , and ~~~~~~ 
is always ~~~~~~.

\subsection{The D$_n$ Groups}

Consider that we start with {\bf C}$_n$, and add a two-fold axis 
perpendicular to the $n$-fold axis, hereafter called the principal 
axis.  The resulting group $\{e,C_nC_n^2,\cdots , 
C_n^{n-1},C-2C_2C_n,C_2C_n^2,\cdots , C_2, C_n^{n-1}\}$ is denoted as 
{\bf D}$_n$, D for dihedral. Here, $C_2$ denotes the new rotation, 
the principal axis will be denoted as $z$.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) {\bf D}$_2$, (b) {\bf D}$_3$, (c) {\bf D}$_4$,
(d) {\bf D}$_6$.}
\label{chap16-fig20}
\end{figure}

The stereograms for several {\bf D}$_n$ are shown in the Figure
\ref{chap16-fig20}.

\subsubsection{D$_2$}

In Figure \ref{chap16-fig21}, we see that $C_{2x}C_{2z} =
C_{2z}C_{2x}$, and that both just correspond to a new $C_2$ about the
$y$ axis.  Thus, {\bf D}$_2$ is composed of rotations about the $x$,
$y$, and $z$ axis.  Since they commute, each element is in a different
class, $\{e\} , \{C_{2z}\}, \{C_{2y}\}, \{C_{2x}\}$.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig21}
\end{figure}

\subsubsection{D$_3$}

Starting with a two-fold axis, $C_{2x}$ and applying a $C_3$
perpendicular to this axis, we obtain new axes, $C^{\prime}_2 =
C_3(C_{2x}) \equiv C_3C_{2x}C_3^{-1}$ and $C^{\prime \prime}_2 =
C^2_3(C_{2x})\equiv C^2_3C_{2x}C_3^{-2}$, as in Figure
\ref{chap16-fig22}.


\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig22}
\end{figure}


Applying $C_{2x}$ to $C_3$, $C_{2x}(C_3) \equiv 
C_{2x}C_3C_{2x}C_3^{-1}$ just reverses the sign of the three-fold 
axis, leading to $C_3^{-1}$.  Thus, the group $D_3$ is non-Abelian, 
and has classes as $\{e\}$, $\{C_3,C_3^{-1}\}$, $\{C_{2x}, C^{\prime}_2, 
C_2^{\prime \prime}\}$.

\subsubsection{D$_4$ and D$_6$}

The classes of {\bf D}$_4$ are $\{e\}$, $\{C_4 , C_4^{-1}\}$, 
$\{C^2_4\}, \{C_{2z}, C_{2y}\}$, $\{C^{\prime}_2 , 
C^{\prime \prime}_2\}$, and {\bf D}$_6$ are $\{e\}$, $\{C_6 , 
C_6^{-1}\}$, $\{C_6^2\}$, $\{C_6^{-2}\}$, $\{C_6^3\}, \{C_{2x} , 
C^{\prime}_2 , C_2^{\prime \prime}\}$, $\{C_{2y}, C_2^{\prime \prime 
\prime} , C_2^{\prime \prime \prime \prime}\}$.

\subsection{The D$_{nh}$ Groups}

Starting with {\bf D}$_n$ having $2n$ elements, and adding a
horizontal reflection, leads to a group of $4n$ elements denoted as
{\bf D}$_{nh}$.  Since the generators are $\{C_n , C_{2x},
\sigma_h\}$, we could also view {\bf D}$_n$ as arising from adding a
$C_{2x}$ to $C_{nh}$.  The stereograms for several cases are found in
Figures \ref{chap16-fig23}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) {\bf D}$_{2h}$, (b) {\bf D}$_{3h}$, (c) {\bf D}$_{4h}$,
(d) {\bf D}$_{6h}$.}
\label{chap16-fig23}
\end{figure}

We recall from (14) that $i = C_{2z} \sigma_h$ so that the inversion
is contained in {\bf D}$_{nh}$, if $n$ is even.  Also, we recall from
the discussion of {\bf D}$_{2v}$ that a $C_2$ rotation axis in a
reflection plane $\sigma$ leads to a new $\sigma^{\prime} = \sigma
C_2$ perpendicular to the old plane, and also containing the $C_2$
axis.  Thus, $C_{2s}\sigma_h$ leads to a $\sigma_v$ plane, that is, a
reflection plane containing the $C_n$ axis.  As a result, {\bf
D}$_{nh}$ contains $n$ vertical reflection planes as indicated in
Figure \ref{chap16-fig23}.  For odd $n$, these $\sigma_v$ planes are
converted into each other by the $C_n$ operations, and hence, all are
in the same class.  For even $n$ there are two classes of $\sigma_v$,
this is the same as the case for $C_2$ classes.  The classes are
\begin{equation}
{\rm{\bf{D}}}_{2h} : \{e\} , \{C_{2x} \}, \{C_{2y}\}, \{C_{2z}\}, \{ i 
\}, \{ \sigma_{xy} \}, \{ \sigma_{xz} \} , \{\sigma_{yz}\}
\end{equation}
\begin{equation}
{\rm{\bf{D}}}_{3h} : \{e\} , \{C_3 , C_3^{-1}\} , \{ \sigma_h \} , \{ S_3, 
S_3^{-1}\} , \{C_2 , C_2^{\prime} , C_2^{\prime \prime} \} , \{ 
\sigma_v \} , \{ \sigma_v^{\prime} \} , \{ \sigma_v^{\prime \prime} 
\}
\end{equation}
\begin{eqnarray}
{\rm{\bf{D}}}_{4h} : & \{e\} , \{C_{4z} \} , \{ C_{4z}^{-1}\} , 
\{C^2_{4z}\} , \{ \sigma_{xy} \} , \{S_4, S_4^{-1}\},\cr
& \{ i\}, \{C_{2x}\} , \{C_{2y}\} , \{ C_2^{\prime}\} , \{ C^{\prime 
\prime}_2 \} , \{ \sigma_{xz} \} , \{ \sigma_{yz} \}, \{ 
\sigma^{\prime \prime} \}
\end{eqnarray}
\begin{eqnarray}
{\rm{\bf{D}}}_{6h} : & \{e\} , \{C_6 , C_6^{-1} \} , \{ C_6^2 , 
C_6^{-2} \} , \{C^3_6 \} , \{C_{2x} , C_2^{\prime} , C_2^{\prime 
\prime} \} , \{C_{2y} , C_2^{\prime \prime \prime} , C_2^{\prime 
\prime \prime \prime}\}\cr
& \{ i \}, \{S_6, S_2^{-2}\} , \{S_3 , S_3^{-1}\} , \{ \sigma_h \}, \{ 
\sigma_{xz} , \sigma^{\prime} , \sigma^{\prime \prime} \} , \{ 
\sigma_{yz} , \sigma^{\prime \prime \prime} , \sigma^{\prime \prime 
\prime \prime}\}
\end{eqnarray}
A protoptype molecule for {\bf D}$_{2h}$ is etyelene.  The standard
axis convention is indicated in Figure \ref{chap16-fig24}.  Here, $x$
is perpendicular to the plane, and $z$ is passing through the maximum
number of atoms. In cases where either choice of $z$ passes through
the same number of atoms, then $z$ is chosen to cut the maximum number
of bonds.$^4$ An example of a molecule with a {\bf D}$_{3h}$ point
group is $s$-triazine, Figure \ref{chap16-fig25}(a).  An example of
{\bf D}$_{4h}$ is cyclobutane, Figure \ref{chap16-fig25}(b), and an
example of {\bf D}$_{6h}$ is benzene, Figure \ref{chap16-fig25}(c).
In all cases, with $n > 2$, the $n$ axis is the $z$ axis.  Here, $x$
is taken to pass through the maximum number of atoms, if this does not
fix $x$ then it is taken to cut the maximum number of bonds.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig24}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig25}
\end{figure}

\subsection{The D$_{nd}$ Groups}

From the previous discussion, we see that {\bf D}$_{nh}$ can be
obtained from {\bf D}$_n$ by adding $\sigma_v$ planes containing both
the $C_n$ and $C_2$ axes.  However, we can also obtain a group of
order $4n$ by starting with {\bf D}$_n$, and placing $\sigma_v$ planes
in between the $C_2$ axis, as Figure \ref{chap16-fig26} illustrates.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) {\bf D}$_{2d}$, (b){\bf D}$_{3d}$.}
\label{chap16-fig26}
\end{figure}

The resulting groups are denoted as {\bf D}$_{nd}$, $d$ for diagonal
mirror planes. From Figure \ref{chap16-fig26}(a), we see that {\bf
D}$_{2d}$ contains $S_4$ and $S_4^{-1}$. Since $\sigma (C_{2x}) \equiv
\sigma C_{2x}\sigma = C_{2y}$ and $C_{2x}(\sigma) \equiv C_{2x} \sigma
C_{2x} = \sigma^{\prime}$, the class structure of {\bf D}$_{2d}$ is
$\{e\}, \{S_{4x} , S_{4x}^{-1}\} , \{C_{2z} \} , \{C_{2x} , C_{2y} \}
, \{ \sigma , \sigma^{\prime} \}$.  An example of a molecule with a
{\bf D}$_{2d}$ point is allene (Figure \ref{chap16-fig27}).

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{Side (a) and end (b) views of allene. Note that the $x$ and
$y$ axes are skewed with respect to the CH$_2$ planes as indicated
on the right.}
\label{chap16-fig27}
\end{figure}


The class structure of {\bf D}$_{3d}$ is $\{ e\}$, $\{ S_6 , S_6^{-1} 
\}$, $\{ C_3 , C_3^{-01} \}$, $\{ i \}$, $\{ C_{2x} , C_2^{\prime} , 
C_2^{\prime \prime} \}$, $\{ \sigma_{yz} , \sigma^{\prime} 
\sigma^{\prime \prime} \}$.  An example of this symmetry is the stable 
configuration of staggered ethane (Figure \ref{chap16-fig28}).

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig28}
\end{figure}


\subsection{C$_{\infty v}$ and D$_{\infty h}$}

Letting the $n$ of {\bf C}$_n$ go to infinity, we obtian the 
two-dimensional rotation group, denoted here as {\bf C}$_{\infty}$.  
For use, only important point groups contain {\bf C}$_{\infty}$ will 
be {\bf C}$_{\infty v}$ and {\bf D}$_{\infty h}$, corresponding to 
linear molecules without and with an inversion center, respectively.  
Since $C_n \sigma_v = \sigma_v C_n^{-1}$, the rotation $R(\varphi)$ 
through an arbitrary angle $\phi$, and its inverse 
$R^{-1}(\phi)-R(-\phi)$ must be in the same class.  {\bf C}$_{\infty v}$ 
and {\bf D}$_{\infty h}$ each contain an infinite number of mirror 
planes, all of which must be in the same class, since given any two 
$\sigma_v$ and $\sigma^{\prime}_v$, the group contains a rotation 
interconverting them. Similarly, the infinite number of $C_2$ axis of 
{\bf D}$_{\infty h}$ are all in the same class.

\subsection{Other Point Groups}

In constructing {\bf D}$_n$, we took the $C_2$ axis perpendicular to 
the $C_n$ axis.  If they are allowed to be non-perpendicular, then 
there are very severe requirements on the inter-relationships that 
must be satisfied in order to end up with a finite group.  These 
requirements are the same ones that must be satisfied in order to 
obtain a regular three-dimensional polyhdron.  The five solutions are:
\begin{enumerate}
\item tetrahedron, four faces, {\bf T} or {\bf T}$_d$
\item cube, six faces, {\bf O} or {\bf O}$_h$
\item octahedron, eight faces, {\bf O} or {\bf O}$_h$
\item dodecahedron, twelve faces, {\bf K} or {\bf K}$_h$
\item icosahedron, twenty faces, {\bf K} or {\bf K}$_h$
\end{enumerate}
If no reflections are allowed, the tetrahedron leads to the group {\bf
T} containing twelve elements.  Including reflections, leads to the
group {\bf T}$_d$ with twenty-four elements.  The cube and octahedron
each lead to groups {\bf O} or {\bf O}$_h$ with twenty-four and
fourty-eight elements, respectively, depending on whether reflections
are forbidden or allowed.  Eliminating the diagonal $C_2$ axis of {\bf
O}$_h$ leads to {\bf T}$_h$ with twenty-four elements.  The
dodecahedron and icosahedron both lead to the groups {\bf K} and {\bf
K}$_h$ with sixty and one-hundred twenty elements, respectively,
depending on whether reflections are forbidden or allowed.  The
stereograms for some of these groups is given in Figure
\ref{chap16-fig29}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) {\bf T}, (b) {\bf T}$_d$, (c) {\bf O}$_h$.}
\label{chap16-fig29}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig30}
\end{figure}

As mentioned earlier, the elements of these groups can be followed 
easily by labelling the corners of a tetrahedron or cube (Figure
\ref{chap16-fig30})
and following the permutations of these indices.  The classes are
\begin{description}
\item[T] $\{e\} , \{C_{2x},C_{2y}C_{2z}\},\{$all four 
$C_2\},\{$all four $C_3^{-1}\}$
\item[T$_d$] $\{e\},\{$three $C_2\},\{$eight 
$C_3,C_3^{-1}\},\{$six $\sigma_d\}\{$six $S_4,S_4^{-1}\}$
\item[O] $\{e\}, \{C_{2x},C_{2y}C_{2z}\},\{$eight 
$C_3,C_3^{-1}\},\{$six $C_4$ and $C_4^{-1}\},\{$six $C_2^{\prime}\}$
\end{description}
{\bf O}$_h$ is obtained from $O$ by {\bf O} $\times$ {\bf C}$_i$. 
That is, for each elements of $O$ we also add the inverse times that 
element.  Thus, the classes of {\bf O}$_h$ are those of {\bf O} plus 
$\{i\},\{\sigma_{yz}, \sigma_{xz} , \sigma_{xy}\}\{$eight $S_3, 
s_3^{-1}\},\{$six $S_4,S_4^{-1}\},\{$six $\sigma^{\prime}\}$.

\section{Representation of Characters}

Group theory is intrinsically interesting to many people, but our 
reason for studying it here is because we can learn a great deal about 
the exact wavefunctions of molecules by applying a little group 
theory.  For example, every selection rule results directly from 
simple group theoretical considerations, and using group theory, 
essentially all degeneracies can be predicted in advance.  The reason 
why group theory helps with learning about wavefunctions is that the 
exact eigenfunctions corresponding to a particular energy form a basis 
for a representation of the group.  In this section, we will 
introduce the basic concepts of a representation of a group.

\subsection{Representations}

Let $G$ be the symmetry group for a Hamiltonian, that is, the set of 
symmetry operations $R$ that commute with $H$,
\begin{equation}
RH = HR.
\label{chap16-eqno15}
\end{equation}
We will sometimes put a circumflex over the operator $R$ to emphasize 
that it is an operator, and other times we will omit it.  Consider an 
exact eigenfunction $\phi$ of $H$
\begin{equation}
H \psi = E \psi
\label{chap16-eqno16}
\end{equation}
and the effect of a symmetry operation $R$ upon (10).  Using (15), we 
see that
\begin{equation}
RH \psi = HR \psi.
\label{chap16-eqno17}
\end{equation}
Thus, applying $R$ to each side of (16) and (17), we obtain 
$H({\hat{R}} \psi) = E({\hat{R}}\psi)$.  Thus, given that $\psi$ is 
an eigenfunction of $H$, then ${\hat{R}}\psi$ is also an eigenfunction 
of $H$, and with the same energy $E$.  This does not, of course, mean 
that there are two solutions with energy $E$.  For example, if 
$\phi_u$ is the wavefunction of the $u$ state of $H_2$, $H \phi_u = 
E_u \phi_u$, then $H(i\phi_u)=E_u(i\phi_u)$ but $i \phi_u = - 
\phi_u$.  That is, $i \phi_u$ is not a new solution, it is just a 
number ($-1$) times the old one.

Operating on (16) with all $g$ elements of the symmetry group of $H$, 
$G = \{e, R_2, \cdots , R_g\}$ we find $g$ functions, which may or may 
not be different.  $S = \{ \psi , R_2 \psi , \cdots , R_2 \psi\}$, all 
of which are eigenfunctions of ${\hat{H}}$ and are degenerate.  
Denoting the functions of $S$ as $\psi_i \equiv R_i\psi$, we see that 
operation of any group element $R_j$ upon any $\psi_i \epsilon S$ 
yields a new element $R_k$ also in $S$,
\begin{equation}
R_j \psi_i = \underbrace{R_jR_i\psi}_{R_k} = R_k \psi = \psi_i 
\epsilon S.
\end{equation}
Hence, the functions of $S$ transform into themselves under all 
transformations of $G$.  Since the functions of $S$ may not be 
linearly independent, we will form a new set of functions 
$S^{\prime}=\{ \phi_1 , \phi_2 , \cdots , \phi_d;(d \leq g)\}$, which 
are orthonormal and hence, linearly independent.  Since any function 
of $S$ can be described as a linear combination of functions in 
$S^{\prime}$, and some $R$ operating on any function of $S$, leads to 
a linear combination of functions of $S$, then $R$ operating on any 
function of $S^{\prime}$ must lead to a linear combination of the 
functions in $S^{\prime}$.  That is, for any $R \epsilon G$ and, any 
$\phi_j\epsilon S^{\prime}$, we have
\begin{equation}
R\phi_j = \sum^{d}_{k=1} \phi_k C_k.
\label{chap16-eqno18}
\end{equation}
Thus, the $d$ dimensional space spanned by $S^{\prime}$, that is, for 
which $S^{\prime}$ is a basis, is invariant under transformation by 
any element $R \epsilon G$.  Such a set of functions is said to be 
complete under $R$, or alternatively, we say that the function of $S^{\prime}$ 
form a basis for, a representation of, the group $G$.

Since  the expansion coefficients $C_k$ in (18) depend upon which 
$\phi_j$ we start with, and which $R \epsilon G$ we operate with, we 
will rewrite (18) as
\begin{equation}
R \phi_j = \sum_{k} \phi_k D_{kj}(R)
\label{chap16-eqno19}
\end{equation}
where $D_{kj}(R)$ is the set of expansion coefficients for all 
possible starting functions $\phi$, and all possible $R$.  Thus, to 
describe the effect of $G$ upon the set $S^{\prime}$, we have a set 
of $g$ matrices $\underline{D}(R)$, one function for each element of 
$G$, each of which is $d$ by $d$.

Now we come to the key point.  Consider operating on $\phi_k$ first 
with $R_J$ and then with $R_I$
\begin{equation}
{\hat{R}}_I {\hat{R}}_J \phi_k = \sum_{\ell} R_I \left[ \phi_{\ell} 
D_{\ell k} (R_J)\right] = \sum_{\ell} \sum_{m} \phi_m D_{m \ell} 
(R_I)D_{\ell k}(R_J)
\label{chap16-eqno20a}
\end{equation}
Note in the second step, that $D_{\ell k}(R_J)$ is just a number and 
hence, is unaffected by $R_I$.  Since the product of $R_I$ and $R_J$ 
is some other element $R_K$, also in the group, $R_K = R_IR_J$, and 
since
\begin{equation}
{\hat{R}}_K \phi_k = \sum_{m} \phi_m D_{mk} \left( R_K \right)
\label{chap16-eqno20b}
\end{equation}
then the right side of (20a) and (20b) must be equal for all $k$ and 
for all choices of $I$ and $J$.  Consequently, since the $\phi_m$ are 
linearly independent, the $D$ matrices must satisfy the relation
\begin{equation}
D_{mk} \left( R_k \right) = \sum_{\ell} D_{m \ell} \left( R_I \right) 
D_{\ell k} (R_J)
\label{chap16-eqno21a}
\end{equation}
or in matrix notation
\begin{equation}
\underline{D} \left( D_K \right) = \underline{D} \left( R_I \right) \underline{D} 
\left( R_J \right).
\label{chap16-eqno21b}
\end{equation}
That is, the matrices associated with the elements $G$ multiply in 
the same way as do the elements for $G$.  If in (19) we had defined
\begin{equation}
R \phi_j = \sum_{k} D_{jk} (R) \phi_k,
\end{equation}
then (21) would have the form
\begin{equation}
\underline{D} \left( R_K \right) = D \left( R_J \right) D \left( R_I 
\right),
\end{equation}
that is, the order of the product in (21) and would be opposite to 
that in (20).

Thus, as far as the space of functions spanned by $S^{\prime} = \{ 
\phi_1 \cdots \phi_d\}$ is concerned, the effects of all the group 
operations of $G$ are completely represented by the effects of the 
matrices $\underline{D}(R)$. Such a set of matrices, $R = \{ 
\underline{D}(e) , \underline{D}(R_2), \cdots , \underline{D} 
(R_2)\}$, multiplying in the same way as the elements of a group, is 
called a representation of the group.  From the above analysis, we see 
that any set of basis functions which is complete for the group $G$ 
leads directly to a representation of the group.  Also shown above, for 
any finite group and given any function $\phi$, we can construct a 
complete set $\{ \phi_i \}$ by operating on $\phi$ with all the 
elements of $G$ and then, Schmidt orthogonalizing to obtain a 
linearly independent set.  The matrices of the representation are then 
just the expansion coefficients for $R \phi_i$.  From now on, instead 
of saying that $\{ \phi_i\}$ is a complete set for $G$, we will say 
that $\{ \phi_i\}$ forms a basis for $G$, or better, that $\{ \phi_i\}$ 
forms a basis for a representation of $G$.

The general mathematical definition of a representation does not 
depend explicitly on the idea of a basis.  The key point of 
representing an abstract group with a set of matrices, is that the 
matrices multiply in the same manner as the abstract group elements.  
That is, the multiplicative structure of the abstract group must be 
preserved.  Using the properties of these matrices, one can obtain all 
information about representations without any discussion of basis 
functions.  However, from our point of view, the whole reason for 
talking about representations is to discuss the properties of 
wavefunctions.  These wavefunctions are just the basis functions for 
representations of the symmetry group.  Hence, by considering 
properties of representations we can learn about our wavefunctions.  
For this reason, we will emphasize the interpretation of results in 
terms of the basis.

\subsubsection{Examples}

The simplest representation, called the trivial representation, of 
any group, is the one where each element is represented by the 
one-by-one matrix 1.  Since $1 \cdot = 1$, the group multiplication 
laws are preserved for any group.  The basis  function of this 
representation must be invariant under all operations of the group, $R 
\psi = \psi$ for all $R \epsilon G$.  As an example, the $1s$ 
wavefunction of $H$ atom is invariant under all operations of the 
three-dimensional rotation group, O$(3)$.  Thus, the $1s$ orbital is 
a basis for the trivial representation, denoted as $S_g$, of this 
group.  Similarly, the group state wavefunction of $H_2$ is invariant 
under all operations of {\bf D}$_{\infty h}$ and hence, forms a basis 
for the trivial representation, denoted as $\sum^+_g$, of this group.  
Note that since every element of $G$ is mapped onto the same matrix, 
the trivial representation does not distinguish between the group 
elements.  As another example, the five $3d$ orbitals of $H$ are 
transformed among themselves by any rotation and hence, they form a 
basis for a five-by-five representation, denoted as $D_g$ of O(3).

Another interesting and useful representation, know as the regular 
representation, is obtained by choosing the basis functions for the 
representation to be the group elements themselves.  For example, 
consider the group {\bf C}$_3 = \{ e , C_3 , C_3^2\}$, then
\begin{eqnarray}
e(e) &=& e\cr
e(C_3) &=& C_3 \Rightarrow \underline{D} (e) = 
\pmatrix{1&0&0\cr
0&1&0\cr
0&0&1\cr}\cr
e(C_3^2) &= C^2_3\cr
C_3(e) &= C_3\cr
C_3(C_3) &= C^2_3 \Rightarrow \underline{D} (C_3) =
\pmatrix{0&1&0\cr
0&0&1\cr
1&0&0\cr}\cr
C_3(C^2_3) &= e\cr
C^2_3(e) &= C^2_3
\end{eqnarray}

\begin{eqnarray}
C^2_3(C_3) &=& e \Rightarrow \underline{D} (C^2_3) =
\pmatrix{0&0&1\cr
1&0&0\cr
0&1&0\cr}\cr
C^2_3(C_3) &=& C^4_3 = C_3
\end{eqnarray}
This representation is three-dimensional for this group, and there is a 
one-to-one correspondence between group elements and matrices.  
Therefore, no information about the group is lost, and the 
representation is said to be faithful, just the opposite of the 
trivial representation.

In both the trivial and the regular representations, the identity 
element $e$ of the group $G$ is mapped to the $d \times d$ identity 
matrix, where $d$ is the dimension or degree of the representation.  
This is true, in general, since for $e \epsilon G$ and $R \epsilon G$ 
is $eR = R = Re$ so that
\begin{equation}
\underline{D} (E) \underline{D}(R) = \underline{D} (R) 
\pmatrix{1 & & 0\cr
& 1 &\cr
0 & & 1\cr}
\end{equation}

As another example, consider the group {\bf C}$_4 = \{ e , C_4 , 
C_4^2 , C^3_4\}$ operating on the function $f(x) = X^2$ in the 
two-dimensional vector space spanned by basis vectors $e_x$ and $e_y$ 
in the $x$ and $y$ directions, respectively.  Since $C_4e_x=e_y$ and 
$C_4e_y = - e_x$, we find that $C_4(xe_x + ye_y) = (-ye_x + xe_y)$ 
for arbitrary $x$ and $y$.  Hence, in vector notation
\begin{equation}
C_4 = \pmatrix{x \cr y\cr}
= \pmatrix{-y\cr x\cr}.
\end{equation}
Consequently, the effect of the group elements on $x^2$ is $C_4x^2 = 
+y^2$, $C_4^2x^2 = +x^2$, and $C^3_4x^2 = + y^2$.  Therefore, $\{x^2 , 
y^2\}$ is a basis for a two-dimensional representation of 
$\underline{C}_4$ with representation matrices
\begin{eqnarray}
\underline{D}(e) &=& \pmatrix{1&0\cr 0& 1\cr}\cr
\underline{D}(C_4) &=& \pmatrix{0 & 1\cr 1 & 0\cr}\cr
\underline{D}(C^2_4) &=& \pmatrix{1 & 0\cr 0 & 1\cr}\cr
\underline{D}(C^3_4) &=& \pmatrix{0 & 1\cr 1 & 0\cr}
\label{chap16-eqno22}
\end{eqnarray}
Sure enough, the $\underline{D}(R)$ multiply like the group elements 
of {\bf C}$_4$.

\subsection{Transformation of Bases}

The set of functions $\{ \phi_i; i = 1 , \cdots , d\}$ used in 
constructing the representation $\{ \underline{D}(R)\}$ is just one 
basis for the $d$-dimensional space.  We could have picked many other 
orthonormal bases, $\{ \phi_1^{\prime} , \cdots , \phi^{\prime}_d \}$ 
spanning the same space.   Letting $\underline{B}$ be the 
transformation between these bases
\begin{equation}
\phi^{\prime}_i = \phi_j B^{-1}_{ji} ,
\label{chap16-eqno23}
\end{equation}
using the Einstein summation convention.  We now obtain
\begin{equation}
{\hat R} \phi^{\prime}_i = {\hat R} \left( \phi_j B_{ji}^{-1} 
\right) = B^{-1}_{ji} {\hat R} \left( \phi_j \right) = B^{-1}_{ji} 
\phi_k D_{kj}(R) = \phi^{\prime}_{\ell} B_{\ell k} D_{kj} (R) 
B^{-1}_{ji} = \phi^{\prime}_{\ell} D^{\prime}_{\ell i}(R),
\end{equation}
where $\underline{D}^{\prime}$ is defined by
\begin{equation}
\underline{D}^{\prime}(R) = \underline{B}\underline{D}(R) 
\underline{B}^{-1}.
\label{chap16-eqno24}
\end{equation}
Note that the order of the $B_{\ell k}$, $D_{kj}$, and $B^{-1}_{ji}$ 
terms is irrelevant as long as the indices are included explicitly.  
However, when using matrix notation as in (24), only one order is 
correct.  Thus, we see that a change in the basis modifies the 
representation matrices as in (24).  Of course, $\{ \phi^{\prime}_i\}$ 
is a basis for $G$ and hence, the new matrices $\{ 
\underline{D}^{\prime}(R)\}$ will also form a representation.  Thus, 
replacing every  $\underline{D}(R)$ by $\underline{D}^{\prime}(R) = 
\underline{B}\underline{D}(R)\underline{B}^{-1}$ and letting $R_IR_J = 
R_K$, we obtain
\begin{equation}
\underline{D}^{\prime}(R_I) \underline{D}^{\prime}(R_J) = 
\underline{B}\underline{D}(R_I) 
\underbrace{\underline{B}^{-1}\underline{B}}_{e} \underline{D} 
(R_J)\underline{B}^{-1} = \underline{B} 
\underbrace{\underline{D}(R_I) \underline{D}(R_J)}_{\underline{D}(R_k)} 
\underline{B}^{-1} = \underline{D}^{\prime}(R_k).
\end{equation}
Two representations $\{\underline{D}^{\prime}\}$ and $\{ 
\underline{D}\}$ related by (24) are said to be equivalent 
representations of the group.  Note that the same $B$ is used for 
all $R \epsilon G$.  We see that equivalent representations just 
correspond to a different choice of the basis for the same 
$d$-dimensional space.  Since $\{ \phi_1 , \cdots , \phi_d\}$ and $\{ 
\phi^{\prime} , \cdots , \phi^{\prime}_d\}$ are both orthonormal, 
$\underline{B}$ is unitary $\underline{B}^{\dag} - 
\underline{B}^{-1}$, and hence, we can rewrite (24) as
$\underline{D}^{\prime} \left( R_I \right) = 
\underline{B} \underline{D} \left( R_I \right) \underline{\tilde{B}}$.

\subsubsection{Examples}

In the earlier example of {\bf C}$_4$ operating on $f(x) = x^2$, let
\begin{eqnarray}
\phi^{\prime}_1 &=& {1 \over \sqrt{2}} \left( x^2 + y^2 \right) ,\cr
\phi^{\prime}_2 &=& {1 \over \sqrt{2}} \left( - x^2 + y^2 
\right)
\label{chap16-eqno25}
\end{eqnarray}
so that
\begin{equation}
\underline{B} = \pmatrix{{1 \over \sqrt{2}} & {1 \over \sqrt{2}}\cr
{-1 \over \sqrt{2}} & {1 \over \sqrt{2}}\cr}
\end{equation}
and
\begin{equation}
\underline{B}^{-1} = \pmatrix{{1 \over \sqrt{2}} & {-1 \over \sqrt{2}}\cr
{1 \over \sqrt{2}} & {1 \over \sqrt{2}}\cr}.
\end{equation}
Then, $C_4(x^2+y^2)=x^2+y^2$ and $C_4(y^2-x^2)=x^2-y^2$, and
\begin{equation}
\underline{D}^{\prime} \left( C_4 \right) =
\pmatrix{{1 \over \sqrt{2}} & {1 \over \sqrt{2}}\cr
{-1 \over \sqrt{2}} & {1 \over \sqrt{2}}\cr}
\pmatrix{0 & 1\cr
1 & 0\cr}
\pmatrix{{1 \over \sqrt{2}} & {-1 \over \sqrt{2}}\cr
{1 \over \sqrt{2}} & {1 \over \sqrt{2}}\cr} = 
\pmatrix{1 & 0\cr 0 & -1\cr}.
\end{equation}
In the new representation, we have
\begin{eqnarray}
\underline{D}^{\prime}(e) &=& \pmatrix{1&0\cr 0&1\cr}\cr
\underline{D}^{\prime}(C_4) &=& \pmatrix{1&0\cr 0&-1\cr}\cr
\underline{D}^{\prime}(C^2_4) &=& \pmatrix{1&0\cr 0&1\cr}\cr
\underline{D}^{\prime}(C^3_4) &=& \pmatrix{1&0\cr 0&-1\cr}
\label{chap16-eqno26}
\end{eqnarray}
Note that the new function
\begin{equation}
\phi^{\prime}_1 = {1 \over \sqrt{2}} \left( x^2 + y^2 \right)
\end{equation}
is transformed into itself by all the operations of {\bf C}$_4$.  Thus, 
using just this one basis function, we can form a new representation 
of the group with matrices, which are just numbers
\begin{eqnarray}
D(e) &=& 1\cr
D \left( C_2 \right) &=& 1\cr
D \left( C_4^2 \right) &=& 1\cr
D \left( C^3_4 \right) &=& 1.
\label{chap16-eqno27a}
\end{eqnarray}
This is the trivial representation.  Similarly, the new function
\begin{equation}
{1 \over \sqrt{2}} \left( y^2 - x^2 \right)
\end{equation}
by itself is also a basis for a representation of the group,
\begin{eqnarray}
D(e) &=& 1\cr
D \left( C_4 \right) &=& -1\cr
D \left( C^2_4 \right) &=& +1 \cr
D \left( C^3_4 \right) &=& -1.
\label{chap16-eqno27b}
\end{eqnarray}

\subsection{Reduction of Representations}

In the above example, we found that the basis functions $\phi_1 = x^2$ 
amd $\phi_2= y^2$ together form a two-dimensional representation (22) 
of $G$, but that they do not independently form a basis for a 
representation of $G$.  However, we found a transformation (25) on  
these basis functions such that each new function is individually a 
basis function for a representation of $G$, see (27a) and (27b).  In 
this case, we can describe the effects of the symmetry operations of 
$G$ on $\phi^{\prime}_1$ and $\phi^{\prime}_2$ in terms of two sets 
of one-dimensional matrices (27a) and (27b), rather than one set of 
two-dimensional matrices as in (26).  A transformation so reducing 
the order of the matrices required to describe a representation, is 
called a reduction and the representation (26) is said to be 
reduced.  A representation such as (22) that, although not reduced, 
can be brought into a reduced form by a suitable transformation on 
the bases, is said to be reducible.

Consider now a more general case, with a set of representation 
matrices $\underline{D}(R)$ each having the block diagram form
\begin{equation}
\underline{D}(R) = \pmatrix{\underline{D}^2(R) & 0\cr
\underbrace{0}_{d_2} & 
\underbrace{\underline{D}^2(R)}_{d_2}\cr}
\label{chap16-eqno28}
\end{equation}
That is, $D_{ij} = 0$ if $i \leq d_2$ and $j > d_1$, and $D_{ij} = 0$ 
if $i > d_1$ and $j \leq d_1$ for all $R \epsilon G$.  The remaining 
parts of $\underline{D}(R)$ consist of a $d_1 \times d_1$ matrix, 
which we refer to as $\underline{D}^1(R)$, and a $d_2 \times d_2$ 
matrix referred to as $\underline{D}^2(R)$.  We will now show that 
such a representation (28) is reduced.

If the basis is $\{ \psi_1 , \cdots , \psi_d\}$ where $d = d_1 + 
d_2$, we see that for all $R \epsilon G$ we obtain
\begin{equation}
{\hat R} \psi_i = \sum_{j=1}^{d_1} \psi_j D^1_{ji}
\end{equation}
for $i \leq d_1$.  Thus, the basis set $\{ \psi_1 , \cdots , \psi d_1\}$ 
forms a basis for a $d_1$ dimensional representation of $G$, which 
matrices $\underline{D}^1$.  Similarly, letting $\phi_i = 
\psi_{d_1+i}$, for $i \leq d_2$, we find that
\begin{equation}
{\hat R} \psi_i = \sum^{d_2}_{j=1} \psi_j D^2_{ji}
\end{equation}
for $i \leq d_2$, and hence, $\{ \phi_1 , \cdots , \phi d_2\} = \{ 
\psi_{d_1+1} , \cdots , \psi_d\}$ forms a basis for a 
$d_2$-dimensional representation of $G$, with matrices 
$\underline{D}^2$.  Consequently, we say that the representation (28) 
is reduced to the representations $\{D^1\}$ and $\{D^2\}$.  This is 
denoted symbolically as $D = D^1 \otimes D^2$.

Multiplying two matrices of (28) together, leads to
\begin{eqnarray}
\underline{D} \left( D_I \right) \underline{D} \left( R_J \right) &=& 
\pmatrix{\underline{D}^1 & 0\cr
0 & \underline{D}^2\left( R_I \right)\cr}
\pmatrix{\underline{D}^1 \left( R_J \right) & 0\cr
0 & \underline{D}^2 \left( R_J \right)\cr}\cr
&=& \pmatrix{\underline{D}^2 \left( R_I \right) \underline{D}^1 \left( 
R_J \right) & 0\cr
0 & \underline{D}^2 \left( R_I \right) \underline{D}^2 \left( R_J 
\right)\cr}
\end{eqnarray}
But if $R_K = R_IR_J$, then
\begin{equation}
\underline{D} \left( R_K \right) = \pmatrix{\underline{D}^1 \left( 
R_K \right) & 0\cr
0 & \underline{D}^2 \left( R_K \right)\cr}.
\end{equation}
Therefore, we obtain
\begin{eqnarray}
\underline{D}^1 \left( R_K \right) &=& \underline{D}^1 \left( R_I 
\right) \underline{D}^1 \left( R_J \right)\cr
\underline{D}^2 \left( R_K \right) &=& \underline{D}^2 \left( R_I 
\right) \underline{D}^2 \left( R_J \right)
\end{eqnarray}
i.e., $\{\underline{D}^1\}$ and $\{\underline{D}^2\}$ do indeed 
separately form representations of the group.

If a representation $\{\underline{D}\}$ is not reduced but there 
exists some transformation of the basis functions, $\phi^{\prime} = 
\phi B^{-1}$ such that the new representation $\{\underline{D}^{\prime}\}$
is reduced, then we say that the representation $\{ \underline{D}\}$ 
is reducible.  If not such $B$ exists, then we say that $D$ is 
irreducible.   Note that reducing a representation just corresponds to 
transforming the basis set to a new one, in which some subset of the 
new basis forms a basis for the group; i.e., from $\{ \phi_1 , 
\phi_2, \cdots , \phi_d\}$ we can transform to $\phi^{\prime} = 
\phi B^{-1}$ such that $\{ \phi^{\prime}_1 , \cdots , 
\phi^{\prime}_{d_1}\}$ and $\{ \phi^{\prime}_1 , \cdots , 
\phi^{\prime}_{d_2}\}$ separately form bases of $G$.  An irreducible 
representation is one for which there is no possible transformation 
$B$ such that some subset of $\{ \phi^{\prime}\}$ is a basis for $G$.  
In this latter case for any $\phi_i$ and $\phi_j$ there is some $R 
\epsilon G$ such that ${\hat R}\phi_i = \sum C_{\ell} \phi_{\ell}$ 
where $C_j \not= 0$.  For example, for {\bf C}$_{4v}:\{x,y\}$ forms 
a basis for an irreducible representation, and $\{x^2 , y^2\}$ forms a 
basis for a reducible representation which reduces to $\{ x^2 + y^2\}$ 
and $\{ x^2 - y^2\}$.

Now consider the symmetry group $G$ for some $H$, and consider the 
exact eigenfunction $\phi_1$, $H \phi_1 = E \phi_1$.  If $\phi_1$ 
belongs to an irreducible representation of degree $d$, then $\phi_1$ 
must belong to a $d$-fold degenerate set, and this degeneracy cannot 
be lifted by any perturbation on $H$ which retains the symmetry of 
$H$.  In other words, given that $\phi_1$ is an eigenstate, we know 
that the state is $d$-fold degenerate, without any computations.  The 
eigenfunctions of $H$ can always be taken as basis functions for a 
representation of $G$, as shown earlier.  If this representation is not 
irreducible, we can recombine the basis functions until each set is 
the basis for an irreducible representation.  Thus, the 
eigenfunctions of $H$ can always be taken as basis functions for 
irreducible representations of $G$,

The important thing there is that for a finite group, there are only 
a finite number of different irreducible representations, i.e., only a 
finite number of possible symmetries.  Even for many important finite 
groups, the irreducible representations are denumerable or countable.

\subsubsection{Example}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig31}
\end{figure}

Consider the inversion group $G = $ {\bf C}$_i = \{e,i\}$ for a
one-dimensional system with a potential of the form in Figure
\ref{chap16-fig31}.  The only two irreducible representations are $A_g
: D^e = 1 , D^i = 1$ and $A_u : D^e = 1 , D^i = -1$, where $A_g$ and
$A_u$ are the names given these representations.  Both set of matrices
are consistent with the group multiplication properties, $ei - i , ii
= e$, etc.  Thus, since $H$ is symmetric, i.e., invariant under {\bf
C}$_i$, its eigenfunctions must be symmetric or antisymmetric under
inversion.

\subsection{Characters}

In an earlier section, Transformations of Bases, we found that two 
different basis sets $\{ \phi_i: i = 1 , \cdots , d\}$ and $\{ 
\phi^{\prime}_i ; i = 1 , \cdots d\}$ for the same $d$-dimensional 
space, yield equivalent representations $\{D(R)\}$ and 
$\{D^{\prime}(D)\}$, that are related by (24), $D^{\prime}(R) = 
BD(R)B^{-1}$, where $B$ is the matrix transforming the basis functions 
on one set into the other, (23), $\phi^{\prime}_i - \phi_j B_j^{-1}$.  
Either representation tells us everything we can know about the effect 
of $G$ upon the $d$-dimensional space spanned by the basis.  Hence, 
we would not want to bother analyzing the properties of both 
representations.

Our problem now is how do we determine whether two different 
representations are equivalent or not.  For example, even with the 
two-dimensional examples mentioned earlier, it is not obvious that 
representations (22) and (26) are equivalent.  Clearly, it is much too 
painful to methodically try all possible $B$ matrices to find if there 
is one such that $D^{\prime}(R) = BD(R)B^{-1}$ for all $R \epsilon 
G$.  Instead, we will look for matrix properties that are invariant 
under similarity transformations, such equivalent representations 
will have the same value for these invariant properties.

One example of an invariant that should quickly come to mind is the 
determinant. If $\underline{A}^{\prime} = \underline{B}AB^{-1}$, then
$\det \underline{A}^{\prime} = \det ( \underline{BAB}^{-1}) = ( \det 
\underline{B}) (\det \underline{A}) (\det \underline{B}^{-1}) = (\det 
\underline{A})$, where we have made use of the fact that $(\det 
\underline{B}) (\det \underline{B}^{-1}) = 1$.  This follows 
immediately, since $\underline{B}^{-1}\underline{B} = \underline{1}$ 
and $\det \underline{1} = 1$.

For our particular needs, it turns out that there is a more useful 
invariant for determining if representations are equivalent.  
Consider the trace of $D(R)$
\begin{equation}
\chi(R) \equiv \sum_{i} D_{ii}(R).
\end{equation}
If $\{ \underline{D}^{\prime}\}$ is equivalent to $\{ 
\underline{D}\}$, then
\begin{eqnarray}
\chi^{\prime} (R) &=& \sum_{i} D^{\prime}_{ii}(R) = \sum_{i} \sum_{jk} 
B_{ij} D_{jk} (R) B^{-1}_{ki}\cr
&=& \sum_{jk} D_{jk} (R) 
\underbrace{\sum_{i} B_{ki}B_{ij}^{-1}}_{\delta_{kj}} = \sum_{i} 
D_{jj}(R) = \chi(R).
\label{chap16-eqno29}
\end{eqnarray}
Therefore, for two representations to be equivalent, they must have 
the same trace, for all $R \epsilon G$.  The converse is also true; 
the proof involves certain orthogonality relations which will be 
developed in the following section.  Hence, the traces $\{ \chi(R)\}$ 
of the representation matrices $\{D(R)\}$ are sufficient to determine 
whether two representations are equivalent.  For this reason the trace 
of $D(R)$ is called its character.  For many of our considerations, 
the characters alone are sufficient to tell us all that we want to know 
about a representation.

Consider now the conjugate operations $R_1$ and $R_2$.  There exists 
an $R_3$ such that $R_3 R_1R_3^{-1} = R_2$, and therefore, as in 
(29), $\chi(R_1) = \chi(R_2)$.  Thus, all the elements of a class 
have the same character.

If $\{D\}$ is a reducible representation,
\begin{equation}
\underline{D}(R) = \pmatrix{\underline{D}^1(R) & 0\cr
0 & \underline{D}^2 (R)\cr},
\end{equation}
then for all $R \epsilon G$
\begin{equation}
\chi(R) = \chi^1 (R) + \chi^2(R)
\end{equation}
where $\chi^1$ and $\chi^2$ are the characters of $D^1$ and $D^2$.  
More generally, if the representation $\underline{D}$ is reducible 
into irreducible representations $\underline{D}^{\nu}$ each occuring 
$a_{\nu}$ times, 
\begin{equation}
\underline{D} = \sum_{\nu} a_{\nu}
\underline{D}^{\nu}
\end{equation}
then the character becomes
\begin{equation}
\chi(R) = \sum_{\nu} a_{\nu} \chi^{\nu}(R)
\label{chap16-eqno30}
\end{equation}
where $\chi^{\nu}(R)$ is the character of $D^{\nu}(R)$.  In any 
representation, the identity element is represented by a unit matrix
\begin{equation}
D(e) = \pmatrix{1 & & 0\cr
& 1 &\cr
0 & & 1\cr}
\end{equation}
and hence, $\chi (e) = D$, the degree or dimensionality of the 
representation.

We saw, above, that characters characterize irreducible 
representations in that equivalent irreducible representations have 
the same set of characters.  Similarly, we saw that all elements in a 
class have the same character.  By making a table of characters with 
rows corresponding to inequivalent irreducible representations and 
columns corresponding to classes, we can condense all this important 
information about a representation into a very compact form.  These 
tables are called character tables.  Since the number of inequivalent 
irreducible representations of some group $G$ is equal to the number 
of classes of the group, the character table is square.

Character tables for the important point groups are listed in Appendix
16.13.4 and character tables for the symmetric groups are also listed
in Appendix 16.13.4.  For example, the character table for {\bf
  C}$_{2v}=\{e , C_2(z), \sigma_y(xy) , \sigma^{\prime}_v(yz)\}$ is
listed in Table \ref{chap16-tab1}.  In addition to the character
table, we have included in the last two columns, various operators and
functional forms of each symmetry.  Here, $R_i$ denotes a rotation
about the axis, $x$, $y$, $z$ denote $p$ functions, and $yx$, $xz$,
etc., denote $d$ functions.  For example, $e[x] = (+1)x$, $C_2[x] =
(-1)x$, $\sigma_v[x] = (+1)x$, and $\sigma^{\prime}_v[x] = (-1)x$,
implying that $x$ is of $B_1$ symmetry, the standard coordinate system
for {\bf C}$_{2c}$ is given in Figures \ref{chap16-fig14} and
\ref{chap16-fig15}.

\begin{table}
\caption{Character table for {\bf C}$_{2v}$.}
\label{chap16-tab1}
\begin{tabular}{ccccccc}\\ \hline
&\multicolumn{4}{c}{Classes}&\multicolumn{2}{c}{Characteristic}\cr
{\bf C}$_{2v}$ $^a$ & e & {\bf C}$_2(z)$ & $\sigma_v(xz)$ &
$\sigma^{\prime}_v(yz)$ &\multicolumn{2}{c}{Symmetries}\cr

$A_1$ & 1 & 1 & 1 & 1 & $z$ & $x^2,y^2,z^2$\cr
$A_2$ & 1 & 1 & $-$1 & $-1$ & $R_z$ & $xy$\cr
$B_1$ & 1 & $-1$ & 1 & $-1$ & $x,R_y$ & $xz$\cr
$B_2$ & 1 & $-1$ & $-1$ & 1 & $y, R_x$ & $yz$\cr
\hline
\end{tabular}\\
$^a$ Labels for irreducible representations.
\end{table}

Examining the character table further, we see that all the irreducible 
representations are one-dimensional; $\chi(e) = 1$ in each case.  
Therefore, the characters and the matrix representations are one and 
the same.  Also, if any two rows or columns are multiplied together 
and summed, the results is zero, i.e., the rows or columns may be 
treated as orthogonal $4 \times 4$ vectors.  This should not be 
surprising since the irreducible representations are inequivalent and 
must be linearly independent.  Finally, we see that multiplying any 
row or column with itself and summing, i.e., the dot product, leads to 
4, the order of the group.

The orthogonality relations outlined above, hold in general for 
irreducible representations as will be discussed in the next section.

\subsection{Orthogonality Theorems and Reduction of Representations}

In Appendix 16.13.1, we derive two orthogonality theorems for the characters 
of irreducible representations.
\begin{enumerate}
\item Orthogonality of irreducible representations
\begin{equation}
\sum_{R \epsilon G} \chi^{\mu} (R) \chi^{\nu*}(R) = g \delta_{\mu \nu}
\end{equation}
or equivalently,
\begin{equation}
\sum^{r}_{i=1} g_i \chi_i^{\mu} \chi_i^{\nu *} = g \delta_{\mu 
\nu}
\label{chap16-eqno31}
\end{equation}
where $g_i$ is the number of operations in classes $i$, $r$ is the 
total number of classes, $g$ is the number of elements in the group, 
$\mu$ and $\nu$ are irreducible representations, and the * indicates 
complex conjugate.
\item Orthogonality of classes
\begin{equation}
\sum^{r}_{\mu=1} \chi_i^{\mu} \chi_j^{\mu *} = {g \over g_i} 
\delta_{ij}
\end{equation}
\end{enumerate}

\subsubsection{Reduction of Representations}

Consider a representation with characters $\chi(r)$.  If the 
representation $\{ \underline{D} (R)\}$ is reducible, that is
\begin{equation}
\underline{D} (R) = \sum_{\nu} a_{\nu} \underline{D}^{\nu} (R)
\end{equation}
where $a_{\nu}$ is the number of times the $\{ \underline{D^{\nu}} 
(R) \}$ irreducible representation occurs in reducing $\{ \underline{D} 
(R)\}$, then we saw in (30),
\begin{equation}
\chi (R) = \sum_{\nu} a_{\nu} \chi^{\nu} (R).
\label{chap16-eqno32}
\end{equation}
Multiplying (32) by $\chi^{\mu *}(R)$ and summing over all $R \epsilon 
G$, we obtain
\begin{equation}
\sum_{R} \chi(R) \chi^{\mu *}(R) = \sum_{\nu} a_{\nu} \sum_{R} 
\chi^{\nu}(R) \chi^{\mu *}(R) = \sum_{\nu} a_{\nu}g\delta_{\mu \nu} = 
ga_{\mu}
\end{equation}
using (31).  Thus, the number of times that the $\mu$ irreducible 
representation occurs in $\{ \underline{D} (R)\}$ is given by the 
simple formula
\begin{equation}
a_{\mu} = {1 \over g} \sum^{r}_{i=1} g_i \chi_i \chi_i^{\mu *}
\label{chap16-eqno33}
\end{equation}
where $i$ refers to the class.

\subsubsection{Examples}

Recall the example from Section 16.1.1, in which we considered the
representation of {\bf C}$_4$ afforded by the functions $x^2$ and
$y^2$.  Taking the traces of the representation matrices in (22), we
obtain the following characters, $\chi(e) = 2$, $\chi(C_4) = 0$,
$\chi(C^2_4) = 2$, and $\chi(C^3_4) = 0$.  The character table for
$\underline{C}_4$ is shown in Table \ref{chap16-tab2}.

\begin{table}
\caption{Character table for {\bf C}$_4$.}
\label{chap16-tab2}
\begin{tabular}{ccccccc}\\ \hline

{\bf C}$_4$ & $e$ & $C_4$ & $C_2$ & $C^3_4$&\multicolumn{2}{c}{Characteristic}\cr
& & & & & \multicolumn{2}{c}{Symmetries}\cr

$A$ & 1 & 1 & 1 & 1 & $x,R_z$ & $x^2+y^2,z^2$\cr
$B$ & 1 & $-1$ & 1 & $-1$ & & $x^2-y^2,xy$\cr
$E_1$ & 1 & $i$ & $-1$ & $-i$ & $(x,y)(R_x,R_y)$ & $(yz,xz)$\cr
$E_2$ & 1 & $-i$ & $-1$ & $i$ & $(x,y)(R_x,R_y)$ & $(yz,xz)$\cr
\hline
\end{tabular}
\end{table}

Using (33), we have
\begin{eqnarray}
a_A &=& {1 \over 4} \left[ 2 \cdot 1 + 0 \cdot 1 + 2 \cdot 1 + 0 \cdot 
1 \right] = 1\cr
a_B &=& {1 \over 4} \left[ 2 \cdot 1 + 0 \cdot (-1) + 2 \cdot 1 + 0 
\cdot (-1) \right] = 1\cr
a_{E_1} &=& {1 \over 4} \left[ 2 \cdot 1 + 0 \cdot i + 2 \cdot (-1) + 
0 \cdot (-i) \right] = 0\cr
a_{E_2} &=& {1 \over 4} \left[ 2 \cdot 1 + 0 \cdot (-i) + 2 \cdot 
(-1) + 0 \cdot i \right] = 0
\end{eqnarray}
so that the representation $\Lambda$ afforded by $x^2$ and $y^2$ is 
reducible and the reduction is $\Lambda = A \oplus B$.  This is 
exactly what we found earlier, where we transformed $x^2$ and $y^2$ 
to $x^2 = y^2$ and $x^2 - y^2$, which are bases for the $A$ and $B$ 
irreducible representations.

\section{Decomposition of Representations}

In Section 16.4 we showed that the eigenfunctions of the Hamiltonian 
are symmetry functions for the symmetry group of $H$.  In this section, 
we will illustrate the use of group theory to obtain information about 
these wavefunctions. See Appendix 16.13.4 for the character tables of common 
point groups.

As we saw in Section 16.4, any set of functions $\{ \chi_i \}$ that 
transform among themselves under the operation of a group, forms a 
basis for a representation $\{ D= (R)\}$ of the group.  We often need 
to know if this representation is reducible, and if so, which 
symmetries are contained in it.  The key relations is
\begin{equation}
a_{\mu} = {1 \over g} \sum_{i} g_i \chi_i^{* (\mu)} \chi_i , 
\label{chap16-eqno34}
\end{equation}
where $\chi_i$ is the character of the given representation for class 
$i$, $\chi_i^{*(\mu)}$ is the complex conjugate of the character for 
the $\mu$ irreducible representation of class $i$, $g_i$ is the 
number of elements in class $i$ and $g$ is the number of elements of 
the group. Equation (34) says that the $\mu$ irreducible representation 
occurs $a_{\mu}$ times in the original representation $\{ D = (R)\}$.  
We will illustrate the use of (34) with several common examples.

\subsection{Reduction of Atomic to Molecular Symmetries}

Since the molecular symmetry group is a subgroup of the symmetry group 
of an atom, a basis for any irreducible representation of an atom is a 
basis for a representation, usually reducible, of the symmetry group 
for the molecule.  In many applications, we want to know which 
molecular symmetries result from these atomic functions.

\subsubsection{ $d$ Functions in C$_{3v}$}

As a prototype of this type of problem, we will consider a single 
$d$-electron on a atom, say $V^{++++}$, with the atom in an external 
field of symmetry {\bf C}$_{3v}$.

The five $d$ states are degenerate for the atom, and have the form
\begin{eqnarray}
\psi_2 &=& f(r)Y_{22} = {1 \over 2} cf(r) \sin^2 \theta e^{+2i\phi}\cr
\psi_{\bar{2}} &=& f(r)Y_{2{\bar{2}}} = {1 \over 2} cf(r) 
\sin^2 \theta e^{-2i\phi}\cr
\psi_1 &=& f(r)Y_{21} = cf(r) \sin \theta \cos \theta e^{i\phi}\cr
\psi_{\bar{1}} &=& f(r)Y_{2{\bar{1}}} = cf (r) \sin \theta \cos e^{-i\phi}\cr
\psi_0 &=& f(r)Y_{20} = cf(r) \sqrt{{2 \over 5}} \left( 3 \cos^2 
\theta - 1 \right)
\label{chap16-eqno35}
\end{eqnarray}

An equivalent set of real function is
\begin{eqnarray}
Z^c_{22} &=& {cf(r) \over r^2} {1 \over \sqrt{2}} \left( x^2 - y^2 
\right)\cr
Z^s_{22} &=& {cf(r) \over r^2} \sqrt{2} xy\cr
Z^c_{21} &=& {cf(r) \over r^2} {\sqrt{2}} zx\cr
Z^s_{22} &=& {cf(r) \over r^2} {\sqrt{2}} zy\cr
Z^c_{20} &=& {cf(r) \over r^2} {\sqrt{2 \over 3}} \left( 2z^2 - x^2 - 
y^2 \right)
\label{chap16-eqno36}
\end{eqnarray}

First we must find the character for the 5 by 5 representation 
generated by (35) or (36).  Under a rotation by an angle $\alpha$, 
the functions in (35) transform as $R_{\alpha} \psi_m ( r, \theta , 
\phi ) = \psi_m ( r , \theta , \phi - \alpha ) = e^{im\alpha} \phi_m 
(r , \theta , \phi )$, see Appendix 16.13.2.  Thus, the matrix 
representation $R_{\alpha}$ is
\begin{equation}
D \left( R_{\alpha} \right) = 
\pmatrix{e^{-2\alpha}\cr
& e^{2\alpha} & & 0\cr
& & e^{-\alpha}\cr
& 0 & & e^{\alpha}\cr
& & & & 1\cr}
\end{equation}
and the character is
\begin{equation}
\chi ( \alpha ) = e^{+2i\alpha} + e^{-2i\alpha} + e^{i \alpha} + 
e^{-i \alpha} + 1 = 1 + 2 \cos \alpha + 2 \cos 2 \alpha = {\sin {5 
\over 2} \alpha \over \sin {\alpha \over 2}}
\label{chap16-eqno37}
\end{equation}
Consequently, $\chi(e) = 5$, and $\chi(C_3) = \chi(C_2^{-1}) = -1$.  
Now consider the mirror plane $\sigma_{xz}$ passing through the 
$x$-axis.  $\sigma_{xz}$ changes the sign of $\phi$, $\sigma_{xz} 
\phi_2 = \psi_{\bar 2}$, $\sigma_{xz} \phi_1 = \psi_{\bar 1}$, and 
$\sigma_{xz} \phi_0 = \psi_0$.  Thus, the representation matrix is
\begin{equation}
D \left( \sigma_{xz} \right) = 
\pmatrix{0 & 1 & 0 & 0 & 0\cr
1 & 0 & 0 & 0 & 0\cr
0 & 0 & 0 & 1 & 0\cr
0 & 0 & 1 & 0 & 0\cr
0 & 0 & 0 & 0 & 1\cr}
\end{equation}
and the character is $\chi(\sigma_{xz}) = 1$.  Since $\chi(\alpha)$ 
is the same for all three $\sigma$, we need only consider one of 
them.  We chose to use $\sigma_{xz}$, since the transformation matrix 
$D(\sigma)$ is easiest to construct for this case.

The relevant characters for applying (34) are shown in Table
\ref{chap16-tab3}, and (34) leads to $a_{A_1} = 1$, $a_{A_2} = 0$, and
$a_E + 2$.  Therefore, in {\bf C}$_{3v}$ the five-fold degenerate $d$
state of $V^{++++}$ becomes split into three different states as in
Figure \ref{chap16-fig32}.

\begin{table}
\caption{Character table for {\bf C}$_{3v}$.}
\label{chap16-tab3}
\begin{tabular}{ccccc}\\ \hline

{\bf C}$_{3v}$ & $e$ & $2C_3$ & $3\sigma$ & $a_{\mu}$\cr

$\chi$ & 5 & $-1$ & $+1$\cr
$A_1$ & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & $-1$ & 0\cr
$E$ & 2 & $-1$ & 0 & 2\cr
\hline
\end{tabular}
\end{table}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig32}
\end{figure}

Combining the original functions (35) or (36), we get bases for the 
irreducible representation of {\bf C}$_{3v}$ as follows
\begin{equation}
A_1 = \phi_0 ~{\rm or} ~ f(r) (2z^2 - x^2 - y^2)
\label{chap16-eqno38a}
\end{equation}
\begin{equation}
E = \left\{ {1 \over \sqrt{2}} \left( \psi_2 + \psi_{\bar{2}} \right) , 
{1 \over \sqrt{2}} \left( \psi_2 - \psi_{\bar{2}} \right) \right\} ~ {\rm or} ~ 
\left\{ {1 \over 2} \left( x^2 - y^2 \right) , xy \right\}
\label{chap16-eqno38b}
\end{equation}
\begin{equation}
E = \left\{ {1 \over \sqrt{2}} \left( \psi_1 + \psi_{\bar{1}} \right) , 
{1 \over \sqrt{2}} \left( \psi_1 - \psi_{\bar{1}} \right) \right\} ~ {\rm 
or} ~ \left\{ xz , yz \right\}
\label{chap16-eqno38c}
\end{equation}
Since there are two set of $E$ functions, the wavefunctions in (38b) 
and (38c) may be mixed in the eigenstates of {\bf C}$_{3v}$ symmetry.

\subsubsection{ $d$ Functions in O$_h$ Symmetry}

Now consider the same atom in a field of octahedral or cubic 
cymmetry, {\bf O}$_h$.  First we consider the subgroup {\bf O} 
containing only proper rotations, with no inversion or reflections.  
In (37) we found the general formula for the character of a rotation 
about the $z$ axis.  In {\bf O}, however, there are several rotation 
axes, only one of which can be the $z$ axis.  Fortunately, we do not 
have to re-derive a corresponding equation for every possible 
rotation axis.  Since the $d$ functions form a representation of the 
full rotation group, O(3), the character of this representation is 
invariant under any rotation.  That is, the character depends only 
upon the rotation angle $\alpha$, and is independent of the 
orientation of the axis.  This need not be true if one includes only a 
subset of the five $d$ functions.  Thus, using (37), we obtain
\begin{eqnarray}
\chi \left( C_3 \right) = -1\cr
\chi \left( C_2 \right) = + 1\cr
\chi \left( C_4 \right) = -1
\label{chap16-eqno39}
\end{eqnarray}
for the $d$ functions, (35).  The relevant characters for applying
(39) are in Table \ref{chap16-tab4}, and (34) leads to the $a_{\mu}$
in that table.

Since the $d$ functions are all invariant, $g$, under inversion, the
decomposition of the $D$ state of {\bf O}$_h$ symmetry leads to $E_g +
T_{2g}$ as indicated in Figure \ref{chap16-fig33}.

\begin{table}
\caption{Character table for {\bf O}.}
\label{chap16-tab4}
\begin{tabular}{ccccccc}\\ \hline
{\bf O} & $e$ & $8C_3$ & $3C^2_4$ & $6C_4$ & $6C_2$ & $a_{\mu}$\cr

$\chi$ & 5 & $-1$ & $+1$ & $-1$ & $+2$\cr
$A_1$ & 1 & 1 & 1 & 1 & 1 & 0\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$ & 0\cr
$E$ & 1 & $-1$ & 2 & 0 & 0 & 1\cr
$T_1$ &  3 & 0 & $-1$ & 1 & $-1$ & 0\cr
$T_2$ & 3 & 0 & $-1$ & $-1$ & 1 & 1\cr
\hline
\end{tabular}
\end{table}


\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig33}
\end{figure}

Recombining the functions of (35), or (36), we find that $\{ xy, yz, 
zx \}$ forms a basis for $T_{2g}$, while
\begin{equation}
\left\{ {1 \over 2} \left( x^2 - y^2 \right) , {1 \over \sqrt{3}} \left(  
z^2 - x^2 - y^2 \right) \right\}
\end{equation}
forms a basis for $E_g$.

\subsubsection{The General Case}

For reduction of other atomic symmetries $\ell$, the general formula 
for a proper rotation $R_{\alpha}$ is obtained by replacing (37) by 
the correct expression for $\ell$.  The result is
\begin{equation}
\chi_{\ell} \left( R_{\alpha} \right) = \sum_{m=-\ell}^{\ell} 
e^{im\alpha} = 1 + 2 \cos \alpha + 2 \cos 2 \alpha + \cdots + 2 \cos 
\ell \alpha.
\label{chap16-eqno40}
\end{equation}
Rewriting $\chi_{\ell} ( R_{\alpha} )$ as
\begin{equation}
\chi_{\ell} \left( R_{\alpha} \right) = e^{-i \ell \alpha} \sum^{2 
\ell}_{m=0} e^{- \alpha m} = e^{- i \ell \alpha} \sum^{2 \ell}_{m=0} 
\left( e^{i \alpha} \right)^m
\end{equation}
we note, the summation is just a geometric progression.  Since
\begin{equation}
1 + r + r^2 + \cdots r^n = {1 - r^{n+1} \over 1 - r},
\end{equation}
we can rewrite (40) as
\begin{equation}
\chi_{\ell} \left( R_{\alpha} \right) = e^{- i \ell \alpha} {1 - 
e^{i(2\ell+1)\alpha} \over 1 - e^{i \alpha}} = {e^{-i \ell \alpha} - 
e^{i(\ell+1)\alpha} \over 1 - e^{i \alpha}}
\end{equation}
Multiplying numerator and denominator by $e^{-i\alpha/2}$ gives
\begin{equation}
\chi_{\ell} \left( R_{\alpha} \right) = {e^{-i(\ell+{1 \over 
2})\alpha} - e^{i (\ell + {1 \over 2} )\alpha} \over e^{-i{\alpha 
\over 2}} - e^{i{\alpha \over 2}}}
\end{equation}
or
\begin{equation}
\chi_{\ell} \left( R_{\alpha} \right) = {\sin \left( \ell + {1 \over 
2} \right) \alpha \over \sin {\alpha \over 2}}
\label{chap16-eqno41}
\end{equation}
Despite the elegance of (41), (40) is generally simpler for small 
$\ell$.

Important special cases for (41) are
\begin{equation}
\chi_{\ell} \left( C_2 \right) = {\sin \left( \ell + {1 \over 
2} \right) \pi \over \sin {\pi \over 2}} = \left( - 1 \right)^{\ell}
\end{equation}
\begin{equation}
\chi_{\ell} \left( C_3 \right) = {\sin \left( \ell + {1 \over 
2} \right) {2 \pi \over 3} \over \sin{\pi \over 3}} = \cases{+1 ~ {\rm 
for} ~ \ell = 0 , 3 , 6 , \cdots\cr
~ 0 ~ {\rm for} ~ \ell = 1 , 4 , 7, \cdots\cr
-1 ~ {\rm for} ~ \ell = 2 , 5 , \cdots\cr}
\end{equation}
\begin{equation}
\chi_{\ell} \left( C_4 \right) = {\sin \left( \ell + {1 \over 
2} \right) {\pi \over 2} \over \sin {\pi \over 4}} = \cases{ +1 ~ {\rm 
for} ~ \ell = 1 , 7,13,\cdots\cr
+1 ~ {\rm for} ~ \ell = 0,1,4,5,\cdots\cr
-1 ~ {\rm for} ~ \ell = 2,3,6,7,\cdots\cr}
\end{equation}
\begin{equation}
\chi_{\ell} \left( C_6 \right) = {\sin \left( \ell + {1 \over 
2} \right) {2 \pi \over 6} \over \sin {\pi \over 6}} = \cases{
+2 ~ {\rm for} ~ \ell = 1,7,13,\cdots\cr
+1 ~ {\rm for} ~ \ell = 0,2,6,8,\cdots\cr
-1 ~ {\rm for} ~ \ell = 3,5,9,11,\cdots\cr
-2 ~ {\rm for} ~ \ell = 4,10,\cdots\cr}
\end{equation}

Next we want general expressions for improper rotations.  Under 
inversion, angular momentum functions transform as $Y_{\ell m} = 
(-1)^{\ell}Y+{\ell m}$.  Thus, $\chi_{\ell}(i) = 
(-1)^{\ell}(2\ell+1)$.  That is, $\chi_{\ell}(i)=1,-3,+5,-7,\cdots$ 
for $\ell = 0,1,2,3,\cdots$.  To obtain $\chi_{\ell}(\sigma)$ for any 
reflection, we note that
\begin{equation}
\sigma = iC_2.
\label{chap16-eqno42}
\end{equation}
Thus, $\chi_{\ell}(\sigma) = (-1)^{\ell} \chi_{\ell}(C_2)$ or 
$\chi_{\ell}(\sigma) = +1$ independent of $\ell$!  The remaining 
operation is the rotary reflection $\sigma_hR_{\alpha}$ which form 
(42) is $iR_{\alpha+\pi}$.  Substituting into (41), leads to
\begin{equation}
\chi_{\ell} \left( \sigma_h R_{\alpha} \right) = \left( -1 
\right)^{\ell} {\cos \left( \ell + {1 \over 2} \right) \alpha \sin 
\left( \ell + {1 \over 2} \right) \pi + \sin \left( \ell + {1 \over 
2} \right) \alpha \cos \left( \ell + {1 \over 2} \right) \pi \over 
\cos {\alpha \over 2} \sin {\pi \over 2} + \sin {\alpha \over 2} 
\cos {\pi \over 2}} = {\cos \left( \ell + {1 \over 2} \right) \alpha 
\over \cos {\alpha \over 2}}.
\end{equation}
Special cases are
\begin{eqnarray}
\chi_{\ell} \left( \sigma_h \right) &=& 1\cr
\chi_{\ell} \left( \sigma_h C_2 \right) &=& \chi_{\ell} (i) = \left( - 
1 \right)^{\ell} \left( 2 \ell + 1 \right)\cr 
\chi_{\ell} \left( S_3 \right) &=& 
\cases{1 ~~ \ell = 0,2,3,4,5,6,\cdots\cr
-1 ~ \ell = 1,4,7,\cdots\cr}\cr
\chi_{\ell} \left( S_4 \right) &=& 
\cases{1 ~~ \ell = 0,3,4,7,8,\cdots\cr
-1 ~~ \ell = 1,2,5,6,\cdots\cr}\cr
\chi_{\ell} \left( S_6 \right) &=& 
\cases{+1 ~~ \ell = 0,5,6,11,\dots\cr
~~0 ~~ \ell = 1,4,7,10,\cdots\cr
-1 ~~ \ell = 1,2,8,9,\cdots\cr}
\end{eqnarray}
The various results of this section are tabulated under O(3) in 
Appendix 16.13.4.

\subsection{Reduction of Molecular Symmetry}

Frequently one starts with a system described by a Hamiltonian $H_0$, 
and a point group $G$.  Then the system is modified in such a way 
that the symmetry is reduced.  The Hamiltonian becomes $H = H_0 + H$, 
and the point group is $G^{\prime}$, a proper subgroup of $G$; i.e., 
$G$ and $G^{\prime}$ are both groups, but all the elements of 
$G^{\prime}$are in $G$, while some elements of $G$ are not in 
$G^{\prime}$.  In general,  the irreducible representations of $G^{\prime}$ 
are either the same or are smaller than those of $G$ and thus, 
degenerate states of $H_0$ may be split for $H$.

The modification of the system signified by $H^{\prime}$ may take on 
various forms.  A low symmetry external field may be turned, or the 
molecule may be substituted in a manner to reduce the symmetry, or 
the molecule may change its geometry through interaction with outside 
forces. A few examples should clarify matters.

Consider the halogenation of benzene
\vskip 1.25truein
\noindent
The electrophilic substitution reduces the symmetry from {\bf
D}$_{6h}$ to {\bf C}$_{2v}$.  We want to know how the various
degenerate benzene orbitals split and what new symmetries the various
states lead to.  From the {\bf D}$_{6h}$ character table we consider
just the characters for the symmetry operations still preserved in
{\bf C}$_{2v}$.  Therefore, we have the results in Table
\ref{chap16-tab5}.

Note, for {\bf D}$_{6h}$ there are three inequivalent $C_2$ axes nd 
three inequivalent $\sigma$ planes.  In such a case, one must be very 
careful to correctly identify which operations are preserved in the 
lower symmetry group.

\begin{table}
\caption{Character table for {\bf D}.}
\label{chap16-tab5}
\begin{tabular}{cccccc}\\ \hline

{\bf D}$_{6h}$ & $e$ & $C_{2x}$ & $\sigma^{\prime}_v(xz)$ & 
$\sigma_h(xy)$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & $A_1$\cr
$A_{2g}$ & 1 & $-1$ & $-1$ & 1 & $B_2$\cr
$B_{1g}$ & 1 & 1 & $-1$ & $-1$ & $A_2$\cr
$B_{2g}$ & 1 & $-1$ & 1 & $-1$ & $B_1$\cr
$E_{1g}$ & 2 & 0 & 0 & $-2$ & $A_2+B_1$\cr
$E_{2g}$ & 2 & 0 & 0 & 2 & $A_1+B_2$\cr
$A_{1u}$ & 1 & 1 & $-1$ & $-1$ & $A_2$\cr
$A_{2u}$ & 1 & $-1$ & 1 & $-1$ & $B_1$\cr
$B_{1u}$ & 1 & 1 & 1 & 1 & $A_1$\cr
$B_{2u}$ & 1 & $-1$ & $-1$ & 1 & $B_2$\cr
$E_{1u}$ & 2 & 0 & 0 & 2 & $A_1+B_2$\cr
$E_{2u}$ & 2 & 0 & 0 & $-2$ & $A_2+B_1$\cr
& $e$ & $C_2$ & $\sigma_v$ & $\sigma^{\prime}_v$ & {\bf C}$_{2v}$\cr

\hline
\end{tabular}
\end{table}

\subsection{Combine Atomic Basis Sets into Molecular Symmetries}

In describing molecular wavefunctions, we generally use a set of 
atomic orbitals centered on each of the nuclei of the system.  For 
equivalent nuclei we use identical basis functions and hence, for 
symmetric molecules, these basis functions can be combined to form 
basis functions of the molecular symmetry group.  We will illustrate 
this with a couple of examples.

\subsubsection{Ozone}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig34}
\end{figure}

Consider $O_3$, in the ground state equilibrium geometry
with the oxygen atom labelled $\ell$, $c$, or $r$ for left, center, 
and right.  The symmetry group is {\bf C}$_{2v} = \{ e , C_{2z} , 
\sigma_v (xz), \sigma_v^{\prime}(yz)\}$.

Earlier in this section, we showed how to determine the molecular
symmetries corresponding to sets of atomic orbitals.  The only new
feature here is that some symmetry operations move the atoms.  Thus,
$\sigma_{xz}$ and $C_{2z}$ interchange atoms $O_{\ell}$ and $O_r$.  In
such cases, there is no diagonal element in the representation matrix
and hence, the basis functions on $O_{\ell}$ or $O_r$ cannot
contribute to $\chi(\sigma_{xz})$ and $\chi(C_{2z})$.  Considering
various atomic symmetries in various centers, leads to the results
shown in Table \ref{chap16-tab6}.  Thus, a minimal basis set composed
of $1s$, $2s$, and $2p$ atomic orbitals on each center, leads to
fifteen basis functions that decompose as $7A_1 + 1A_2 + 2B_1 + 5B_2$.
A set of polarization functions ($d$) on each center leads to fifteen
basis functions decomposing as $5A_1 + 3A_2 + 3B_1 + 4B_2$.

\begin{table}
\caption{}
\label{chap16-tab6}
\begin{tabular}{cccccccccc}\\ \hline

& & $e$ & $C_{2z}$ & $\sigma_v(xz)$ & $\sigma^{\prime}_h(yz)$ & 
$A_1$ & $A_2$ & $B_1$ & $B_2$\cr

$s$ & $O{\ell}$ & 1 & 1 & 1 & 1 & 1 & 0 & 0 & 0\cr
$s$ & $O_{\ell}O_r$ & 2 & 0 & 0 & 2 & 1 & 0 & 0 & 1\cr
$p$ & $O_{\ell}$ & 3 & $-1$ & 1 & 1 & 1 & 0 & 1 & 1\cr
$p$ & $O_{\ell}O_r$ & 6 & 0 & 0 & 2 & 2 & 1 & 1 & 2\cr
$d$ & $O_{\ell}$ & 5 & 1 & 1 & 1 & 2 & 1 & 1 & 1\cr
$d$ & $O_{\ell}O_r$ & 10 & 0 & 0 & 2 & 3 & 2 & 2 & 3\cr
& $A_1$ & 1 & 1 & 1 & 1\cr
& $A_2$ & 1 & 1 & $-1$ & $-1$\cr
& $B_1$ & 1 & $-1$ & 1 & $-1$\cr
& $B_2$ & 1 & $-1$ & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\subsubsection{Ring Ozone}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig35}
\end{figure}

Suppose the bond angle in ozone had been 60 degrees instead of 116.8
degrees.  There is an excited state of ozone that, in fact, has an
equilateral triangle geometry.$^5$ Figure \ref{chap16-fig35}
illustrates $z$ is into the plane.  In this case, the molecular
symmetry group is {\bf D}$_{3h}$.  We need only consider one element
of each class.  Thus, we examine the effect of $e$, $C_{3z}$,
$C_{2x}$, $\sigma_h(xy)$, $S_{3z}$ , and $\sigma_v(xz)$.  Since $C_3$
and $S_3$ take each atom into a different one, there are no diagonal
elements in teh transformation matrix and hence, $\chi(C_3)=\chi(S_3)
= 0$.  The other four operations, $e$, $C_{2x}$, $\sigma_h(xy)$, and
$\sigma_v(xz)$ were also present in $C_{2v}$, where they were denoteds
as $e$, $C_{2z}$, $\sigma_{yz}$, and $\sigma_{xz}$.  Hence, from Table
\ref{chap16-tab6} we obtain Table \ref{chap16-tab7}.  Thus, a minimal
basis set, leads to $3A^{\prime}_1 + A^{\prime}_2 + A^{\prime
\prime}_2 + 4 E^{\prime} = E^{\prime \prime}$, while a set of
polarization functions, leads to $2A^{\prime}_1 + A^{\prime}_2 +
A_1^{\prime \prime} + A_2^{\prime \prime} + 3E^{\prime} + 2 E^{\prime
\prime}$.  A useful result to remember is that the regular
representqion leads to $\chi(e) = g$ with all other $\chi(R) = 0$.
Reducing this representation, leads to $a_{\nu} d^{\nu}$.  That is,
each representation occurs a number of times equal to its degree, as
indicated in the fourth row of Table \ref{chap16-tab7}.  Since the
characters of the $d$ representation are the sum of the character of
the $s$ representation and the character of the regular
representation, we add the $a_{\nu}$ for these latter two
representations to get the $a_{\nu}$ for the $d$ representation.  This
often avoids tedious applications of (34).

\begin{table}
\caption{}
\label{chap16-tab7}
\begin{tabular}{ccccccccccccc}\\ \hline
& $e$ & $2C_3$ & $3C_2$ & $\sigma_h$ & $2S_3$ & $3\sigma_v$ & 
$A^{\prime}_1$ & $A^{\prime}_2$ & $A_1^{\prime\prime}$ & 
$A_2^{\prime\prime}$ & $E^{\prime}$ & $E^{\prime\prime}$\cr

$s$ & 3 & 0 & 1 & 3 & 0 & 1 & 1 & 0 & 0 & 0 & 1 & 0\cr
$p$ & 9 & 0 & $-1$ & 3 & 0 & 1 & 1 & 1 & 0 & 1 & 2 & 1\cr
$d$ & 15 & 0 & 1 & 3 & 0 & 1 & 2 & 1 & 1 & 1 & 3 & 2\cr
RR$^a$ & 12 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 1 & 2 & 2\cr
$A_1$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A_2^{\prime}$ & 1 & 1 & $-1$ & 1 & 1 & $-1$\cr
$A_1^{\prime\prime}$ & 1 & 1 & 1 & $-1$ & $-1$ & $-1$\cr
$A_2^{\prime\prime}$ & 1 & 1 & $-1$ & $-1$ & $-1$ & 1\cr
$E^{\prime}$ & 2 & $-1$ & 0 & 2 & $-1$ & 0\cr
$E^{\prime\prime}$ & 2 & $-1$ & 0 & $-2$ & 1 & 0\cr
\hline
\end{tabular}\\
$^a$ Note, that this row is the regular representation.
\end{table}

\subsection{Molecular Orbitals from Bond Functions}

\subsubsection{Closed Shell Wavefunctions}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig36}
\end{figure}

For many molecules, the electronic wavefunction is invariant under 
all symmetry transformations of the molecule.  That is, the 
wavefunction belongs to the trivial irreducible representation.  In 
many of these cases, the form of the wavefunction is obvious from the 
bonding structure.  Examples include Figure \ref{chap16-fig36}
where $T_d$, $D_{3d}$, and $D_{2h}$ are illustrated above, 
respectively.  For example, the wavefunction of CH$_4$ can be written 
as $A \Psi = A [ \psi_{1s} \psi_{1s} \psi_{b1} \psi_{b1} \psi_{b2} 
\psi_{b2} \psi_{b3} \psi_{3b} \psi_{b4} \psi_{b4} \alpha \beta \cdots 
\alpha \beta ]$.  If $\tau_a$ is any permutation of the orbitals 
with $\alpha$ spin, and $\tau_b$ is any permutation of the orbitals 
with $\beta$ spi, then from the properties of the antisymmetrizer we 
have $A \tau_a \tau_b \Psi = \zeta_{\tau_a} \zeta_{\tau_b} A \Psi$.  
Since $R$ leads to the same permutation of the bond orbitals of a 
$\alpha$ spin and of $\beta$ spin, we have $RA \Psi = ( 
\zeta_{\tau})^2 A \psi = A \psi$.  That is, the many electron 
wavefunction is invariant under all $R \epsilon G$ and hence, the 
electronic wavefunction belongs to the totally symmetric, or trival, 
irreducible representation of $G$.  The same proof applies to ethane 
and ethylene, and to any other molecule where all symmetry operations 
just permute doubly-occupied bond orbitals.

\subsubsection{Molecular Orbitals}

Since the bond orbitals transform into each other under $G$, the set 
of occupied orbitals forms a representation of the group.  By taking 
linear combination of these original orbitals, we can form molecular 
orbitals transforming as symmetry functions of $G$.

Consider CH$_4$.  The basis is $\{ \phi_{1s}, \phi_{b1}, \phi_{b2} ,
\phi_{b3} , \phi_{b4}\}$, a five-dimensional representation.  Since
$C_3$ leaves one bond invariant, $S_4$ and $C_2$ move all bonds, and
$\sigma$ leaves two bonds invariant, we obtain the $\chi(R)$ in Table
\ref{chap16-tab8}, which reduces to $2A_1 + T_2$.  Thus, the $C_{1s}$
orbital leads to $A_1$ symmetry, and the four CH bonds lead to one
$A_1$ molecular orbital and one set of $T_2$ molecular orbitals.

\begin{table}
\caption{}
\label{chap16-tab8}
\begin{tabular}{ccccccc}\\ \hline

{\bf T}$_d$ & $e$ & $8C_3$ & $3C)_2$ & $6S_4$ & $6\sigma$\cr

$C_{1s}$ & 1 & 1 & 1 & 1 & 1 & $\rightarrow A_1~~~~~~$\cr
CH & 4 & 1 & 0 & 0 & 2 & $\rightarrow A_1 + T_2$\cr
$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$\cr
E & 2 & $-1$ & 2 & 0 & 0\cr
$T_1$ & 3 & 0 & $-1$ & 1 & $-1$\cr
$T_2$ & 3 & 0 & $-1$ & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) $A_g$, (b) $B_{1u}$, (c) $B_{2u}$, (d) $B_{3g}$.}
\label{chap16-fig37}
\end{figure}

Similarly, for ethylene, the six bond orbitals and two $C_{1s}$
orbitals lead to an eight-dimensional representation with characters
as shown in Table \ref{chap16-tab9}.  Thus, the eight occupied
molecular orbitals of C$_2$H$_4$ are $3 A_g + B_{3g} + 2B_{1u} +
B_{2u} + B_{3u}$.  For example, the four CH bond orbitals lead to
orbitals of the shapes shown in Figure \ref{chap16-fig37}.

\begin{table}
\caption{}
\label{chap16-tab9}
\begin{tabular}{cccccccccc}\\ \hline

{\bf D}$_{2h}$ & $e$ & $C_{2z}$ & $C_{2y}$ & $C_{2x}$ & $i$ & 
$\sigma_{xy}$ & $\sigma_{xz}$ & $\sigma_{yz}$\cr

$C_{1s}$ & 2 & 2 & 0 & 0 & 0 & 0 & 2 & 2 & $\rightarrow A_g + 
B_{1u}$\cr
CH & 4 & 0 & 0 & 0 & 0 & 0 & 0 & 4 & $\rightarrow A_g , B_{1u} , 
B_{2u} B_{2g}$\cr
CC$\sigma$ & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & $\rightarrow A_g$\cr
CC$\pi$ & 1 & $-1$ & $-1$ & 1 & $-1$ & 1 & 1 & $-1$ & $\rightarrow 
B_{3u}$\cr
$A_g$ & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\cr
$B_{1g}$ & 1 & 1 & $-1$ & $-1$ & 1 & 1 & $-1$ & $-1$\cr
$B_{2g}$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
$B_{3g}$ & 1 & $-1$ & $-1$ & 1 & 1 & $-1$ & $-1$ & 1\cr
$A_u$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & $-1$ & $-1$\cr
$B_{1u}$ & 1 & 1 & $-1$ & $-1$ & $-1$ & $-1$ & 1 & 1\cr
$B_{2u}$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1 & $-1$ & 1\cr
$B_{3u}$ & 1 & $-1$ & $-1$ & 1 & $-1$ & 1 & 1 & $-1$\cr
\hline
\end{tabular}
\end{table}

\subsection{Vibrational Symmetries}

As outline in Section 16-1, the motions of the $Q$ nuclei of a 
molecule are described with the nuclear wavefunction
\begin{equation}
\Psi^{nuclear} \left( {\rm{\bf R}}_1 , {\rm{\bf R}}_2 , \cdots , 
{\rm{\bf R}}_Q \right)
\label{chap16-eqno43}
\end{equation}
where
\begin{equation}
\left( T^n + V^{nn} + E^{e\ell} \right) \Psi^{nuclear} = E 
\Psi^{nuclear}
\label{chap16-eqno44}
\end{equation}
and each {\bf R}$_i$ is the position vector of the $i$th nucleus.  As 
discussed in Chapter 7, the translation of the center of mass and 
rigid body rotation of the molecule can be separated out so that (43) 
and (44) describe just the $3Q-6$ or $3Q-5$, for a linear molecule 
vibrational coordinate.  Even so, it is convenient to describe the 
vibrational wavefunction using all $3Q$ coordinates as in (43).  
In this case, there are six, or five for a linear molecule, redundant 
coordinates corresponding to translation and rotation.  Each of these 
will lead to a vibrational frequency of zero.

\subsubsection{The Representation}

We will denote the equilibrium coordinate of the $i$th nucleus as {\bf 
A}$_i$, and the displacement as
\begin{equation}
{\bf{\rm q}}_i = {\bf{\rm R}}_i - {\bf{\rm a}}_i ; i = 1 , 2 , 
\cdots , Q.
\label{chap16-eqno45}
\end{equation}
Since each of these $Q$ displacements has three components, (45) can 
be written as $q_{ik} = R_{ik} - a_{ik}$, where $k = 1,2,3$ indicates 
the component of the $i$th particle.  The pair of indices $ik$ will 
generally be replaced by a single index $j$ having $3Q$ possible values
\begin{equation}
q_j = R_j - a_j ; j = 1 , 2, \cdots , 3Q.
\label{chap16-eqno46} 
\end{equation}
distinction between the case (45) where $i$ refers to the 
displacement vector for a nucleus and case (46) where $j$ refers to a 
component for a matrix displacement, is the presence or absence, 
respectively, of a bold $q$.

Using (45) the nuclear wavefunction of (43) can be expanded in a 
Taylor series about the equilibrium positions as
\begin{equation}
\Psi^{nuclear} \left( {\bf{\rm R}}_1 , {\bf{\rm R}}_2 , \cdots , {\bf{\rm 
R}}_Q \right) = \Psi_0 + \sum^{3Q}_{j=1} q_j \Psi_j + 
\sum^{3Q}_{j,k=1} {1 \over 2} q_j q_k \Psi_{jk} \cdots
\label{chap16-eqno47}
\end{equation}
where
\begin{eqnarray}
\Psi_0 & \equiv& \Psi^{nuclear} \left( {\bf{\rm a}}_1, {\bf{\rm a}}_2 , 
\cdots , {\bf{\rm a}}_0 \right)\cr
\Psi_j & \equiv& {\partial \Psi^{nuclear} \over \partial R_j}\cr
\Psi_{jk} & \equiv & {\partial^2 \Psi^{nuclear} \over \partial R_j 
\partial R_k}.
\end{eqnarray}
Keeping only the first order terms in (47),
\begin{equation}
\Psi^{nuclear} = \Psi_0 + \sum^{3Q}_{j=1} q_j \Psi_j,
\label{chap16-eqno48}
\end{equation}
leads to a harmonic approximation, in which we retain terms in the 
energy only through second order in the displacement coordinate.  
This approximation is used throughout the course so that (48) will be 
considered as the general vibrational wavefunction.

The symmetry group $G$ of a molecule is defined in terms of the 
equilibrium coordinates $\{ {\bf{\rm a}}_i \}$.  More precisely, 
an ${\hat{R}}\epsilon G$ must take the equilibrium vector {\bf a}$_i$ 
for each nucleus into the equilibrium vector {\bf a}$_j$ for an 
equivalent nucleus,
\begin{equation}
{\hat{R}} {\bf{\rm a}}_i = {\bf{\rm a}}_j.
\label{chap16-eqno49}
\end{equation}
From the beginning of this chapter, the charges of the two nuclei 
must also be equal, in order that $E^{e\ell}$ and $V^{nn}$ be 
invariant.  Also, the nuclear masses must be equal in order that $T^n$ 
be invariant.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig38}
\end{figure}

For a general set of displacements $\{q_i\}$, there will usually be no
symmetry left, as illustrated in Figure \ref{chap16-fig38}.  Starting
with $D_{3h}$ symmetry, a general set of displacements leads to {\bf
C}$_1$, no symmetry.  Up and down in the figure indicates motion out
of the plane.  That is, in general ${\hat{R}}( {\bf{\rm a}}_i +
{\bf{\rm q}}_i) \not= ( {\bf{\rm a}}_j + {\bf{\rm q}}_j)$ even though
(49) is satisfied.  Even so, symmetry can be a big help to us.  For
example, the displacements in Figure \ref{chap16-fig39} must all have
an equivalent effect on the energy.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig39}
\end{figure}

First, we notice that a symmetry element $\hat{R}$ takes a general
displacement $q_i$ on center $i$ into a transformed displacement
$\-{q}_j$ on center $j$, as indicated in Figure \ref{chap16-fig40},
$\hat{R}(a_i + q_i ) = a_{j + \-{q}_j}$, where
\begin{equation}
{\bf{\- q}}_j = R {\bf q}_i
\label{chap16-eqno50}
\end{equation}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig40}
\end{figure}

Defining the orthogonal displacement vectors {\bf e}$_{ix}$, {\bf 
e}$_{ij}$, {\bf e}$_{iz}$, for each atom, we obtain a set of $3Q$ 
displacement vectors 
\begin{equation}
\left\{ {\bf e}_{ix} , {\bf e}_{iy} {\bf e}_{iz} ; i = 1 , \cdots , Q 
\right\} = \left\{ {\bf e}_j ; j = 1 , \cdots , 3 Q \right\}
\label{chap16-eqno51}
\end{equation}
in terms of which any displacement can be described.  From (50) we 
see that any symmetry operation $R \epsilon G$ takes each vector in 
(51) into a linear combination of vectors in (51).  Thus, the $3Q$ 
vectors in (51) form a representation of $G$.  By reducing the 
representation of $G$ into irreducible representations, we can 
determine the vibrational symmetries, and degeneracies, for each 
molecule.

Strictly speaking, the proper procedure in developing this result is 
to apply $\hat{R}$ to $\Psi^{nuclear}$ in (48).  Since $\hat{R}$ 
permutes equivalent nuclei, and since the nuclei have no internal 
structure, we have $\hat{R} \Psi_0 = \Psi_0$.  Thus, since (48) is 
linear in the displacement coordinates, we obtain 
\begin{equation}
R \Psi^{nuclear} = \Psi_0 + \sum^{3Q}_{j=1} {\- q}_j \Psi_j
\end{equation}
where the ${\-{q}}_j$ are the transformed displacements.  Thus, we 
conclude that the set of $3Q$ displacement vectors $\{ \Psi_j \}$ 
for a basis form a representation of $G$.  This simple result is a 
consequence of using (48), rather than (47), in which the nuclear 
wavefunction is linear in the displacements.

In fact, nuclei often do have internal structure, resulting in 
properties such as nuclear spin and nuclear quadrupole moments.  
Because of the nuclear spin, the permuted wavefunction $\hat{R}\Psi$ 
may not equal $\Psi_0$, and indeed, there may be restrictions 
resulting from the Pauli principle applied to the nuclei. There are 
occasionally important macroscopic consequences arising from such 
considerations; however, we ignore them here.

\subsubsection{Applications}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig41}
\end{figure}

Consider the BH$_3$ molecule, having $D_{3h}$ symmetry.  The
displacement coordinates are indicated in Figure \ref{chap16-fig41}.
The displacements and the plane are omitted in Figure
\ref{chap16-fig41}.

Since we only want characters for the representation (51), we can use
any orientation of the displacement axis on each center as illustrated
in Figure \ref{chap16-fig41}.  There is no need for these local
coordinate systems to be related to each other. However, astute
choices, such as in Figure \ref{chap16-fig41}(b), can simplify
identification of the character of various modes.

The $3Q$-dimensional representation (51) leads to diagonal components 
only for those centers $i$ that are left invariant by this 
transformation.  Thus, in calculating $\chi({\hat R})$, we need only 
consider those centers that go into themselves under $\hat R$.  Of 
course, $\hat{R}$ may lead to a rotation or reflection among the 
components
\begin{equation}
\left( e_{ix} , e_{iy} , e_{iz} \right)
\label{chap16-eqno52}
\end{equation}
on center $i$.  For rotations and other point operations leaving 
center $i$ unchanged, the functions (52) transform in the same way 
as $p$ functions, $(p_x, p_y , p_z)$ on that center.  Thus, the 
$\chi(\ell)$ for (52) are given by the equation $\chi(R)$ for $\ell = 
1$ in the O(3) table of Appendix 16.13.4.  After reducing the 
$3Q$-dimensional representation (51), we separately consider the 
symmetries of the three translational coordinates, denoted as $x$, 
$y$, $z$ in Appendix 16.13.4, and three rotational coordinates, denoted as 
$x_g$, $y_g$, $z_g$ in Appendix 16.13.4, and subtract to obtain the $3Q-6$ 
vibrational coordinates.

For BH$_3$, the result is in Table \ref{chap16-tab10}.  Note that $e$
and $\sigma_v$ leave three H invariant, $C_2$ and $\sigma_v$ leave one
invariant, and $C_3$ and $S_3$ none.  Thus, the twelve displacement
coordinates of BH$_3$ lead to $A^{\prime}_1 + A^{\prime}_2 + 2
A^{\prime \prime}_2 + 3 E^{\prime} + E^{\prime \prime}$.  This
includes, translation $(x,y,z)$ as $A^{\prime \prime}_2 + E^{\prime}$,
and rotation $(z_g , y_g , z_g)$ as $A^{\prime}_2 + E^{\prime
\prime}$.  Thus, the pure vibrational coordinates lead to
$A^{\prime}_1 + A^{\prime \prime}_2 + 2 E^{\prime \prime}$, $3Q-6$ as
expected.

\begin{table}
\caption{}
\label{chap16-tab10}
\begin{tabular}{cccccccc}\\ \hline

{\bf D}$_{3h}$ & $e$ & $2C_3$ & $2C_2$ & $\sigma_h$ & $2S_3$ & 
$3\sigma_v$\cr

B & 3 & 0 & $-1$ & $+1$ & $-2$ & $+1$ & $\rightarrow 
A^{\prime\prime}_2 + E^{\prime}$\cr
H & 9 & 0 & $-1$ & $+3$ & 0 & $+1$ & $\rightarrow A^{\prime}_1 + 
A^{\prime}_2 + A^{\prime\prime}_2 + 2E^{\prime} + E^{\prime\prime}$\cr
$A^{\prime}_1$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A^{\prime}_2$ & 1 & 1 & $-1$ & 1 & 1 & $-1$\cr
$A^{\prime \prime}_1$ & 1 & 1 & 1 & $-1$ & $-1$ & $-1$\cr
$A^{\prime \prime}_2$ & 1 & 1 & $-1$ & $-1$ & $-1$ & 1\cr
$E^{\prime}$ & 2 & $-1$ & 0 & 2 & $-1$ & 0\cr
$E^{\prime \prime}$ & 2 & $-1$ & 0 & $-2$ & 1 & 0\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16-tab11}
\begin{tabular}{cccccccc}\\ \hline

{\bf D}$_{3h}$ & $e$ & $2C_3$ & $2C_2$ & $\sigma_h$ & $2S_3$ & 
$3\sigma_v$\cr

$H_x$ & 3 & 0 & 1 & 3 & 0 & 1 & $\rightarrow A^{\prime}_1 + 
E^{\prime}$\cr
$H_y$ & 3 & 0 & $-1$ & 3 & 0 & $-1$ & $\rightarrow A^{\prime}_2 + 
E^{\prime}$\cr
$H_z$ & 3 & 0 & $-1$ & $-3$ & 0 & 1 & $\rightarrow A^{\prime\prime}_2 + 
2E^{\prime\prime}$\cr
$B$ & 3 & 0 & $-1$ & $+1$ & $-2$ & $+1$ & $\rightarrow A^{\prime\prime}_2 
+ 2E^{\prime}$\cr

\hline
\end{tabular}
\end{table}

Using the coordinate system of Figure \ref{chap16-fig41}(b), we obtain
Table \ref{chap16-tab11}.  Starting with vibrational modes
corresponding to the $A^{\prime}_1 + EE^{\prime}$, $E^{\prime}$, and
$A^{\prime \prime}_2$ cases in Table \ref{chap16-tab11}, and
subtracting vibrational modes corresponding to the $A^{\prime}_2$,
$E^{\prime \prime}$, and $A^{\prime \prime}_2$ cases, so as to remove
translation and rotation, leads to the pure vibrational modes of
Figure \ref{chap16-fig42}.  Since the $E^{\prime}$ representation
appears twice, these modes are not unique.

Consider the CH$_4$ molecule, as shown in Table \ref{chap16-tab12}.
The $\sigma_d$ transformations lave two H's invariant, $C_{2z}$ and
$S_4$ leave none.  In Table \ref{chap16-tab12}, we find $3Q-6 = 9$
vibrational functions of symmetries $A_1 + E + 2T_2$.  The
experimental vibrational frequencies of CH$_4$ are found in Table
\ref{chap16-tab13}.

\begin{table}
\caption{}
\label{chap16-tab12}
\begin{tabular}{ccccccc}\\ \hline

{\bf T}$_+d$ & $e$ & $8C_3$ & $3C_{2z}$ & $6S$ & $6\sigma_d$\cr

C & 3 & 0 & $-1$ & $-1$ & 1 & $\rightarrow T_2$\cr
H & 12 & 0 & 0 & 0 & 2 & $\rightarrow A_1 + E + T_1 + 2T_2$\cr
Trans & & & & & & $T_2$\cr
Rotn & & & & & & $T_1$\cr
$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$E$ & 2 & $-1$ & 2 & 0 & 0\cr
$T_1$ & 3 & 0 & $-1$ & 1 & $-1$\cr
$T_2$ & 3 & 0 & $-1$ & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Experimental vibrational frequencies of CH$_4$.}
\label{chap16-tab13}
\begin{tabular}{ccccc}\\ \hline

CH$_4$ & Symmetry & ${\bar{\nu}}$ & Character & Activity\cr
& & (cm$^{-1}$)\cr

$\nu_1$ & $A_1$ & 2916.5 & CH stretch & R\cr
$\nu_2$ & $E$ & 1533.6 & HCH scissors & R\cr
$\nu_3$ & $T_2$ & 3019.49 & CH stretch & I,R\cr
$\nu_4$ & $T_2$ & 1306.2 & HCH scissors & R\cr
\hline
\end{tabular}
\end{table}


\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig42}
\end{figure}

Consider the C$_2$H$_4$ molecules
\begin{equation}
%missing figure!
\end{equation}
The results are in Tables \ref{chap16-tab14a}--\ref{chap16-tab14b},
leading to $3Q - 6 = 12$ vibrational wavefunctions.  The experimental
vibrational frequencies for ethylene are found in Table
\ref{chap16-tab15}.  In this table, a vibration, denoted as CH$_2$,
can be tought of as a rigid motion of the CH$_2$ group in the fashion
indicated.  The symmetry column in Table \ref{chap16-tab15} is a
strange sequence, due to a switch of the $x$ and $z$ axes from that of
Herzberg to the standard ethylene coordinate system of Mulliken.

\begin{table}
\caption{}
\label{chap16-tab14a}
\begin{tabular}{cccccccc}\\ \hline

{\bf D}$_{2h}$ & $e$ & $C_{2z}$ & $C_{2y}$ & $C_{2x}$ & 
$\sigma_{xy}$ & $\sigma_{xz}$ & $\sigma_{yz}$\cr

C & 6 & $-2$ & 0 & 0 & 0 & 2 & 2\cr
H & 12 & 0 & 0 & 0 & 0 & 0 & 4\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Number of states of each symmetry.}
\label{chap16-tab14b}
\begin{tabular}{ccccccccc}\\ \hline


{\bf D}$_{2h}$ & $A_g$ & $B_{1g}$ & $B_{2g}$ & $B_{3g}$ & $A_u$ & 
$B_{1u}$ & $B_{2u}$ & $B_{3u}$\cr

C & 1 & 0 & 1 & 1 & 0 & 1 & 1 & 1\cr
H & 2 & 1 & 1 & 2 & 1 & 2 & 2 & 1\cr
Trans & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1\cr
Rotn & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0\cr
Vibn & 3 & 0 & 1 & 2 & 1 & 2 & 2 & 1\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Experimental vibrational frequencies for C$_2$H$_4$.}
\label{chap16-tab15}
\begin{tabular}{ccccc}\\ \hline

 & Symmetry & ${\bar{\nu}}$ & Character & Activity\cr
 & & (cm$^{-1}$)\cr

$\nu_1$ & $A_g$ & 3026.4 & CH stretch & R\cr
$\nu_2$ & $A_g$ & 1622.6 & CC stretch & R\cr
$\nu_3$ & $A_g$ & 1342.2 & HCH scissors & R\cr
$\nu_4$ & $A_u$ & 1027 & CH$_2$ out of plane$^{a,b}$ & -\cr
$\nu_5$ & $B_{3g}$ & 3103.5 & CH stretch & R\cr
$\nu_6$ & $B_{3g}$ & 1236 & CH$_2$ in plane$^b$ & R\cr
$\nu_7$ & $B_{3u}$ & 949.2 & CH$_2$ out of plane$^b$ & I\cr
$\nu_8$ & $B_{2g}$ & 950 & CH$_2$ out of plane$^b$ & R\cr
$\nu_9$ & $B_{2u}$ & 3105.3 & CH stretch & I\cr
$\nu_{10}$ & $B_{2u}$ & 810.3 & CH$-2$ in plane$^b$ & I\cr
$\nu_{11}$ & $B_{1u}$ & 2988.7 & CH stretch & I\cr
$\nu_{12}$ & $B_{1u}$ & 1443.5 & HCH scissors & I\cr
\hline
\end{tabular}\\
$^a$ Twist CC.
$^b$ Rigid motion of the CH$_2$ group in the indicated fashion.
\end{table}

\subsubsection{Selection Rules}

As will be discussed in the next section, 16.6, there are selection 
rules on various transitions.  For adsorption and emission of light 
the strong transitions are dipole allowed.  Thus, starting with the 
ground vibrational state, only vibrations of symmetries transforming 
like $x$, $y$, and $z$ can be excited.  Such modes are denoted as $I$ 
to denote infrared active.

In addition to absorption, we can have Raman transitions in which 
incident light has frequency $\nu$, and the scattered light has 
frequency $\nu^{\prime}$ with the difference in  energy going into 
vibrational excitation $\Delta = h \nu - h \nu^{\prime}$.  In this 
case, the transition operators transform as $\{ xx , yy , zz , xy , 
xz , yz \}$.  Modes that can be individually excited by such 
transitions are denoted as $R$ for Raman active.

\subsubsection{Numbering Conventions}

There is a standard convention for numbering the vibrations of a 
molecule.  Within a symmetry, they are numbered sequentially, starting 
with the largest $\nu$ and ending with the smallest.  Different 
symmetries are numbered sequentially, starting with the first 
irreducible representation, the trivial representation, and ending 
with the last, highest-dimensional.  This raises a problem since 
different authors list the irreducible representations in different 
orders. Generally, the convention used by Herzberg$^6$ is to list in 
the sequence A, B, E, T; within these to list by subscript 1, 2; 
within these, to list by prime, double prime, and within these, to 
list by g, u.  This differs in several cases from the list we use 
which is based more on the way of building up the group in terms of 
its generators.

\subsection{Wigner Projection Operators}

In the previous section, we showed how to determine the irreducible 
representations affored by an arbitrary set of functions serving as a 
basis for a representation.  Now we want to find general procedures 
for constructing the symmetry functions that transform according to 
these irreducible repersentations.

\subsubsection{One-Dimensional Representations}

For one-dimensional representations this is very simple.  Consider an 
arbitrary $\theta$, any old crummy function picked up off the street 
or out of the garbage, and form a new function
\begin{equation}
\psi = \sum_{R \epsilon G} a^{\mu}_R \left( {\hat R} \theta \right), 
\label{chap16-eqno53}
\end{equation}
where
\begin{equation}
a^{\mu}_R = \chi^{\mu} \left( R^{-1} \right)
\label{chap16-eqno54}
\end{equation}
is the character corresponding to the $\mu$ irreducible 
representation of $G$.  Equation (53) involves a linear combination of 
the $g$ functions ${\hat R}\theta$, but depending upon the form of 
$\theta$, these functions may not all be different.  Now apply ${\hat 
S} \epsilon G$ to (41)
\begin{equation}
S \psi = \sum_{R \epsilon G} a^{\mu}_R SR \theta = \sum_{R \epsilon 
G} a^{\mu}_R ( T \theta ).
\label{chap16-eqno55}
\end{equation}
where $T = SR$ or $R^{-1} = T^{-1}S$.  From (54)
$a^{\mu}_R = \chi^{\mu}(R^{-1}) = 
\chi^{\mu}(T^{-1}S) = \chi^{\mu}(T^{-1}(S)\psi$ and hence, (55) becomes
\begin{equation}
S \psi = \chi^{\mu} (S) \sum_{T \epsilon G} a^{\mu}_T ( T \theta ) = 
\chi^{\mu} (S) \psi
\end{equation}
using the rearrangement theorem, Appendix 16.13.1.  Thus, if $\psi \not= 
0$, then$\psi$ transforms as the $\mu$ irreducible representation 
regardless of which $\theta$ we started with.  We may consider
\begin{equation}
{\hat P}_{\mu} \equiv {1 \over g} \sum_{R \epsilon G} \chi^{\mu} 
\left( R^{-1} \right) {\hat R} ,
\end{equation}
$g$ is put in so that $P^{\mu}P^{\mu} = P^{\mu}$, as a projection 
operator, called the Wigner projection operator, that upon operating 
on a function $\theta$ projects away all pieces of $\theta$ that do 
not belong to representation $\mu$.  In any case,
\begin{equation}
\psi^{\mu} = P^{\mu} \theta =- {1 \over g} \sum_{R \epsilon G} 
\chi^{\mu} \left( R^{-1} \right) \left( {\hat R} \theta 
\right).
\label{chap16-eqno56}
\end{equation}
Some examples follow.

Consider H$^+_2$ and the symmetry group {\bf C}$_i = \{ e , i \}$.  
The projection operators are
\begin{eqnarray}
P^{A_g} &=& {1 \over 2} \left( e + I \right)\cr
P^{A_u} &=& {1 \over 2} \left( e - I \right)
\end{eqnarray}
and hence, starting with $\theta = \chi_a$, an $s$ orbital on the left 
center, we obtain
\begin{eqnarray}
\psi_{A_g} &=& {1 \over 2} \left( \psi_a + \psi_b \right)\cr
\psi_{A_u} &=& {1 \over 2} \left( \psi_a - \psi_b \right)
\end{eqnarray}
these functions are not normalized.

Consider ozone, Figure \ref{chap16-fig34}.  The projection operators
for {\bf C}$_{2v}$ are
\begin{eqnarray}
P^{A_1} &=& {1 \over 4} \left( e + C_2 + \sigma_v + \sigma^{\prime}_v 
\right)\cr
P^{A_2} &=& {1 \over 4} \left( e + C_2 - \sigma_v - \sigma^{\prime}_v 
\right)\cr
P^{B_1} &=& {1 \over 4} \left( e - C_2 + \sigma_v - \sigma^{\prime}_v 
\right)\cr
P^{B_2} &=& {1 \over 4} \left( e - C_2 - \sigma_v + \sigma^{\prime}_v 
\right)
\end{eqnarray}
Thus, applying these operators to the various atomic orbitals on
O$_{\ell}$ and O$_c$ of Figure \ref{chap16-fig34}, we get
\begin{eqnarray}
P^{A_1}{\rm O}_{\ell pz} &=& {1 \over 2} \left( {\rm O}_{\ell pz} + 
{\rm O}_{rpz} \right)\cr
P^{B_2}{\rm O}_{\ell pz} &=& {1 \over 2} \left( {\rm O}_{\ell pz} - 
{\rm O}_{rpz} \right)\cr
P^{A_1}{\rm O}_{\ell py} &=& {1 \over 2} \left( {\rm O}_{\ell py} -
{\rm O}_{rpy} \right)\cr
P^{B_2}{\rm O}_{\ell py} &=& {1 \over 2} \left( {\rm O}_{\ell py} + 
{\rm O}_{rpy} \right)\cr
P^{B_1}{\rm O}_{\ell px} &=& {1 \over 2} \left( {\rm O}_{\ell px} + 
{\rm O}_{rpx} \right)\cr
P^{A_2}{\rm O}_{\ell px} &=& {1 \over 2} \left( {\rm O}_{\ell px} - 
{\rm O}_{rpx} \right)
\end{eqnarray}
etc.

\subsubsection{Multidimensional Representations}

For an irreducible representation of degree greater than one, 
$d_{\mu} > 1$, we can use (56) to obtain one basis function for the 
irreducible representation.  However, we generally want to obtain a 
full set of $d_{\mu}$ basis functions spanning the irreducible representation.

To do this, consider the Wigner projection operator
\begin{equation}
O^{\mu}_{ij} \equiv {1 \over \gamma_{\mu}} \sum_{R \epsilon G} 
D^{\mu}_{ji} \left( R^{-1} \right) \hat{R}
\end{equation}
where $\gamma_{\mu} = \left( {g / d_{\mu}} \right)$.
Applying $S \epsilon G$, we obtain
\begin{equation}
SO^{\mu}_{ij} = {1 \over \gamma_{\mu}} \sum_{R \epsilon G} 
D^{\mu}_{ji} \underbrace{(R^{-1})}_{T^{-1}S} 
\underbrace{\hat{S}\hat{R}}_{T} = {1 \over \gamma_{\mu}} \sum_{R 
\epsilon G} \sum_m D^{\mu}_{jm} \left( T^{-1} \right) D_{mi}(S) 
\hat{T} = \sum_m O^{\mu}_{mj} D^{\mu}_{mi}(S).
\end{equation}
Thus, the set of operators $\{O^{\mu}_{1j} , O^{\mu}_{2j}, \cdots , 
O^{\mu}_{dj}\}$ transform according to the $\mu$ 
irreducible representation of $G$.  Consequently, given any function 
$\theta$ and defining $\phi^{\mu}_i$ as
\begin{equation}
\phi^{\mu}_i = O^{\mu}_{ij} \theta
\label{chap16-eqno57}
\end{equation}
we find that the set of functions $\{ \phi^{\mu}_i; i = 1 , \cdots , 
d^{\mu}\}$ forms a basis for the $\mu$ irreducible representation, 
assuming that the functions $\phi^{\mu}_i \not= 0$, if one of the 
functions $\phi^{\mu}_i \not= 0$, then all of them are nonzero.  To 
form this basis we need the full representation matrices 
$\{D^{\mu}(R)\}$ not just the characters.

An example would be the representation matrices for the $E$ 
irreducible representation of $C_{3v}$, which are
\begin{eqnarray}
D_e &=& \pmatrix{1 & 0\cr
0 & 1\cr},\cr
D_{C_3} &=& \pmatrix{-{1 \over 2} & -{\sqrt{3} \over 2}\cr
{\sqrt{3} \over 2} & -{1 \over 2}\cr},\cr
D_{C_3^{-1}} &=& \pmatrix{-{1 \over 2} & {\sqrt{3} \over 2}\cr
-{\sqrt{2} \over 2} & - {1 \over 2}\cr},\cr
D_{\sigma_x} &=& \pmatrix{1 & 0\cr
0 & -1\cr},\cr
D_{\sigma^{\prime}} &=& \pmatrix{-{1 \over 2} & -{\sqrt{3} \over 2}\cr
-{\sqrt{3} \over 2} & {1 \over 2}\cr},\cr
D_{\sigma^{\prime \prime}} &=& \pmatrix{-{1 \over 2} & {\sqrt{3} \over 
2}\cr
{\sqrt{3} \over 2} & {1 \over 2}\cr}.
\end{eqnarray}

\vskip 1.25truein

Thus,
\begin{eqnarray}
O_{11} &=& {1 \over 3} \left[ e - {1 \over 2} C_3 - {1 \over 
2}C_3^{-1} + \sigma_x - {1 \over 2} \sigma^{\prime} - {1 \over 2} 
\sigma^{\prime \prime} \right]\cr
O_{21} &=& {\sqrt{3} \over 6} \left[ C_3 - C_3^{-1} - \sigma^{\prime} + 
\sigma^{\prime \prime}\right]\cr
O_{12} &=& {\sqrt{3} \over 6} \left[  - c_3 + C_3^{-1} - 
\sigma^{\prime} + \sigma^{\prime \prime}\right]\cr
O_{22} &=& {1 \over 3} \left[ e - {1 \over 2} C_3 - {1 \over 2} 
C_3^{-1} - \sigma_x + {1 \over 2} \sigma^{\prime} + {1 \over 2} 
\sigma^{\prime \prime}\right]
\end{eqnarray}

Consider the NH$_3$ molecule and let $\theta_1$ be the $1s$ orbital 
on $H_1$, $\theta_2$ be the $1s$ orbital on $H_2$ and $\theta_3$ be 
the $1s$ orbital on H$_3$.
\vskip 1.25truein

Thus,
\begin{eqnarray}
O_{11} \theta_1 &=& {1 \over 3} \left[ \theta_1 - {1 \over 2}
\theta_2 - {1 \over 2} \theta_3 + \theta_1 - {1 \over 2}
\theta_3 - {1 \over 2} \theta_1 \right] = {2 \over 3} \left( 
\theta_1 - {1 \over 2} \theta_2 - {1 \over 2}\theta_3 \right)\cr
O_{21} \theta_1 &=& {\sqrt{3} \over 6} \left[ \theta_2 - \theta_3 - 
\theta_3 + \theta_2 \right] = {\sqrt{3} \over 3} \left( \theta_2 - 
\theta_3 \right)\cr
O_{12} \theta_1 &=& {\sqrt{3} \over 6} \left[ - \theta_2 + \theta_3 - 
\theta_3 + \theta_2 \right] = 0\cr
O_{22} \theta_1 &=& {1 \over 3} \left[ \theta_1 - {1 \over 2}
\theta_2 - {1 \over 2} \theta_3 - \theta_1 + {1 \over 2}
\theta_3 + {1 \over 2} \theta_2 \right] = 0
\end{eqnarray}
This leads to one set of functions
\begin{eqnarray}
\phi_1 &=& O_{11} \theta_1 = {2 \over 3} \left( \theta_1 - {1 \over 
2} \theta_2 - {1 \over 2} \theta_3 \right)\cr
\phi_2 &=& O_{21} \theta_1 = {\sqrt{3} \over 3} \left( \theta_2 - 
\theta_3 \right)
\end{eqnarray}
transforming according to the $E$ irreducible representation of 
$C_{3v}$.

\subsubsection{The Algebra of Wigner Projection Operations}

Next, we want to derive an important relationship
\begin{equation}
O^{\mu}_{ij} O^{\nu}_{k\ell} = \delta^{\mu \nu} \delta_{jk} 
O^{\mu}_{i\ell}.
\label{chap16-eqno58}
\end{equation}
Multiplying two such operators together, we obtain
\begin{equation}
O^{\mu}_{ij} O^{\nu}_{k\ell} = {1 \over \gamma_{\mu}} {1 \over 
\gamma_{\nu}} \sum_{R \epsilon G} \sum_{R \epsilon G}  D^{\mu}_{ji} 
\left( R^{-1} \right) D^{\nu}_{\ell k} \left( S^{-1} \right) 
{\hat{R}} {\hat{S}}.
\end{equation}
Letting $RS = T$ or $S^{-1} = T^{-1}R$, and noting that
\begin{equation}
D^{\nu}_{\ell k} \left( S^{-1} \right) = \sum_m D^{\nu}_{\ell m} 
\left( T^{-1} \right) D^{\nu}_{mk} (R)
\end{equation}
we obtain
\begin{equation}
O^{\mu}_{ij} O^{\nu}_{k\ell} = {1 \over \gamma_{\mu} \gamma_{\nu}} \sum_m
\sum_{T \epsilon G} D^{\nu}_{\ell m} \left( T^{-1} \right) {\hat{T}} 
\sum_{R \epsilon G} D^{\nu}_{j k} \left( R^{-1} \right) D^{\nu}_{mk}(R).
\end{equation}
Using the orthogonality theorem, from Appendix 16.13.1, leads to
\begin{equation}
\sum_{R \epsilon G} D^{\nu}_{m k} (R) D^{\mu}_{ji} \left( R^{-1} 
\right) = \gamma_{\mu} \delta^{\mu \nu} \delta_{jk} \delta_{im}
\end{equation}
and hence,
\begin{equation}
O^{\mu}_{ij} O^{\nu}_{k\ell}  O^{\mu}_{ij} = \delta^{\mu \nu} {1 
\over \gamma_{\nu}} \sum_{T \epsilon G}
D^{\nu}_{\ell i} \left( T^{-1} \right) {\hat{T}} = \delta^{\mu \nu} 
\delta_{jk} O^{\mu}_{i \ell}
\end{equation}

Consider now the overlap of two functions 
$O^{\mu}_{ij} \theta$ and $O^{\nu}_{k \ell} \theta$.
\begin{equation}
\langle O^{\mu}_{ij} \theta | O^{\nu}_{k\ell} \theta \rangle = {1 
\over \gamma_{\mu}} \sum_{R \epsilon G} D^{\nu *}_{ji} (R^{-1}) 
\underbrace{\langle R \theta | O^{\nu}_{k\ell} \theta 
\rangle}_{\langle \theta | R^{-1} O^{\nu}_{k\ell} \theta 
\rangle}
\label{chap16-eqno59}
\end{equation}
If the representation is unitary, $D^{\dag} = D^{-1}$, as is always 
the case for the groups we deal with, then $D^{\mu *}_{ji}(R^{-1}) = 
D^{\mu}_{ij}(R)$ and (59) becomes
\begin{equation}
\langle O^{\mu}_{ij} \theta | O^{\nu}_{k\ell} \theta \rangle = 
{1 \over \gamma_{\mu}} \sum_{S \epsilon G} D^{\nu}_{ji} (S^{-1}) 
\langle \theta | SO^{\nu}_{k\ell} \theta \rangle = \langle \theta | 
O^{\mu}_{ji} O^{\nu}_{k\ell} \theta \rangle = \delta^{\mu \nu} 
\delta_{ik} \langle \theta | O^{\nu}_{j\ell} \theta \rangle ,
\end{equation}
where in the first step we replaced $R^{-1}$ with $S$, and in the third 
step, we used (58).  The functions $O^{\mu}_{ij|} \theta$ having 
different $\mu$ or $i$ are othogonal.  Expanding the final term, we 
obtain
\begin{equation}
\langle \theta | O^{\nu}_{j\ell} \theta \rangle = {1 \over 
\gamma_{\mu}} \sum_{R \epsilon G} R^{\nu}_{\ell j} \left( R^{-1} 
\right) \langle \theta | R \theta \rangle .
\label{chap16-eqno60}
\end{equation}
If the function $\theta$ is sufficiently general, then $\langle 
\theta | R \theta \rangle = \delta_{eR}$ and (60) becomes
\begin{equation}
\langle \theta | O^{\nu}_{j\ell} \theta \rangle = {1 \over 
\gamma_{\mu}} \sum_{R \epsilon G} \delta_{\ell j} - d_{\mu} 
\delta_{\ell j}.
\end{equation}
Thus, for appropriately chosen $\delta$ the functions (57) for 
different $j$ orthogonal.  Hence, we may obtain as many as $d$ sets 
of orthogonal functions, each transforming according to the $\mu$ 
irreducible representation.

\section{Selection Rules}

When we solve for wavefunctions or evaluate properties, integrals of 
the form $\langle \phi_i | {\hat{O}} | \psi_j \rangle$ arise.  For 
example, as shown in Chapter 6, the transition probability for light 
to excite a molecule from the state $\psi_m$ to the state 
$\psi_{\ell}$ is proportional to $M_{\ell m} = | \langle 
\psi_{\ell} | {\bf R} \cdot \lambda | \phi_m \rangle |^2$, where $R$ 
is the sum of coordinate vectors of the electrons {\bf R}$ = 
\sum^N_{i=1}$ {\bf r}$_i$ and $\lambda$ is the polarization, i.e., 
direction of the electric vector, of the electromagnetic field.  We 
will develop here, the group theoretical apparatus for determining 
which transitions are allowed and which are forbidden, the selection 
rules.

\subsection{Invariant Integrals and Orthogonality}

In this section, we derive two useful theorems of symmetry 
functions.  The first is Theorem I, invariant integrals
\begin{equation}
\int d \tau f ( {\bf r} )
\label{chap16-eqno61}
\end{equation}
is necessarily zero if the integrand $f$({\bf r}) does not contain a 
component $f^{A_1}$({\bf r}) that is invariant under all operations 
of the group.  The resulting value of the integral is
\begin{equation}
\int d \tau f ( {\bf r} ) = \int d \tau f^{A_1}({\bf r}).
\end{equation}

Theorem II describes the orthogonality of symmetry functions.  The 
overlap $\langle \phi^{\mu}_i | \theta^{\nu}_j \rangle$ of functions
$\phi^{\mu}_i$ and $\theta^{\nu}_j$, transforming as the i{\it th} 
basis function of irreducible representation $\mu$, and the j{\it th} 
basis function of irreducible representation  $\nu$, is zero if $\mu 
\not= \nu$ or if $i \not= j$.  That is, symmetry functions 
transforming according to different irreducible representations are 
orthogonal and symmetry functions that transform as different 
components of the same irreducible representation  are orthogonal.

Theorem I says that for an irreducible representation $\mu \not= A_1$, 
the function $f^{\mu}(r)$ contains the same amount of positive and 
negative character so that $\int f^{\mu}(r)d \tau = 0$.  Theorem II 
says that any function $\phi^{\mu}_i \theta^{\nu}_j$ has equal amount 
of positive and negative character unles $\mu = \nu$ nd $i = j$.

\subsubsection{Proof of Theorem I}

First we decompose $f$({\bf r}) as a linear combination of functions 
transforming according to the various irreducible representations of 
the group
\begin{equation}
f( {\bf r} ) = \sum_{\mu i} f^{\mu}_i ( {\bf r} ).
\end{equation}
Consider the integral of one of the components
$\int d \tau f^{\mu}_i ( {\bf r} ) = \alpha$,
where $\alpha$ is some number.  Applying an operation ${\hat{R}}$ of 
the symmetry group $G$, leads to
$\alpha = \int d \tau {\hat{R}} f^{\mu}_i ( {\bf r} )$,
since $\alpha$ is a number, and hence, invariant, and the volume 
increment $d \tau$ is invariant under symmetry operations.  Applying 
in turn each element of the group and summing, leads to
$\alpha = \int d \tau {1 \over g} \sum_{R} f^{\mu}_i ( {\bf r} )$,
where
\begin{equation}
{1 \over g} \sum_{R} {\hat{R}} f^{\mu}_i ( {\bf r} ) = {1 \over g} 
\sum_{j} f^{\mu}_i ( {\bf r} ) \sum_{R} D^{\mu}_{ji} (R).
\label{chap16-eqno62}
\end{equation}
Now recall the orthogonality theorem
\begin{equation}
\sum_{R} D^{\mu}_{i\ell} (R) D^{\nu*}_{jm} (R) = {g \over d_{\mu}} 
\delta^{\mu \nu} \delta_{ij} \delta_{\ell m},
\label{chap16-eqno63}
\end{equation}
 $\nu$ be the trivial representation, $\nu = A_1$, (63) becomes
\begin{equation}
\sum_{R} D^{\mu}_{i \ell} = g \delta^{\mu , A_1} \delta_{i1} 
\delta_{\ell 1}
\label{chap16-eqno64}
\end{equation}
Using (64) in (62), leads to
\begin{equation}
{1 \over g} \sum_{R} {\hat{R}} f^{\mu}_i ( {\bf r} ) = \delta^{\mu , 
A_1} f^{A_1} ( {\bf r} )
\end{equation}
and hence, (61) becomes
\begin{equation}
\int d \tau f ( {\bf r} ) = \delta^{\mu , A_1} \int d \tau 
f^{A_1} ( {\bf r} )
\end{equation}
{\it quod erat demonstrandum}.

\subsubsection{Proof of Theorem II}

We will now show that symmetry functions transforming according to 
different irreducible representations are orthogonal.  Consider the 
overlap $\langle \phi^{\mu}_i | \psi^{\nu}_j \rangle = \int 
\phi^{\mu *}_i ( 1 , \cdots , n ) \psi^{\nu}_j ( 1 , \cdots , n ) d^3 
x_1 , \cdots , d^3 x_n$ where $\mu$ and $\nu$ refer to irreducible 
representations of group $G$.  This overlap is some number and 
hence, is invariant under application of any transformation $R 
\epsilon G$.  Thus, $\langle \phi^{\mu}_i | \psi^{\nu}_j \rangle = 
\langle R \phi^{\mu}_i | R \psi^{\nu}_j \rangle$ for all $R \epsilon 
G$.  But
\begin{equation}
\langle R \phi^{\mu}_i | \psi^{\nu}_j \rangle = \sum_{k \ell} D^{\mu 
*}_{ki} (R) D^{\nu}_{\ell j} (R) \langle \phi^{\mu}_k | 
\psi^{\nu}_{\ell} \rangle
\end{equation}
and hence,
\begin{equation}
\langle \phi^{\mu}_i | \psi^{\nu}_j \rangle = {1 \over g} \sum_{R}
\langle R \phi^{\mu}_i | \psi^{\nu}_j \rangle = 
{1 \over g} \sum_{k \ell} \langle \phi^{\mu}_k | \psi^{\nu}_{\ell} \rangle 
\underbrace{\sum_{R} D^{\mu *}_{ki}(R) D^{\nu}_{\ell j}(R)}_{{g \over 
d_{\mu}} \delta^{\mu \nu} \delta_{k \ell} \delta_{ij}}
\end{equation}
where we have used the orthogonality theorem.  Thus,
\begin{equation}
\langle \phi^{\mu}_i | \psi^{\nu}_j \rangle = \delta^{\mu \nu} 
\delta_{ij} {1 \over d_{\mu}} \sum_k \langle \phi^{\mu}_k | 
\psi^{\nu}_k \rangle
\end{equation}
or $\langle \phi^{\mu}_i | \psi^{\nu}_j \rangle = \delta^{\mu \nu} 
\delta_{ij} a^{\mu}$, where $a^{\mu}$ is independent of $i$ and $j$,
{\it quod erat demonstrandum}.

\subsection{The Kornecker Product Representation}

In this section, we define a useful representation, the Kronecker, or 
direct, product representation, and we derive a theorem useful for 
obtaining selection rules.

Consider a set of functions $\{ \phi^{(\mu)}_i\}$ that form a basis 
for the representation $D^{(\mu)}$ of the group $G$, and a set of 
$\{ \psi^{(\nu)}_j\}$ that form a basis for a representation $D^{(\nu)}$ 
of $G$.  Then, the set of $d^{\mu} \times d^{\nu}$ product functions
\begin{equation}
\left\{ \phi^{\mu}_i ( {\bf r} ) \psi^{\nu}_j ( {\bf r}^{\prime} ) 
\right\}
\label{chap16-eqno65}
\end{equation}
also forms a basis for a representation of $G$ referred to as the 
Kronecker product, or direct product representation and denoted as 
$\mu \times \nu$.  Note that coordinate spaces for the functions in 
(65) may be different, as indicated, e.g., {\bf r} could refer to 
electron 1, or {\bf r}$^{\prime}$ to electron 2, or they may be the 
same.  If $\mu = \nu$, we assume that the basis functions are chosen 
in the same way, that is, $\phi^{\mu}_i$ transforms under $R$ the same 
way as $\psi^{\mu}_i$.

The character of this representation is given by $\chi^{( \mu \times 
\nu)} (R) = \chi^{\mu}(R) \chi^{\nu}(R)$.  In general, the Kronecker 
product representation is reducible.

The proof for Theorem III, is the Kornecker product of 
irreducible representations $\mu$ and $\nu$ contains the trivial 
irreducible representation $A_1$ if, and only if, $\mu = \mu * \cdot 
\mu*$ indicates the representation whose characters are the complex 
conjugate of those of $\mu$.  For most groups of interest to us, 
$\mu * = \mu$.  This theorem will be of great value in deriving 
selection rules.

\subsubsection{The Character for the Kornecker Product Representation}

The functions in (65) transform as
\begin{eqnarray}
{\hat{R}} \left( \phi^{(\mu)}_i \psi^{(\nu)}_j \right) &=& \sum_{k} 
\sum_{\ell} \left[ \phi^{(\mu)}_k D^{(\mu)}_{ki} (R) \right] \left[ 
\phi^{(\nu)}_{\ell} D^{(\nu)}_{\ell j} (R) \right]\cr
&=& \sum_{k} 
\sum_{\ell} \phi^{(\mu)}_k \psi^{(\nu)}_{\ell} D^{(\mu)}_{ki} (R) 
D^{(\nu)}_{\ell j} (R)
\end{eqnarray}
Thus, denoting the functions of (65) as $\theta_{ij}$, where $ij$ is 
considered as a single index, we obtain
\begin{equation} 
R
\theta_{ij} = \sum_{k \ell} \theta_{k \ell} D^{\mu \times \nu}_{k 
\ell , ij} ,
\end{equation}
where $D^{(\mu \times \nu)}_{k 
\ell , ij} (R) = D^{\mu}_{ki} (R) D^{(\nu)}_{\ell , ij} (R)$.

The characters of $(\mu \times \nu)$ are given by
\begin{equation}
\chi^{(\mu \times \nu)} (R) = \sum_{ij} D^{(\mu \times \nu)}_{ij,ij} 
(R) = \sum_{i} \sum_{j} D^{(\mu)}_{ii} (R) D^{(\nu)}_{jj} (R) = 
\chi^{(\mu)}(R) \chi^{(\nu)} (R)
\end{equation}
that is, $\chi^{(\mu \times \nu)}(R) = \chi^{\mu}(R) \chi^{\nu}(R)$.

For example, let $\mu = E^{\prime}$ and $\nu = E^{\prime \prime}$ of
{\bf D}$_{3h}$.  Then the basis functions are
$\psi_1^{(\mu)}\psi_1^{(\nu)}$, $\psi_1^{(\mu)}\psi_2^{(\nu)}$,
$\psi_2^{(\mu)}\psi_2^{(\nu)}$, and $\psi_2^{(\mu)}\psi_1^{(\nu)}$,
and the characters are found in Table \ref{chap16-tab16}.  Reducing
the $E^{\prime} \times E^{\prime \prime}$ product representation gives
one $A^{\prime \prime}_1$, one $A^{\prime \prime}_2$, and one
$E^{\prime \prime}$ or $E^{\prime} \times E^{\prime \prime} =
A^{\prime \prime}_1 \oplus A^{\prime \prime}_2 \oplus E^{\prime
\prime}$.  Similary, $E^{\prime} \times E^{\prime} = A^{\prime}_1 +
A^{\prime}_2 + E^{\prime}$.

\begin{table}
\caption{}
\label{chap16-tab16}
\begin{tabular}{cccccccc}\\ \hline

 & $e$ & $2C_3$ & $3C_2$ & $\sigma_h$ & $2S_3$ & $3\sigma_v$\cr

$E^{\prime}$ & 2  & $-1$ & 0 & 2 & $-1$ & 0\cr
$E^{\prime\prime}$ & 2 & $-1$ & 0 & $-2$ & 1 & 0\cr 
$E^{\prime} \times E^{\prime\prime}$ & 4 & 1 & 0 & $-4$ & $-1$ & 0 & 
$\rightarrow A^{\prime\prime}_1 + A^{\prime\prime}_2 + E^{\prime\prime}$\cr
$E^{\prime} \times E^{\prime}$ & 4 & 1 & 0 & 4 & 1 & 0 & 
$A^{\prime}_1 + A^{\prime}_2 + E^{\prime}$\cr
\hline
\end{tabular}
\end{table}

\subsubsection{Proof of Theorem III}

Next we will examine the circumstances under which the product $\mu 
\times \nu$ of irreducible representations $\mu$ and $\nu$ will 
contain the trivial irreducible representation $A_1$.  From the representation 
reduction theorem, the $A_1$ irreducible representation occurs 
$a_{A_1}$ times, where
\begin{equation}
a_{A_1} = {1 \over g} \sum \left[ \chi^{A_1} (R) \right]^* \chi^{(\mu 
\times \nu)} (R) = {1 \over g} \sum_{R} \chi^{\mu}(R) \chi^{\nu} 
(R)
\label{chap16-eqno66}
\end{equation}
using $\chi^{A_1} (R) = 1$.  From the orthogonality theorem on 
characters, (66) becomes $a_{A_1} (R) = \delta^{\mu*,\nu}$.  

It is easy to obtain the wavefunction of $(\mu \times \mu*)$ that 
transforms as $A_1$.  It is just
\begin{equation}
\sum^{d^{\mu}}_{i=1} \phi^{\mu}_i ( {\bf r} ) \psi^{\mu *}_i ( {\bf 
r}^{\prime} ).
\label{chap16-eqno67}
\end{equation}
Note that the coordinate spaces of $\phi$ and $\psi$ need not be the 
same, nor do the functions $\phi_i$ and $\psi_i$ need be the same.  
All that is important is that $\phi_i$ and $\psi_i$ transform in the 
same way under $R$.

Reconsidering Theorem II, we see that it is just a special case of 
Theorem III.  The integral $\langle \phi^{\mu}_i | \psi^{\nu}_j 
\rangle$ must be zero unless the product representation $(\mu * 
\times \nu )$ spanned by
\begin{equation}
\left\{ \phi^{\mu *}_i ( {\bf r} ) \psi^{\nu}_j ( {\bf r} ) \right\}
\label{chap16-eqno68}
\end{equation}
contains the $A_1$ irreducible representation.  Note
that the same spaces are used here.  From Theorem II, this can 
occur if, and only if, $\mu = \nu$.

\subsubsection{Symmetric and Antisymmetric Direct Product 
Representation}

In cases of a Kornecker product representation involving the same 
irreducible representation both times, we can always reduce the product
representation $( \mu \times \mu )$ into a symmetric direct 
product $[ \mu \times \mu ]$, and an antisymmetric direct product 
$\{ \mu * \times \mu \}$.  

The symmetric product $[ \mu \times \mu ]$ contains 1/2 
$d^{\mu}(d^{\mu} + 1)$ functions $\{ \theta^s_{ij} ; i \geq j \}$, 
where $\theta^s_{ii} = \phi^{\mu}_i \psi^{\mu}_i$ and
\begin{equation}
\theta^s_{ij} = {\left(\phi^{\mu}_i \psi^{\mu}_j + \phi^{\mu}_j 
\psi^{\mu}_i\right) \over \sqrt{2}},
\end{equation}
and has a character given by
\begin{equation}
\chi^{[\mu \times \mu]}(R) = {1 \over 2} \left\{ \left[ 
\chi^{\mu}(R) \right]^2 + \chi^{\mu} \left( R^2 \right) 
\right\}
\label{chap16-eqno69}
\end{equation}
The antisymmetric direct product $\{ \mu \times \mu \}$ contains 1/2 
$d^{\mu}(d^{\mu} - 1)$ functions $\{ \theta^a_{ij} ; i > j \}$, where
\begin{equation}
\theta^a_{ij} = {\left(\phi^{\mu}_i \psi^{\mu}_j - \phi^{\mu}_j 
\psi^{\mu}_i\right) \over \sqrt{2}}
\label{chap16-eqno70}
\end{equation}
and leads to a character of
\begin{equation}
\chi^{\{\mu \times \mu\}}(R) = {1 \over 2} \left\{ \left[ 
\chi^{\mu}(R) \right]^2 - \chi^{\mu} \left( R^2 \right) 
\right\}
\label{chap16-eqno71}
\end{equation}
Note that the terms symmetric and antisymmetric used here refer to 
the permutational symmetry of the indices.

For example, the $E^{\prime} \times E^{\prime}$ product for D$_{3h}$
leads to the characters in Table \ref{chap16-tab13}.  The
antisymmetric function is $\phi_x \theta_y - \phi_y \theta_z
\rightarrow A^{\prime}_2$ which is of $A^{\prime}_2$ symmetry, while
the symmetric functions are $\phi_x \theta_x$, $\phi_y \theta_y$, and
$\phi_x \theta_y + \phi_y \theta_x$.  Recombining the symmetric
functions, leads to
\begin{equation}
\phi_x \theta_x + \phi_y \theta_y \rightarrow A^{\prime}_1
\end{equation}
\begin{eqnarray}
\phi_x \theta_x &-& \phi_y \theta_y\cr
\phi_x \theta_y &+& \phi_y \theta_x \rightarrow E^{\prime}
\end{eqnarray}
See Table \ref{chap16-tab17}.

\begin{table}
\caption{}
\label{chap16-tab17}
\begin{tabular}{cccccccc}\\ \hline

{\bf D}$_{3h}$ & $e$ & $2C_3$ & $3C_2$ & $\sigma_h$ & $2S_3$ & $3\sigma_v$\cr

$E^{\prime}$ & 2 & $-1$ & 0 & 2 & $-1$ & 0\cr
$E^{\prime} \times E^{\prime}$ & 4 & 1 & 0 & 4 & 1 & 0 &$\rightarrow 
A^{\prime}_1 + A^{\prime}_2 + E^{\prime}$\cr 
$\{E^{\prime} \times E^{\prime}\}$ & 1 & 1 & $-1$ & 1 & 1 & $-1$ & 
$\rightarrow A^{\prime}_2$\cr
$[E^{\prime} \times  E^{\prime}]$ & 3 & 0 & 1 & 3 & 0 & 1 & 
$\rightarrow A^{\prime}_1 + E^{\prime}$\cr
\hline
\end{tabular}
\end{table}

\subsubsection{Derivation of the Character}

This section discusses the derivation of the character for the 
antisymmetric product representation.  Dropping the $\mu$ 
superscripts, the antisymmetric functions (70) transform as
\begin{eqnarray}
{\hat{R}} \theta^a_{ij} &=& {1 \over \sqrt{2}} \sum_{k \ell} \phi_k 
\psi_{\ell} \left( D_{ki} D_{\ell j} - D_{kj} D_{\ell i} \right)\cr
&=& {1 \over \sqrt{2}} \sum_{k > \ell} \phi_k 
\psi_{\ell} \left( D_{ki} D_{\ell j} - D_{kj} D_{\ell i} \right)
+ {1 \over \sqrt{2}} \sum_{k < \ell} \phi_k 
\psi_{\ell} \left( D_{ki} D_{\ell j} - D_{kj} D_{\ell i} \right)\cr
&=& \sum_{k > \ell} \theta^a_{k \ell} 
\left( D_{ki} D_{\ell j} - D_{kj} D_{\ell i} \right)
\end{eqnarray}
Thus, the representation matrix is
$D^{\{\mu \times \mu\}}_{k \ell , ij} (R) = D_{ki} (R) D_{\ell j} 
(R) - D_{kj} (R) D_{\ell i} (R)$ and the character becomes
\begin{eqnarray}
\chi^{\{\mu \times \mu\}}(R) &=& \sum_{k > \ell} D^{\{\mu \times 
\mu\}}_{k \ell , k \ell}
= \sum_{k > \ell} \left( D_{kk} D_{\ell \ell} - D_{k \ell} D_{\ell 
k} \right)\cr
&=& {1 \over 2} \sum_{k,\ell} \left[ D_{kk} (R) D_{\ell \ell} (R) - 
D_{k \ell} (R) D_{\ell k} (R) \right]
\end{eqnarray}
where the last term is obtained by interchanging dummy indices $k$ 
and $\ell$ in the next to the last term, and averaging, the $k = 
\ell$ terms cancel.  But,
\begin{equation}
\sum_k \sum_{\ell} D_{k \ell} (R) D_{\ell k} (R) = \sum_k D_{kk} 
\left( R^2 \right) = \chi \left( R^2 \right)
\end{equation}
leading to (71).

Since the character of the whole direct product representation is
\begin{equation}
\chi^{\mu \times \mu} (R) = \left[ \chi^{\mu} \left( R \right) 
\right]^2
\label{chap16-eqno72}
\end{equation}
the character of the symmetric direct product representation is 
obtained by subtracting (71) from (72), leading to (69).

\subsection{Selection Rules}

We are now ready for the two basic theorems used in deriving 
selection rules.  For Theorem IV, perturbations, such as ${\hat{O}}$, 
having the full symmetry of the group cannot lead to transitions 
between states of different symmetry.  For Theorem V, if $\mu$, 
$\sigma$, and $\nu$ are irreducible representations of the symmetry 
group, the matrix elements
\begin{equation}
\langle \psi^{\mu}_{\ell} | {\hat{O}}^{\sigma}_p | \theta^{\nu}_m 
\rangle
\label{chap16-eqno73}
\end{equation}
are zero for all $\ell$, $p$, and $m$, unless the direct product 
$\sigma \times \nu$ contains $\mu *$.  Equivalently, we can consider 
$\mu * \times \nu$ first, in which case transitions are forbidden 
unless $\sigma$ is contained in $\mu * \times \nu$.

\subsubsection{Special Case of Theorem V}

Consider the case where $\mu * = \nu$ in (73).  Then the integral 
(73) has the form $\int d \tau \psi^{\nu}_{\ell} ( {\bf r} ) 
O^{\sigma}_p \theta^{\nu}_m ( {\bf r} )$.  Hence, if $O^{\sigma}_p$ is 
a real Hermitian operator, and if the functions are real, then 
$\langle \psi^{\nu}_{\ell} | O^{\sigma}_p | \theta^{\nu}_m \rangle$, 
we would have $\nu \times \nu = A^{\prime}_1 + A^{\prime}_2 + 
E^{\prime}$, and hence, we have that transitions are forbidden for 
operators transforming as $\sigma = A^{\prime \prime}_1$, $A^{\prime 
\prime}_2$, or $E^{\prime}$.  However, since the wavefunction part of 
the matrix element transforms as $[ \nu \times \nu ] = A^{\prime}_1 + 
E^{\prime}$, and hence, transitions are also forbidden for operators 
transforming as $\sigma = A^{\prime}_2$.

\subsubsection{Proof of Theorem IV}

Consider the matrix element $\langle \psi^{\mu}_{\ell} | 
{\hat{O}}^{A_1} | \theta^{\nu}_m \rangle$ where ${\hat{O}}^{A_1}$ 
transforms acording to the $A_1$ irreducible representation of $G$.  
Then ${\hat{R}}$ and ${\hat{O}}$ commute so that
\begin{equation}
{\hat{R}} \left[ {\hat{O}} \theta^{\nu}_m \right] = \sum_{j} \left[ 
{\hat{O}} \theta^{\nu}_j \right] D^{\nu}_{jm} (R).
\end{equation}
Consequently, ${\hat{O}} \theta^{\nu}_m$ transforms according to the  
$\nu$ irreducible representation.  Thus, using Theorem II we obtain 
Theorem IV.

\subsubsection{Proof of Theorem V}

Now we will consider the more general case of (73), $\langle 
\psi^{\mu}_{\ell} | {\hat{O}}^{\sigma}_p | \theta^{\nu}_m \rangle$ 
where $\mu$, $\sigma$, and $\nu$ correspond to
irreducible representations of $G$.   From Theorem I we know that all 
such matrix elements (73) must be zero, unless the 
representation spanned by
\begin{equation}
\left\{ \psi^{\mu *}_{\ell} {\hat{O}}^{\sigma}_p \theta^{\nu}_m; ~ 
{\rm all} ~ \ell , p , m \right\}
\label{chap16-eqno74}
\end{equation}
contains $A_1$.  We can approach this many ways.  For example, taking 
the direct product $\sigma \times \nu$ first, we know from Theorem III 
that (74) contains $A_1$ only if $\sigma \times \nu$ contains $\mu$, 
since only $\mu * \times \mu$ contains $A_1$.  Thus, we obtain Theorem 
V.

\subsection{Applications to Atoms}

The point group of an atom is $O(3)$ which is the direct product of 
the group of proper rotations $SO(3)$ and $C_i$, $O(3) = SO(3) 
\times {\bf C}_i$.  The irreducible representations of $SO(3)$ are 
characterized by an angular momentum with a basis
\begin{equation}
\left\{ Y^{\prime}_{LM} M = - L , - L + 1 , \cdots , + L 
\right\}
\label{chap16-eqno75}
\end{equation}
For $O(3)$ there is one additional symmetry referred to as the parity 
$i \psi = ( - 1)^p \psi$ where the even $p$ indicates $g$ symmetry, 
and odd $p$ indicates $u$ symmetry.  For one-particle functions the 
$p$ and $L$ are related $p = L$, so that the even $L$ are even 
parity, and odd $L$ are odd parity.  However, for many electron 
systems, no such relation holds.  Thus, in general, the atomic 
wavefunctions are characterized as $\psi_{LMp}$.

From the theory of angular momentum, addition of two angualr momenta 
$L$ and $L^{\prime}$ leads to total angular momentum $L^{\prime 
\prime}$ ranging from $L + L^{\prime}$ down to $| L - L^{\prime} |$, 
in integer increments,
\begin{equation}
L^{\prime \prime} = L + L^{\prime} , L + L^{\prime} - 1 , \cdots , | 
L - L^{\prime} |.
\label{chap16-eqno76}
\end{equation}
Thus, if $L = 2$ and $L^{\prime} = 3$, we obtain $L^{\prime \prime} = 
5, 4, 3, 2, 1$.  In terms of group representations, the addition of 
angular momenta $L$ and $L^{\prime}$ corresponds to taking the 
Kornecker product representation $\{ Y_{LM} Y_{L^{\prime}M} ; M = - 
L , \cdots , +L; M^{\prime} = - L^{\prime} , \cdots , + L^{\prime} 
\}$.  The reduction of this product representation then leads to one 
irreducible representation of each integer angular momentum 
satisfying (76).

Under inversion, we have
$i \psi_{LMp} \theta_{L^{\prime}M^{\prime}p^{\prime}} = ( - 1 
)^{p+p^{\prime}} \psi_{LMp} \theta_{L^{\prime}M^{\prime}p^{\prime}}
$ so that the parities add.

\subsubsection{Dipole Transitions}

The matrix elements for dipole transitions are
\begin{equation}
\langle \psi_{LMp} | R_i | \psi_{L^{\prime}M^{\prime}p^{\prime}} 
\rangle
\label{chap16-eqno77}
\end{equation}
where $R_i = x , y$, or $z$.  Thus, the operator in (77) transforms 
as angular momentum 1, with odd parity.  The components of this 
operator may be put in the form (75)
\begin{eqnarray}
R_{10} &=& z\cr
R_{1{\bar{1}}} &=& {(x-iy) \over \sqrt{2}}\cr
R_{11} &=& {-(x + iy) \over \sqrt{2}}
\end{eqnarray}
so that they combine in exactly the same way as $\{Y_{LM}\}$. The 
minus sign on $R_{11}$ is to preserve the usual convention on phases 
of $Y_{LM}$.

For angular momentum states, Theorem I says that an integral is zero 
unless the integrand contains a components with $S_g$ symmetry, $L = 
0 , p = 0$.  Thus, Theorem V says that all matrix elements of 
$\langle \psi_{LMp} | R_i | \psi_{L^{\prime \prime}M^{\prime \prime}
p^{\prime \prime}} \psi_{L^{\prime}M^{\prime}p^{\prime}}
\rangle$ are zero unless $L$ is contained in the addition of 
$L^{\prime}$ and $L^{\prime \prime}$, and unless $p = p^{\prime 
\prime} + p^{\prime}$.  For the dipole operator, the Kornecker product
\begin{equation}
R_{LM} Y_{L^{\prime}M^{\prime}}
\label{chap16-eqno78}
\end{equation}
leads to $L^{\prime \prime} = L^{\prime} + 1 , L^{\prime} , 
L^{\prime} - 1$, and thus, the matrix elements in (77) are zero 
unless $L =  L^{\prime} + 1 , L ,  L^{\prime} - 1$ and $p = 
p^{\prime} + 1$.  That is, the dipole selection rules are
\begin{equation}
\Delta L = 0 , \pm 1
\label{chap16-eqno79a}
\end{equation}
\begin{equation}
\Delta p = 1
\label{chap16-eqno79b}
\end{equation}
Of course, negative $L$ is not allowed.  We made one mistake here.  
If $L^{\prime} = 0$, then the Kronecker product (78) leads to 
$L^{\prime \prime} = 1$, and hence, $\Delta L = 0$ is not allowed.  
Thus, we add to (79), $L = 0 {\not\leftrightarrow} L = 0$.

\subsubsection{Higher Order Transitions}

In Chapter 6, we found that in addition to dipole transitions, there 
are weaker transitions such as electric quadrupole, $Q_{2M}$, where 
the transition operator transforms as $L = 2$ with even parity, and 
magnetic dipole $M_{1M}$, where the transition operator transforms as 
$L = 1$ with even parity.  The corresponding selection rules are, 
first for electric quadrupole, $\Delta L = 0 , \pm 1 , \pm 2$, 
$\Delta = 0$, $L = 0 \not\leftrightarrow L = 0$, and $L = 0 
\not\leftrightarrow L = 1$.  For magnetic dipole, 
\begin{eqnarray}
\Delta L &=& \pm 1\cr
\Delta p &=& 0
\label{chap16-eqno80}
\end{eqnarray}
The $\Delta L \not= 0$ restriction is explained in the following 
sections.

\subsubsection{More on $\Delta L = 0$ Transitions}

Note that transitions between states of the same $L$ and $p$ are 
dipole forbidden, $\psi_{LMp} \not\leftrightarrow 
\psi_{LM^{\prime}p}$, even though $\Delta L = 0$ is allowed by 
addition of angular moment.  However, $\psi_{LM} \not\leftrightarrow 
\psi_{LM^{\prime}}$ is forbidden even for $SO(3)$.  That is, even 
when the inversion is not contained in the group.  The reason for this 
is, the integrand of
\begin{equation}
\langle \psi_{LM} | R_{1M^{\prime \prime}} | 
\psi_{LM^{\prime}} \rangle
\label{chap16-eqno81}
\end{equation}
contains only the symmetric Kornecker product $[L \times L]$.  For 
angular momentum, $[L \times L] \rightarrow 2L, 2L - 2 , \cdots , 0$, 
while $\{L \times L\} \rightarrow 2L - 1 , 2L - 3, \cdots , 1$.  
Thus, since $[L \times L]$ does not contain $L^{\prime} = 1$, the 
matrix element of (81) is zero.

For magnetic dipole transitions, where $\Delta p = 0$, these 
considerations lead to an additional selection rule $\Delta L \not= 
0$, which was included in (80).  However, for electric quadrupole 
transitions $L^{\prime} = 2$ is contained in $[L \times L]$, and there 
is no problem.

\subsection{Application to Linear Molecules}

For a linear molecule, the point group is {\bf C}$_{\infty v}$ or {\bf 
D}$_{\infty h}$.  Considering first {\bf C}$_{\infty v}$, the 
irreducible representations can be denoted as $\Lambda = 0 \Sigma$, 
$1 \pi$, $2 \Delta$, $3 \Phi$, and $4 \Gamma$, etc., where $\Lambda 
\not= 0$ leads to a double degenerate representation.  In one 
representation, we diagonalize the representation matrices for 
rotation, leading to basis functions $\psi_{+\Lambda} = 
e^{+i\Lambda \phi}$ and $\psi_{-\Lambda} = e^{-i\Lambda \phi}$, 
where $\phi$ is the angular coordinate about the rotation axis.  In 
the other important representation, we diagonalize the representation 
matrix for the reflection $\sigma_{xz}$
\begin{eqnarray}
\psi^+_{\Lambda} &=& \cos \Lambda \phi\cr
\psi^-_{\Lambda} &=& \sin \Lambda \phi
\label{chap16-eqno82}
\end{eqnarray}
In the case of $\Lambda = 0$, the symmetry functions are either 
symmetric or antisymmetric under $\sigma_v$, $\Sigma^+ : \psi^+_0$ 
and $\Sigma^- : \psi^-_0$.  We will use the basis (82) for $\Lambda 
\not= 0$ so that all {\bf C}$_{\infty v}$ functions can be denoted 
as $\psi^s_{\Lambda}$, where $s = \pm 1$ and $\Lambda \geq 0$.  For 
$\Lambda > 0$, both $s = +1$ and $s = -1$ are present, but for 
$\Lambda = 0$ only one is.

For {\bf D}$_{\infty h}$, we have in addition the parity $p$, $i 
\psi^s_{\Lambda p} = (- 1)^p \psi^s_{\Lambda p}$.  However, there is 
not special relationship between rotational and inversion symmetry 
for one electron function.

\subsubsection{Kornecker Products}

The Kornecker product is most easily studied by merely constructing 
the basis functions.  Thus, if $\Lambda_1 , \Lambda_2 > 0$, we obtain 
four basis functions
\begin{eqnarray}
\Lambda &=& \Lambda_1 + \Lambda_2 
{\cases{\theta_{\Lambda_1 , \Lambda_2} = 
e^{i\Lambda_1 \phi_1} e^{i\Lambda_2 \phi_2}\cr
\theta_{-\Lambda_1 , - \Lambda_2} = 
e^{-i \Lambda_1 \phi_1} e^{- i \Lambda_2 \phi_2}\cr}}\cr
\Lambda &=& | \Lambda_1 - \Lambda_2 | 
{\cases{\theta_{\Lambda_1 , - \Lambda_2} = e^{i\Lambda_1 \phi_1} 
e^{-i\Lambda_2 \phi_2}\cr
\theta_{-\Lambda_1 , - \Lambda_2} = e^{-i \Lambda_1 \phi_1} 
e^{i \Lambda_2 \phi_2}\cr}}
\end{eqnarray}
Hence, the Kornecker product leads to $\Lambda = \Lambda_1 + 
\Lambda_2$ and $| \Lambda_1 - \Lambda_2 |$.

If $\Lambda_1 = \Lambda_2$, the $\Lambda = 0$ functions must be 
recombined as $\Sigma^+ : \theta_{\Lambda , - \Lambda} + \theta_{- 
\Lambda , \Lambda}$ and $\Sigma^- : \theta_{\Lambda , - \Lambda} - 
\theta_{- \Lambda , \Lambda}$ in order to obtain irreducible 
representations of {\bf C}$_{\infty v}$.  Thus, $\Lambda \times 
\Lambda = 2 \Lambda \oplus \Sigma^+ \oplus \Sigma^-$.  Considering 
the symmetric and anitsymmetric products, we see that $[ \Lambda 
\times \Lambda ] = 2 \Lambda \oplus \Sigma^+$ and $\{ \Lambda \times 
\Lambda \} = \Sigma^-$.  If $\Lambda_2 = 0$, then $\Lambda_1 \times 
\Lambda_2 = \Lambda_1$.  Thus, $\Lambda \times \Sigma^+ = \Lambda$ 
and $\Lambda \times \Sigma^- = \Lambda$.

\subsubsection{Dipole Transitions}

In {\bf C}$_{\infty v}$ and {\bf D}$_{\infty h}$, the dipole operators
$x$, $y$, and $z$ transform as shown in Table \ref{chap16-tab18}.

For parallel transitions ($z$), we see that the selection rules for 
{\bf C}$_{\infty v}$ are $\Delta \Lambda = 0$ and $\Delta s = 0$.  For
{\bf D}$_{\infty h}$  they are $\Delta \Lambda = 0$, $\Delta s = 0$, 
and $\Delta p = 1$.

For perpendicular transitions ($x,y$), we find that for {\bf C}$_{\infty 
v}$  it is $\Delta \Lambda = \pm 1$.  And for {\bf D}$_{\infty h}$, they 
are $\Delta \Lambda = \pm 1$ and $\Delta p = 1$.  Thus, there are not 
dipole transitions between $\Sigma^+$ and $\Sigma^-$.

\begin{table}
\caption{}
\label{chap16-tab18}
\begin{tabular}{cccc}\\ \hline

& {\bf C}$_{\infty v}$ & {\bf D}$_{\infty h}$\cr

$z$ & $\Sigma^+$ & $\Sigma^+_u$ & parallel\cr
$z,y$ & $\Pi$ & $\Pi_u$ & perpendicular\cr

\hline
\end{tabular}
\end{table}

\subsubsection{Higher Transitions}

For linear molecules, the electric quadrupole and magnetic dipole
transitions, have the symmetries as shown in Table \ref{chap16-tab19}.
For $M_{10}$ transitions, the rotational symmetry suggests the
selection rule of $\Delta \Lambda = 0$.  However, if $\Lambda \not=
0$, the wavefunction part of the matrix element, $\langle
\psi^s_{\Lambda} | M_{10} | \psi^{s^{\prime}}_{\Lambda} \rangle$
transforms according to $[ \Lambda \times \Lambda ] = 2 \Lambda \oplus
\Sigma^+$, whereas $M_{10}$ transforms according to $\Sigma^-$, and
hence, $M_{10}$ transitions are forbidden for $\Lambda \not= 0$.  If
$\Lambda = 0$, we can have a transition $\Sigma^+ \leftrightarrow
\Sigma^-$.

\begin{table}
\caption{}
\label{chap16-tab19}
\begin{tabular}{cccccc}\\ \hline

& & &\multicolumn{3}{c}{Selection Rules}\cr
& {\bf C}$_{\infty v}$ & {\bf D}$_{\infty h}$ & $\Delta \Lambda$ & 
$\Delta s^a$ & $\Delta p$\cr

$Q_{22}, Q_{22}$ & $\Delta$ & $\Delta_g$ & 2 & &  0\cr
$Q_{21} , Q_{2{\bar{1}}}$ & $\pi$ & $\pi_g$ & 1 & & 0\cr
$Q_{20}$ & $\Sigma^+$ & $\Sigma^+_g$ & 0 & 0 & 0\cr
$M_{11} , M_{1{\bar{1}}}$ & $\pi$ & $\pi_g$ & 1 & & 0\cr
$M_{10}$ & $\Sigma^-$ & $\Sigma^-_g$ & only & $\Sigma^+ 
\leftrightarrow \Sigma^-$ & allowed\cr
\hline
\end{tabular}\\
$^a$ For $\Sigma \leftrightarrow \Sigma$ transitions.
\end{table}

For example, consider
\begin{equation}
\langle e^{iM\phi} | M_{10} | e^{iM^{\prime}\phi} \rangle = \int d 
\tau_1 d \tau_2 \left\{ e^{-iM\phi} M_{10} e^{i 
M^{\prime}\phi}\right\}
\end{equation}
where $M , M^{\prime} = \pm \Lambda$.  Rotating about the axis by an 
angle $\alpha$, the integrand transforms as 
$e^{i(M-M^{\prime})\alpha}$.  Since the integrand must be invariant, 
we obtain $M = M^{\prime}$, that is, $\Delta M = 0$.  Now consider 
reflection $\sigma_v$ the integrand goes from 
$e^{-M\phi}M_{10}e^{iM\phi}$ to $e^{iM\phi}(-M_{10})e^{-M\phi_1}$ and 
hence, changes sign.  But for the matrix element to be nonzero, the 
integrand must be invariant, or contain a piece that is invariant.  
Thus, no transition is allowed if $M \not= 0$.

\subsection{Applications to Polyatomic Molecules}

The character tables, in Appendix 16.13.4, all have indicates the 
irreducible representations corresponding to dipole operators, $x$, 
$y$, and $z$.  Thus, for {\bf D}$_4$, $z$ transforms as $A_2$, 
parallel, and $x$ and $y$ transforms as $E$, perpendicular.

Since $A_2 \times A_1 = A_2$, $A_2 \times A_2 = A_1$, $A_2 \times 
B_1 = B_2$, $A_2 \times B_2 = B_1$, and $A_2 \times E = E$, the 
selection rules for parallel transitions, $z$, first allowed $A_1 
\leftrightarrow A_2$, $B_1 \leftrightarrow B_2$, and $E 
\leftrightarrow E$, and then the forbidden $A_{1,2} 
\not\leftrightarrow E$, $B_{1,2} \not\leftrightarrow E$, $A_{1,2} 
\not\leftrightarrow B_{1,2}$, $A_i \not\leftrightarrow A_i$, and 
$A_i \not\leftrightarrow B_i$.  Since $E \times A_1 = E$, $E \times 
A_2 = E$, $E \times B_1 = E$, $E \times B_2 = E$, and $E \times E = 
A_1 \oplus A_2 \oplus B_1 \oplus B_2$.  The selection rules for 
perpendicular transitions $x$ and $y$, for the allowed $E 
\leftrightarrow A_1$, $E \leftrightarrow A_2$, $E \leftrightarrow 
B_1$, and $E \leftrightarrow B_2$ and for the forbidden, $A_{1,2} 
\not\leftrightarrow B_{1,2}$, $E \not\leftrightarrow E$, $A_i 
\not\leftrightarrow A_j$, And $B_i \not\leftrightarrow B_j$.  Thus, 
the selection rules are completely different for the two 
polarizations, and neither polarizations allows transitions between 
$A_{1,2} \leftrightarrow B_{1,2}$, $A_i \leftrightarrow A_i$, and 
$B_i \leftrightarrow B_i$. 

\section{The Wigner-Eckart Theorem}

In the previous section, we considered selection rules, that is, the 
conditions under which a matrix element $\langle \phi^{\mu}_i | 
{\hat{O}}^{\sigma}_k | \theta^{\nu}_j \rangle$ is zero.  Now we want 
to consider the nonzero matrix elements and relations between them. 
Throughout most of this section, we will consider atomic states.

\subsection{Atoms}

\subsubsection{The Basis Equations}

The direct product of two angular momenta $L$ snd $L^{\prime}$ can be 
decomposed into terms of angular momenta $L^{\prime \prime}$ as
\begin{equation}
Y_{LM} Y_{L^{\prime}M^{\prime}} = \sum^{L+L^{\prime}}_{L^{\prime 
\prime}=| L- L^{\prime}|} C_{L^{\prime \prime}}Y_{L^{\prime 
\prime},M+M^{\prime}}.
\label{chap16-eqno83}
\end{equation}
The coefficients $C_{L^{\prime \prime}}$ in (83) are referred to as 
the vector coupling coefficients, and depend upon $L, L^{\prime}, 
L^{\prime \prime}, M$ and $M^{\prime}$.  The vector coupling 
coefficients are also referred to a Clebsch-Gordon coefficient, or 
Wigner coefficient.  The terms vector-coupling, or Wigner, are for 
angular momentum functions, Clebsch-Gordon may be used for functions 
of any group. 

To explicitly show this dependence, they are generally written as
\begin{equation}
\left( L^{\prime \prime} , M^{\prime \prime} | L, M ; L^{\prime} , 
M^{\prime} \right).
\label{chap16-eqno84}
\end{equation}
This is, (83) is replaced by
\begin{equation}
Y_{LM} Y_{L^{\prime}M^{\prime}} = \sum_{L^{\prime \prime} , M^{\prime 
\prime}} \left( L^{\prime \prime} | M^{\prime \prime}  LM ; L^{\prime} 
M^{\prime} \right) Y_{L^{\prime \prime} , M^{\prime \prime}}
\label{chap16-eqno85}
\end{equation}
where (84) is zero unless $\delta_{M^{\prime \prime},M+M^{\prime}}$, 
and unless $L^{\prime \prime}$ lies in the range $|L - L^{\prime}|$ 
to $L+L^{\prime}$.

Now consider the functions $F_{\alpha LM} = f_{\alpha L} ( r ) 
Y_{LM} ( \theta , \varphi )$ and $G_{\alpha^{\prime \prime}
L^{\prime \prime} , M^{\prime \prime}} = 
g_{\alpha^{\prime}L^{\prime}}(r) Y_{L^{\prime} , M^{\prime}}(\theta , 
\varphi)$ and some operator $H_{L^{\prime \prime} , M^{\prime}} = 
h(r) Y_{L^{\prime \prime} , M^{\prime \prime}} ( \theta , \varphi )$.  
Then the matrix elements are given by
\begin{equation}
G_{\alpha^{\prime \prime} L^{\prime \prime} , M^{\prime \prime}} | 
H_{L^{\prime}M^{\prime}} | F_{\alpha LM} \rangle = \langle g | h | f 
\rangle_r \left( L^{\prime \prime} M^{\prime \prime}  | 
L^{\prime}M^{\prime} ; LM \right).
\label{chap16-eqno86}
\end{equation}
The result (86) is not limited, however, to one-electron systems, nor 
is it limited to cases of integer $L$, for which the angular momentum 
functions $Y_{LM}$ are the usual spherical harmonics.

We consider a set of $2L+1$ states $| \alpha LM \rangle ; M = L , L - 
1 , \cdots , -L$ and set of $2 L^{\prime \prime} +1$ states $| 
\alpha^{\prime \prime} L^{\prime \prime} M^{\prime \prime} \rangle ; 
M^{\prime \prime} = L^{\prime \prime} ,
L^{\prime \prime} - 1 , \cdots , -L^{\prime \prime}$ and a set of 
$2L^{\prime} + 1$ operators $O_{L^{\prime}M^{\prime}} ; M^{\prime} = 
L^{\prime} , L^{\prime} - 1 , \cdots , -L^{\prime}$ where each set 
transforms under rotation in the same way as the corresponding 
angular momentum functions.  For example, the angular momentum 
functions $O_{11} \equiv -(p_x + ip_y)$, $O_{10} \equiv p_z$, and 
$O_{1{\bar{1}}} = (p_x - ip_y)$ transforms as $L = 1$, whereas the 
kinetic energy operator $O_{00} = (1/2n) (p^2_x + p^2_y + p^2_z)$ 
transform as $L = 0$.  

Then from (85) and (86), we obtain
\begin{equation}
\langle \alpha^{\prime \prime} L^{\prime \prime} , M^{\prime 
\prime} | {\hat{O}}_{L^{\prime}M^{\prime}} | \alpha LM \rangle = 
\langle \alpha^{\prime \prime} | {\hat{O}} | \alpha \rangle \left( 
L^{\prime \prime} , M^{\prime \prime} | L , M ; L^{\prime} , 
M^{\prime} \right)
\label{chap16-eqno87}
\end{equation}
where
\begin{equation}
\langle \alpha^{\prime \prime} | {\hat{O}} | \alpha \rangle
\label{chap16-eqno88}
\end{equation}
is an integral over all coordinates except the angular coordinates, 
and depends explicitly upon $\alpha$, $\alpha^{\prime \prime}$ and 
the form of the operator.  For a one-dimensional system, 
$\langle \alpha^{\prime \prime} | O | \alpha \rangle$ is a radial 
integral. For an $N$-particle system, (88) is a $3N-2$ coordinate 
integration.  Equation (87) says that the $(2L+1)(2L^{\prime} + 
1)(2L^{\prime \prime}+1)$ matrix elements in (87) can all be written 
in terms of a single radial integral (88), and a set of angular 
matrix elements (84) that can be evaluated once and used for all 
atomic problems.

Now consider two different sets of operators $\{ 
{\hat{O}}_{L^{\prime}M^{\prime}}  ; M^{\prime} = + L^{\prime} , 
\cdots , -L^{\prime} \}$ and $\{ {\hat{p}}_{L^{\prime}M^{\prime}}  ; 
M = + L^{\prime} , \cdots , -L^{\prime} \}$.  From (87) we see that
$\langle \alpha^{\prime \prime} L^{\prime \prime} , M^{\prime 
\prime} | {\hat{O}}_{L^{\prime}M^{\prime}} | \alpha LM \rangle = 
\langle \alpha^{\prime \prime} | {\hat{O}} | \alpha \rangle ( 
L^{\prime \prime} M^{\prime \prime} | L M ; L^{\prime} 
M^{\prime})$ and 
$\langle \alpha^{\prime \prime} L^{\prime \prime} , M^{\prime 
\prime} | {\hat{p}}_{L^{\prime}M^{\prime}} | \alpha LM \rangle = 
\langle \alpha^{\prime \prime} | {\hat{p}} | \alpha \rangle ( 
L^{\prime \prime} M^{\prime \prime} | L M ; L^{\prime} 
M^{\prime})$,  Thus, the matrix elements involing ${\hat{p}}$ can be 
written as
\begin{equation}
\langle \alpha^{\prime \prime} L^{\prime \prime} , M^{\prime 
\prime} | {\hat{p}}_{L^{\prime}M^{\prime}} | \alpha LM \rangle = \beta
\langle \alpha^{\prime \prime} L^{\prime \prime} M^{\prime \prime} |
{\hat{O}}_{L^{\prime} M^{\prime}} | \alpha LM \rangle
\label{chap16-eqno89}
\end{equation}
where
\begin{equation}
\beta = {\langle \alpha^{\prime \prime} | {\hat{O}} | \alpha \rangle 
\over \langle \alpha^{\prime \prime} | {\hat{p}} | \alpha \rangle}
\end{equation}
is independent of $M$, $M^{\prime}$, and $M^{\prime \prime}$.  Thus ,
equation (89) is referred to as the Wigner-Eckart Theorem.

The Wigner-Eckart theorem (89) is used in the following way.  Let 
${\hat{p}}_{L^{\prime}M^{\prime}}$ be a set that is tedious, or 
difficult, to evaluate, say
\begin{equation}
q_{ij} = \sum_k {r_{ik}r_{jk} - {1 \over 3} \delta_{ij}r^2_k \over 
r^5_k},
\end{equation}
where the sum if over the particles of the system, and $r_{ik}$ is 
the i$th$ component for particle $k$.  The set $q_{ij}$ leads to five 
linearly independent quantities and they also transform like $L = 
2$.  Consider some other set of operators, say
\begin{equation}
T_{ij} = {\hat{L}}_i {\hat{L}}_j - {1 \over 3} \delta_{ij} {\hat{L}}^2
\end{equation}
that transform like $L = 2$ but for which the matrix elements are easy 
to evaluate.  This operator, $T_{ij}$ cannot change the total angular 
momentum of the system and hence, is appropriate only for cases in 
which $L^{\prime \prime} = L$.  From (89) we have that 
$\langle \alpha^{\prime \prime} L^{\prime \prime} , M^{\prime 
\prime} | q_{ij} | \alpha LM \rangle = \beta
\langle \alpha^{\prime \prime} L^{\prime \prime} M^{\prime \prime} |
T_{ij} | \alpha LM \rangle$, where $\beta$ is independent of $i$, 
$j$, $M$, and $M^{\prime \prime}$.  For example,
\begin{eqnarray}
\langle \alpha^{\prime \prime} L^{\prime \prime} , M^{\prime 
\prime} | q_{zz} | \alpha LM \rangle &=& \beta
\langle \alpha^{\prime \prime} L^{\prime \prime} M^{\prime \prime} | 
\left( L^2_z - {1 \over 3} {\hat{L}}^2 \right) | \alpha LM \rangle\cr
&=& \beta \delta_{\alpha^{\prime \prime}\alpha} 
\delta_{L^{\prime \prime}L} \delta_{M^{\prime \prime}M} 
\left[ M^2 - {L(L+1) \over 3} \right].
\label{chap16-eqno90}
\end{eqnarray}
That is, the dependence of the $q$ matrix elements upon $L$, $M$, 
and $M^{\prime \prime}$ can be easily determined.

The example in (90) shows a limitation of the Wigner-Eckart theorem.  
The operator $T_{ij}$ can on ly change the $M$ value of a state, and 
thus, gives a zero matrix element for $L^{\prime \prime} \not= L$ for 
a $\alpha^{\prime \prime} \not= \alpha$.  Thus, (90) provides no 
information on $\beta$ for $L^{\prime \prime} \not= L$ or for 
$\alpha^{\prime \prime} \not= \alpha$.

The proportionality constant $\beta$ can be determined using any 
convenient $i$, $j$, $M$, and $M^{\prime \prime}$.  Thus, using $i = 
j = z$ and $M = M^{\prime \prime}$, we obtain
\begin{equation}
\beta = {3 \over L(2L=1)} \langle \alpha LL | q_{zz} | \alpha LL 
\rangle
\end{equation}
for the case $L^{\prime \prime} = L$ and $\alpha^{\prime \prime} = 
\alpha$.

\subsubsection{Examples}

A magnetic moment $\mu$ and an angular momentum $\ell$ both transform 
the same way under O(3).  Hence, by the Wigner-Eckart theorem, we may 
write $\langle \alpha LM^{\prime \prime} | \mu | \alpha LM \rangle = q 
\langle \alpha LM^{\prime \prime} | \ell | \alpha LM \rangle$.  For 
example, $\langle | \mu_z | \rangle = qM \delta_{M^{\prime 
\prime}M}$.  In this case, the Wigner-Eckart constant $g$ is called 
the gyromagnetic ratio.

Consider a system whose wavefunctions are eigenstates of 
${\hat{L}}^2$, ${\hat{S}}^2$, ${\hat{J}}^2$, and ${\hat{J}}_z$ where
${\hat{J}}_i{\hat{L}}_i + {\hat{S}}_i$.  Since ${\hat{J}}_i - 
{\hat{L}}_i = {\hat{S}}_i$, we see that
\begin{equation}
\sum_{i} \left( {\hat{J}}_i - {\hat{L}}_i \right)^2 = \sum_{i} 
{\hat{J}}_i^2 + \sum_{i} {\hat{L}}_i^2 - 2 \sum_i 
{\hat{J}}_i {\hat{L}}_i = \sum_i {\hat{S}}_i^2.
\end{equation}
That is
\begin{equation}
{\hat{J}} \cdot {\hat{L}} = {1 \over 2} \left[ {\hat{J}}^2 + 
{\hat{L}}^2 - {\hat{S}}^2 \right]
\end{equation}
and, similarly
\begin{eqnarray}
{\hat{J}} \cdot {\hat{S}} &=& {1 \over 2} \left[ {\hat{J}}^2 -
{\hat{S}}^2 - {\hat{L}}^2 \right]\cr
{\hat{L}} \cdot {\hat{S}} &=& {1 \over 2} \left[ {\hat{J}}^2 + 
{\hat{S}}^2 - {\hat{L}}^2 \right]
\end{eqnarray}
Thus, $\langle \alpha^{\prime} L^{\prime} S^{\prime} J^{\prime} 
M^{\prime} | {\hat{J}} \cdot {\hat{L}} | \alpha LSJM \rangle = 
\delta_{\alpha^{\prime}\alpha} \delta_{L^{\prime}L} 
\delta_{S^{\prime}S} \delta_{J^{\prime}J} \delta_{M^{\prime}M} 
\beta_{J \cdot L}$
where
\begin{equation}
\beta_{J \cdot L} = {1 \over 2} \left[ J \left( J+1 \right) + L 
\left( L+1 \right) - S \left( S+1 \right) \right]
\end{equation}
and, similarly
\begin{equation}
\beta_{J \cdot S} = {1 \over 2} \left[ J \left( J+1 \right) + S 
\left( S+1 \right) - L \left( L+1 \right) \right]
\end{equation}
and
\begin{equation}
\beta_{L \cdot S} = {1 \over 2} \left[ J \left( J+1 \right) - S 
\left( S+1 \right) - L \left( L+1 \right) \right]
\end{equation}
The wavefunctions $ | \alpha LSJM \rangle$ are not, in general, 
eigenfunctions of $L_z$ or $S_z$.  However, using the Wigner-Eckart 
theorem, we can write
\begin{eqnarray}
\langle \alpha LSJM^{\prime} | {\hat{L}}_z | \alpha LSJM \rangle &=& 
\beta_L \langle \alpha LSJM^{\prime} | {\hat{J}}_z | \alpha LSJM 
\rangle = \beta_L M \delta_{MM^{\prime}}\cr
\langle \alpha LSJM^{\prime} | {\hat{L}}_z | \alpha LSJM \rangle &=& 
\beta_S M \delta_{MM^{\prime}}
\label{chap16-eqno91}
\end{eqnarray}
To evaluate the $\beta$'s, we consider
\begin{eqnarray}
\langle \alpha LSJM^{\prime} | {\hat{J}} \cdot {\hat{L}} | \alpha 
LSJM \rangle = \sum_i & \langle \alpha LSJM^{\prime} | {\hat{J}}_i 
\cdot {\hat{L}}_i | \alpha LSJM \rangle\cr
= \sum_i \sum_{\alpha^{\prime \prime}L^{\prime \prime}S^{\prime \prime} 
J^{\prime \prime}M^{\prime \prime}} & \langle \alpha LSJM^{\prime} | 
{\hat{J}}_i | \alpha^{\prime \prime}L^{\prime \prime}S^{\prime \prime} 
J^{\prime \prime}M^{\prime \prime} \rangle\cr
& \langle \alpha^{\prime \prime}L^{\prime \prime}S^{\prime \prime} 
J^{\prime \prime}M^{\prime \prime} | {\hat{L}}_i | \alpha LSJM 
\rangle
\label{chap16-eqno92}
\end{eqnarray}
using closure.  But, $\langle \alpha LSJM^{\prime} | {\hat{J}}_i |
\alpha^{\prime \prime}L^{\prime \prime}S^{\prime \prime} 
J^{\prime \prime}M^{\prime \prime} \rangle = \delta_{\alpha 
\alpha^{\prime\prime}} \delta_{LL^{\prime\prime}} 
\delta_{SS^{\prime\prime}} \delta_{JJ^{\prime\prime}} \langle M | 
J_i | M^{\prime\prime} \rangle$ so that (92) becomes
\begin{equation}
\langle M^{\prime} | {\hat{J}} \cdot {\hat{L}} | M \rangle = 
\sum_{iM^{\prime\prime}} \langle M^{\prime} | {\hat{J}}_i | 
M^{\prime\prime} \rangle \langle M^{\prime\prime} | L_i | M \rangle.
\end{equation}
Using (91a), this becomes
\begin{equation}
\langle M^{\prime} | {\hat{J}} \cdot {\hat{L}} | M \rangle = \beta_L 
\sum_{iM^{\prime\prime}} \langle M^{\prime} | {\hat{J}}_j | 
M^{\prime\prime} \rangle \langle M^{\prime\prime} | J_i | M 
\rangle = \beta_L \langle M^{\prime} | {\hat{J}}^2 |  M \rangle
\end{equation}
Setting $M = M^{\prime}$, we obtain
\begin{equation}
\beta_L = {\langle {\hat{J}} \cdot {\hat{L}} \rangle \over 
\langle {\hat{J}} \cdot {\hat{J}} \rangle} = {J(J+1)+L(L+1)-S(S+1) 
\over 2J(J+1)}
\end{equation}
Similarly,
\begin{equation}
\beta_S = {\langle {\hat{J}} \cdot {\hat{S}} \rangle \over 
\langle {\hat{J}} \cdot {\hat{J}} \rangle} = {J(J+1)+S(S+1)-L(L+1) 
\over 2J(J+1)}
\end{equation}
Since, ${\hat{L}}_zz + {\hat{S}}_z = {\hat{J}}_z$, we expect 
$\beta_L + \beta_S = 1$, which checks.  Applying a magnetic field 
in the $z$ direction, the magnetic moment is $\langle M | L_z + 
2S_z | M \rangle = gM$ where
\begin{equation}
g = \beta_L + 2\beta_S = {3J(J+1)_S(S+1)-L(L+1) \over 2J(J+1)},
\end{equation}
the famous Land\'e-g formula.  Actually, the coefficient of $S_z$ 
is 2.0023, we ignore such fine points.

\subsection{Molecules}

The power of the above analysis is greatest for system with large 
degeneracies.  Thus, this approach is less useful for molecules.  For 
the groups $T_d$, $O$, $O_h$, and the dodecahedral groups, there are 
representations of order $\geq 3$, and the analysis is of some 
utility.  Note that for spherical symmetry, angular moment, the 
decomposition of the direct product leads to the occurrence of each 
final angular momentum only once.   That is, each irreducible 
representation occurs only once in the direct product.  As a result, 
there is only one radial term $\langle \alpha^{\prime\prime} | O | 
\alpha \rangle$ in (87).  For systems leading to multiple occurrences 
of an irreducible representation in the direct product, the equation 
corresponding to (87) has a similar number of invariants.


\section{The Jahn-Teller Theorem}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig43}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig44}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig45}
\end{figure}

As will be discussed, the propenyl radial (Figure \ref{chap16-fig43})
in {\bf D}$_{3h}$ symmetry leads to a $^2E^{\prime\prime}$ ground
state.  On the other hand, considering the forms of the wavefunctions
of this state shown in Figure \ref{chap16-fig44} we see that
$^2E^{\prime\prime}_x$ would prefer a distortion of the form in Figure
\ref{chap16-fig45} leading to {\bf C}$_{2v}$ symmetry.  Indeed, a plot
of the energy of the $^2E^{\prime\prime}$ states as a function of the
distortion in Figure \ref{chap16-fig45} has the form in Figure
\ref{chap16-fig46}.  From this figure, we can see energy for {\bf
C}$_{2v}$ distortion of Figure \ref{chap16-fig43}. The abscissa $Q$ is
for distortion of the form in Figure \ref{chap16-fig45}.  The states
are degenerate for {\bf D}$_{3h}$, but $^2E^{\prime\prime}_x$ is lower
for distortions of the form in Figure \ref{chap16-fig45}, while
$^2E^{\prime\prime}_y$ is lower for distortions in the opposite
direction.  Figure \ref{chap16-fig46} says more, however.  It
indicates that the {\bf C}$_{2v}$ geometry leads to a lower energy
than the {\bf D}$_{3h}$ geometry.  This is a general result as was
proven by Jahn and Teller.$^7$

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig46}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig47}
\end{figure}

\subsection{The Theorem and it's Proof}

\subsubsection{The Theorem}

For the Jahn-Teller theorem, if an electronic state is spatially 
degenerate, then for a nonlinear molecule there is always some 
distortion of the molecule which splits the degeneracy in such a way 
that, the lower component is spatially nondegenerate, and such that 
the energy of the distorted molecule is lower than the energy of the 
undistorted molecule  This theorem says that the ground state of a 
molecule at the optimum geometry is never spatially degenerate, and 
except for the special case of a linear molecule.

Jahn$^8$ took this one step further and showed that for a nonlinear 
molecule with spin degeneracy, the geometry will always distort in 
such a way as to remove this degeneracy, except for the Kramers, 
two-fold, degeneracy of odd electron systems.  Kramers showed that for 
odd electron systems, in the absence of a magnetic field, there must 
always be at least a two-fold degeneracy.

\subsubsection{The Proof, Nonlinear Molecules}

Consider a set of state $\{ \phi_i\}$ all the same energy $E_0$,
\begin{equation}
H_0 \psi_i = E_0 \psi_i ,
\label{chap16-eqno93}
\end{equation}
and apply a distortion $Q$ to the geometry of the system.  Note that
$Q$ may involve simultaneous distortions on several centers, as in
Figure \ref{chap16-fig45}.  Writing the energy of the distorted system
as
\begin{equation}
E_i = E_0 + Q {\partial E_I \over \partial Q}
\label{chap16-eqno94}
\end{equation}
we see that if
\begin{equation}
{\partial E_i^{e\ell} \over \partial Q} \not= 0
\label{chap16-eqno95}
\end{equation}
then either the distortion $+Q$ or $-Q$ will lower the energy of the 
state.  Distortion preserving linearity cannot remove the degeneracy.  
Thus, if $Q \not= A_1$ symmetry, the molecular symmetry will be 
reduced.  To prove the Jahn-Teller theorem, we must how that for any 
degenerate state of any nonlinear molecule there is a $Q$ such that 
(95) is satisfied.

Unfortunately, the situation is not quite as simple as in (94).  
Because the states (93) are degenerate, even a very small distortion 
$Q$ may lead to intermixing of the degenerate states.  This is a 
standard problem in perturbation theory for degenerate states, we must 
ensure that the eigenstates are chosen os as to diagonalize the first 
order perturbation matrix.  Letting
\begin{equation}
H = H_0 + Q {\partial H \over \partial Q}
\end{equation}
and $E_i$ of (94) be the Hamiltonian and energy after the 
perturbation $Q$, higher order terms in $Q$ are neglected, we require 
that the degenrate $\{ \psi_i\}$ be recombined into $\{ 
\psi_i^{\prime}\}$ such at $\langle \psi_i^{\prime} | ( H-E_j)| 
\psi_j^{\prime} \rangle = 0$ to first order in $Q$.  That is,
\begin{equation}
{\partial \over \partial Q} \langle \psi_i^{\prime} | ( H - E_j)| 
\psi_j^{\prime} \rangle = 0
\label{chap16-eqno96}
\end{equation}
to zero order in $Q$.  Expanding the left side of (96) to
\begin{equation}
\underbrace{\langle {\partial \psi_i^{\prime} \over \partial Q} | 
\left( H_0 - E_0 \right) | \psi_j^{\prime} \rangle}_{=0} + 
\underbrace{ \langle \psi_i^{\prime} | H_0 - E_0 | {\partial 
\psi_j^{\prime} \over \partial Q} \rangle}_{=0} + \underbrace{\langle 
\psi_i^{\prime} | {\partial H \over \partial Q} - {\partial E_i 
\over \partial Q}| \psi_j^{\prime} \rangle}_{=0}
\end{equation}
where we have used (93), $(H_0 - E_0) \psi_i^{\prime} = 0$.  Thus,
\begin{equation}
\langle \psi_i^{\prime} | \left({\partial H \over \partial Q} - 
{\partial E_i \over \partial Q} \right) | \psi_j^{\prime} \rangle = 
0.
\label{chap16-eqno97}
\end{equation}
For $i = j$, (97) is referred to as the Hellmann-Feynman theorem.  
That is, to the perturbed energy as in (94), we must choose the 
$\psi_i$ so that they diagonalize the matrix
\begin{equation}
V^Q_{ij} = \langle \psi_i^{\mu} | {\partial H \over \partial Q} | 
\psi_j^{\mu} \rangle (98)
\end{equation}
where $\mu$ indicates that the unperturbed functions belong to 
degenerate irreducible representation $\mu$ of the unperturbed 
symmetry group.

Now we are at the point to prove the Jahn-Teller theorem.   In the 
following, it is assumed that $Q$ is not of $A_1$ symmetry since an 
$A_1$ distortion would not lower the symetry and hence, would not 
split the degeneracy.   If any eigenvalue of the $V^Q$ matrix is not 
zero, then distortion $Q$ will lead to a distorted geometry having a 
lower energy.  The wavefunction part of (97) transforms as the 
symmetric direct product $[ \mu \times \mu]$.  Thus, group 
theoretically, (97) will be zero for all $Q$ if no vibrational mode 
leads to $\partial H / \partial Q$ having a symmetry contained in 
$[ \mu \times \mu]$.  Since $Q$ and $\partial H / \partial Q$ have 
the same symmetry, the important question is whether there is a 
vibrational mode of some symmetry contained in $[ \mu \times \mu]$.  
Jahn and Teller considered every degenerate representation of every 
point group, and considered every possible set of atoms leading to 
that point group.  In each case, they found that except for linear 
molecules, some vibrational mode has a symmetry combined in 
$[ \mu \times \mu]$.

The Jahn-Teller theorem says nothing about magnitudes of distortions.  
Thus, we can have cases in which the distortion leads to energy 
separations of the order of electron volts, and we can have cases 
where the energy separation is less than 0.0001 eV.  For the lighter 
atoms, the splitting of the spin degeneracies referred to in the Jahn 
theorem are quite small, of the order of 10$^{-4}$ eV or less.  Since 
normal vibrational frequencies are of the order of 0.1 to 0.5 eV, 
Jahn-Teller splittings of much less than 0.1 eV will be of little 
significance to us, since averaging over the zero point motions, the 
molecule will behave as if it had the full symmetry.

Occasionally, distortions such as in Figure \ref{chap16-fig46} are
described as if there is some sort of Jahn-Teller force that causes
the distortions.  There is no such kind of force, of course.  The
distortion occurs because one component can get better bonding for the
distorted structure.  For example, in Figure \ref{chap16-fig44} the
$^2E_x^{\prime\prime}$ component has a double bond and hence, extra
attractive interaction between $C_2$ and $C_3$ but repulsive
interaction of the pi orbital on $C_1$ with the $C_3$ double bond.
Thus, the {\bf C}$_{2v}$ distortion in Figure \ref{chap16-fig45} is
expected to decrease the energy.  How large the distortion and how
great the splitting of the $^2E^{\prime\prime}$ levels depends on the
balance between the pi interactions which favor {\bf C}$_{2v}$
symmetry, and the sigma bonds, which favor {\bf D}$_{3h}$

\subsubsection{Linear Molecules}

For a nonlinear molecule, the degenerate state has $\Lambda \geq 1$, 
and as shown in Section 16.6, the symmetry product $[ \mu \times 
\mu ]$ leads to $\Lambda^{\prime} = 0$ and $| \Lambda^{\prime} - 2 
\Lambda | \geq 2$.  But the perpendicular vibration has 
$\Lambda^{\prime} = 4$.  Distortions preserving linearity cannot 
remove the degeneracy.  Hence, the eigenvalues of (97) must be zero.  
Consequently, the potential curve for a linear molecule must have a 
slope of zero at the linear configuration,
\begin{equation}
{\partial E_i \over \partial \theta} = 0
\label{chap16-eqno99}
\end{equation}
at $\theta = 180^{\circ}$.  A qualitative argument for deriving (99) 
is as follows.  Consider the distortion $Q$
\bigskip
\noindent
The distortion $-Q$
\bigskip
\noindent
is exactly equivalent ot the first.  Hence, the energy of each state 
$\psi_i$ satisfies $E_i(+Q) = E_1(-Q)$, for degenerate and 
nondegenerate states, leading to (99).

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig48}
\end{figure}

For degenerate state, (99) allows three possible types of potential
curves, as indicated in Figure \ref{chap16-fig48}.  Possible potential
curves as a function of bending angle for a state of a polyatomic
molecule that is degenerate at the linear configuration.  If the first
case applies, then the ground state of the linear molecule is
spatially degenerate.  The other two cases lead to nondegenerate,
nonlinear ground states.  The removel of degeneracy of linear
molecules as in Figure \ref{chap16-fig48}, is referred to as Renner
splitting.  Note that the Jahn-Teller system does not say that the
linear polyatomic molecules remains undistorted and degenerate.  The
theorem merely says, the first case is allowed and hence, they can be
linear polyatomic molecules that are spatially degenerate.  On the
other hand, the theorem says that for nonlinear molcules, the minimum
energy state will not be spatially degenerate.

\subsection{Analysis of Propenyl Radical}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig49}
\end{figure}

With one $p_z$ orbital in each $C$ of Figure \ref{chap16-fig43}, we
get three molecular orbitals of the form shown in Figure
\ref{chap16-fig49}.  With three electrons, the ground state
configuration is $( a^{\prime\prime}_z)^2 ( e^{\prime\prime} )^1$
leading to the $^2E^{\prime\prime}$ state, as discussed above.

The valence bond description is a bit more obscure.  We can write three 
equivalent bonding structures
\begin{eqnarray}
\Psi_1 &=& \mathcal{A}abc ( \alpha \beta - \beta \alpha )\alpha\\
\Psi_2 &=& \mathcal{A}abc ( \alpha \beta - \beta \alpha )\\
\Psi_3 &=& \mathcal{A}abc ( \beta \alpha \alpha - \alpha \alpha \beta).
\end{eqnarray}
However, $\psi_3 + \psi_2 = - \psi_1$ so that there are only two
independent states, say $\psi_z = \psi_1$ and $\psi_y = \psi_3 -
\psi_2$ as indicated in Figure \ref{chap16-fig44}.  Of course, we
could just as well have considered our states to be the ones shown in
Figures \ref{chap16-fig50} or \ref{chap16-fig51}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig50}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig51}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16-fig52}
\end{figure}

For Figure \ref{chap16-fig44}(a) the optimum distortion is Figure
\ref{chap16-fig45}, while for Figure \ref{chap16-fig50}(a), it is
Figure \ref{chap16-fig52}.  Thus, starting with the
$^2E^{\prime\prime}$ state in {\bf D}$_{3h}$ symmetry, expect to find
three equivalent distortions, Figures \ref{chap16-fig45} and
\ref{chap16-fig52}, each of which leads to the same decrease in the
energy.

That the mode of Figure \ref{chap16-fig45} would have the correct
symmetry to split the degeneracy of $^2E^{\prime\prime}$ can be
determined mathematically by noting that $[ E^{\prime\prime} \times
E^{\prime\prime} ] = A^{\prime}_1 + E^{\prime}$.  Thus, the distortion
removing the degeneracy must be of $E^{\prime}$ symmetry, as in Figure
\ref{chap16-fig45}.

\section{The Double Point Groups}

We have generally assumed that the spatial and spin parts of the 
wavefunction are completely independent, except for the coupling 
inherent in the Pauli principle.  Here we will examine some of the 
group theoretical considerations appropriate for cases where the 
spatial and spin parts of the wavefunction are coupled, for example, 
due to spin-orbit coupling.

Consider the one-electron wavefunction as $\Psi({\bf r}, \sigma) = 
\Phi( {\bf r} ) \chi(\sigma)$ where $\Phi({\bf r})$ depends only upon 
spatial coordinates, and $\chi(\sigma)$ depends only upon spin 
coordinates.  If ${\hat{R}}$ is some spatial operation such as 
rotation or reflection, we have assumed that the spin part of the 
wavefunction is unaffected by ${\hat{R}}$, 
${\hat{R}} \Psi (r,\sigma) = [ {\hat{R}}\Phi({\bf r} ) ] \chi( 
\sigma)$.  That is, ${\hat{R}} \Psi (r,\sigma) =$ $\Psi (R^{-1} {\bf 
r} , \sigma ) =$ $\Phi(R^{-1} {\bf r} ) \chi (\sigma )=$ $[{\hat{R}} 
\Phi ( {\bf r} ) ] \chi( \sigma )$.  However, if the spatial and spin 
coordinates are coupled, the only symmetry operations are those for 
which we allow ${\hat{R}}$ to operate both as spatial and spin 
coordinates ${\hat{R}} \Psi ( {\bf r},\sigma) = [ {\hat{R}}\Phi({\bf 
r} ) ] [ {\hat{R}} \chi ( \sigma)]$.  That is, ${\hat{R}} \Psi (r,\sigma) =$ 
$\Psi (R^{-1} {\bf r} , R^{-1} \sigma ) =$ $\Phi(R^{-1} {\bf r} ) 
\chi (R^{-1} \sigma )=$ $[{\hat{R}} \Phi ( {\bf r} ) ] [ {\hat{R}} 
\chi( \sigma )]$. 

First, we will consider the nature of the transformation $R \sigma$.  
If ${\hat{R}}$ is some proper rotation, then
\begin{equation}
{\hat{R}} r_i = \sum_{j=1}^{3} r_j O_{ij} (R)
\end{equation}
where $\underline{O}(R)$ is a unique three-by-three orthogonal matrix 
with $\det \underline{O} = 1$.  that is, $\underline{O} {\tilde{O}} = 
\underline{1}$.  Since $O$ is orthogonal and since $\det 
\underline{O} = 1$, we say that $\underline{O}(R) \epsilon SO(3)$.  We 
will find that the corresponding transformation on spin coordinates is
\begin{equation}
{\hat{R}} \sigma_i = \sum_{j=1}^{2} \sigma_j \underline{U}_{ij} (R)
\end{equation}
where $\underline{U} = 1$ is a two-by-two unitary matrix with $\det 
\underline{U} = 1$.  That is, $\underline{U}U^{\dag} = 1$.  Thus, we 
say that $U(R)\epsilon SU(2)$.

Thus, ${\hat{R}}$ operating on spatial and spin coordinates may be 
condsidered as the ordered product ${\hat{R}} = \{O(R) \times U(R)\}$, 
where $O(R)$ operates on spatial coordinates and $U(R)$ operates on 
spin coordinates.

Since $O(R)$ and $U(R)$ describe the transformation on spatial and 
spin coordinates arising from a specific $R$, we expect some 
relationship between them.  This relationship is examined next, where 
we find that each $U(R)$ corresponds to a unique $O(R)$ but that each 
$O(R)$ corresponds to two different $U(R)$.  Indeed, we find that 
although a rotation $R(2\pi)$ through $2\pi$ radians corresponds to the 
identity for $\underline{O}(R)$, $\underline{O}(2\pi) = 
\underline{1}$, $R(2\pi)$ corresponds to the negative of the identity 
for $U(R)$, $\underline{U}(2\pi) = - \underline{1}$.  Thus, the 
smallest rotation corresponding to the identity is $R(4\pi)$ leading 
to $\underline{O}(4 \pi) = \underline{1}$ and $\underline{U}(4\pi) = 
\underline{1}$.

As a result, the structure of many point groups changes markedly, 
leading to what are called the double point groups.  These new point 
groups are examined later.  They are denoted by a number symbol, 
e.g., {\bf D}$^{\#}_{4h}$.

\subsection{The Relation Between U(R) and O(R)}

\subsubsection{The Spatial Transformation $\underline{O}(R)$}

Any spatial vector {\bf r} can be written as
\begin{equation}
{\bf r} = r_x {\bf e}_x + r_y {\bf e}_y + r_z {\bf e}_z = \sum_{i} 
r_i {\bf e}_i
\label{chap16-eqno100}
\end{equation}
where the ${\bf e}_i$ are orthonormal unit vectors, ${\bf e}_i \cdot 
{\bf e}_j = \delta_{ij}$.  Transforming {\bf r} by ${\hat{R}}$ leads 
to some new vector {\bf r}$^{\prime}$
\begin{equation}
{\bf r}^{\prime} = {\hat{R}} {\bf r} = \sum_{i} r_i 
{\bf e}_i^{\prime}
\label{chap16-eqno101}
\end{equation}
where ${\bf e}_i^{\prime}$ are the transformed basis vectors.  
Expanding the ${\bf e}_i^{\prime}$ in terms of $\{ {\bf e}_i\}$ leads 
to
\begin{equation}
{\hat{R}} {\bf e}_i = {\bf e}_i^{\prime} = \sum_{j} {\bf e}_j 
O_{ji}(R)
\label{chap16-eqno102}
\end{equation}
where the $3 \times 3$ matrix $\underline{O}$ depends upon which 
${\hat{R}}$ is used.  Since the ${\bf e}_i$ and ${\bf e}_i^{\prime}$ 
are real, the matrix $\underline{O}$ is real.  For any transformation 
preserving angles between angles, e.g., rotations, reflections, etc., 
we have ${\bf e}_i^{\prime} \cdot {\bf e}_j^{\prime} = \delta_{ij}$, 
and hence,
\begin{equation}
\delta_{ij} = {\bf e}_i^{\prime} \cdot {\bf e}_j^{\prime} = 
\sum_{k\ell} \underbrace{({\bf e}_k \cdot {\bf 
e}_{\ell})}_{\delta_{k\ell}} P_{ki} O_{\ell j} = \sum_{k} O_{ki} 
O_{kj} = \sum_{k} {\tilde{O}}_{ik} O_{kj}
\end{equation}
that is,
\begin{equation}
\underline{1} = {\underline{\tilde O}} \underline{O}
\label{chap16-eqno103}
\end{equation}
where $\tilde{O}$ denotes the transpose, such matrices are called 
orthogonal.  The set of all orthogonal matrices, that is, the set of 
matrices satisfying (103) is denoted as $O(3)$.

Using (101) and (102), transformation may be written as
\begin{equation}
{\hat{R}} {\bf r} = \sum_{i} r_i {\bf e}_i^{\prime} = \sum_{j} r_i 
{\bf e}_j O_{ji} (R) = \sum_{j} r^{\prime}_j {\bf e}_j ,
\end{equation}
where
\begin{equation}
r^{\prime}_j = \sum_{i} O_{ji} (R) r_i
\end{equation}
Thus,
\begin{equation}
\sum_{j} \left( r^{\prime}_j \right)^2 = \sum_{k\ell} r_k r_{\ell} 
\sum_{j} \underbrace{O_{kj}O_{\ell j}}_{\delta_{k\ell}} = \sum_{k} 
(r_k)^2 .
\end{equation}
That is, any orthogonal transformation preserves the length of the 
vector
\begin{equation}
x^{\prime 2} + y^{\prime 2} + z^{\prime 2} = x^2 + y^2 + 
z^2.
\label{chap16-eqno104}
\end{equation}

Every point operation, rotation, reflection, inversion, etc., leads to 
a unique transformation $x , y , z \rightarrow x^{\prime} , 
y^{\prime} , z^{\prime}$ satisfying (104) and every such transformation 
corresponds to a unique orthogonal matrix of (103).  Thus, there is a 
one-to-one correspondence between point operations and $3 \times 3$ 
orthogonal matrices.  Hence, we will generally refer to any such 
transformation ${\hat{R}}$ in terms of its orthogonal matrix, 
$\underline{O}({\hat{R}})$.

The  $\underline{O}(R)$ corresponding to some common point 
operations, are as follows.
\begin{equation}
\underline{O}_z( \varphi ) = 
\pmatrix{\cos \varphi & - \sin \varphi & 0\cr
\sin \varphi & \cos \varphi & 0\cr
0 & 0 & 1\cr}
\label{chap16-eqno105}
\end{equation}
for rotation through an angle $\varphi$ about the $z$ axis,
\begin{equation}
\underline{O}_x( \varphi ) = 
\pmatrix{1 & 0 & 0\cr
0 & \cos \varphi & - \sin \varphi\cr
0 & \sin \varphi & \cos \varphi\cr}
\label{chap16-eqno106}
\end{equation}
for rotation about the $x$ axis,
\begin{equation}
\underline{O}_y( \varphi ) = 
\pmatrix{\cos \varphi & 0 & \sin \varphi\cr
0 & 1 & 0\cr
- \sin \varphi & 0 & \cos \varphi\cr}
\label{chap16-eqno107}
\end{equation}
for rotation about the $y$ axis,
\begin{equation}
\underline{O}(I) = 
\pmatrix{-1 & 0 & 0\cr
0 & -1 & 0\cr
0 & 0 & -1\cr}
\label{chap16-eqno108}
\end{equation}
for inversion
\begin{equation}
\underline{O}( \sigma_{xy}) =
\pmatrix{+1 & 0 & 0\cr
0 & +1 & 0\cr
0 & 0 & -1\cr}
\label{chap16-eqno109}
\end{equation}
for reflection in the $xy$ plane, and
\begin{equation}
\sigma_{xy} R_z ( \varphi ) =
\pmatrix{\cos \varphi & - \sin \varphi & 0\cr
\sin \varphi & \cos \varphi & 0\cr
0 & 0 & -1\cr}
\label{chap16-eqno110}
\end{equation}
for the rotary reflection.

The proper rotations (105) through (107) all have $\det 
\underline{O}(R) = 1$, while the improper rotations (108) through 
(110) all have $\det \underline{O}((R) = -1$.  Since a proper rotation 
through an arbitrary angle about an arbitrary axis can be written as 
an appropriate combination of (105) through (107), and since
\begin{equation}
\det ( \underline{ABC} \cdots ) = ( \det \underline{A} ) ( \det 
\underline{B} ) ( \det \underline{C} ) , \cdots ,
\label{chap16-eqno111}
\end{equation}
we see that all proper rotations $R$ have
\begin{equation}
\det \underline{O} ( R) = 1.
\label{chap16-eqno112}
\end{equation}
Any improper rotation can be written as $IR$, where $R$ is a proper 
rotation and hence, $\det O(IR) = [\det O(I)][\det O(R)]=-1$.  From 
(103) and (111), we have $[\det \underline{O}(ABC)]^2 = +1$ and 
hence, $\det \underline{O} (ABC) + \pm 1$ are the only allowed 
values.  The subset of $O(R)$ satisfying (112), forms a subgroup 
denoted as $SO(3)$, $S$ for special, corresponding to all proper 
rotations.

\subsubsection{The Spin Transformation $U(R)$}

Any spin function can be written as a complex, linear combination of 
the up-and-down spin functions $\alpha$ and $\beta$
\begin{equation}
\sigma = \sigma_1 \alpha + \sigma_2 \beta = \sum^{2}_{i=1} \sigma_i 
E_i
\end{equation}
where $E_1 = \alpha$ and $E_2 = \beta$ are the basis functions.  
These functions are orthonormal $\langle E_i | E_j \rangle = 
\delta_{ij}$, but they, and the $\sigma_i$, may be complex.  
Applying ${\hat{R}}$ to the $E_i$ must lead to a linear combination of 
the $\{{\bf E}_i\}$
\begin{equation}
E^{\prime}_i = {\hat{R}} {\bf E}_i = \sum^{2}_{j=1} {\bf E}_j U_{ji} 
(R)
\label{chap16-eqno113}
\end{equation}
Requiring that $\langle E_i | E_j \rangle = \delta_{ij}$ leads to
\begin{equation}
\delta_{ij} = \sum_{k\ell} \underbrace{\langle E_k | 
E_{\ell}}_{\delta_{ij}} U^*_{ki} U_{\ell j} = \sum_{k} U^*_{ki}U_{kj} = 
\sum_{k} U^{\dag}_{ik} U_{kj}
\end{equation}
or $\underline{1} = \underline{U}^{\dag}\underline{U}$. That is 
$\underline{U}(R)$ is unitary.  Later we will show $\det 
\underline{U} = 1$, so that the matrices $\underline{U}(R)$ in (113) 
belong to the group of special unitary matrices in two dimensions $U 
\epsilon SU(2)$.

Note that with spin coordinates, we considered the transformation of 
the two basic spin functions $\alpha$ and $\beta$, finding that they 
transform like $U(R)$.  Whereas, for spatial coordinates we considered 
the transformation of the three basic spatial coordinates, finding that 
they transform like $O(R)$.  To find how the spatial functions 
transform, we made use of this transformation on spatial coordinates, 
but for spin functions, we bypassed considerations of the specific 
spin coordinates.

Since,
\begin{equation}
{\hat{R}} {\hat{S}} {\bf E}_i = R \left[ \sum_j E_j 
U_{ji}(S)\right] = \sum_{kj} E_k U_{kj}(R)U_{ji}(S),
\end{equation}
we see that the matrices $\{ U(R)\}$ multiply in the same way as the 
group elements.  That is, they lead to a representation of the group.

\subsubsection{Rotation of Spin Orbitals}

Consider a one-electron wavefunction $\psi_{ij}({\bf r} , \sigma ) = 
\phi_i ( {\bf r} ) = \chi_j(\sigma)$.  Applying a point operation 
${\hat{R}}$, leads to
\begin{eqnarray}
{\hat{R}} \psi_{ij} ( {\bf r} ) \sigma &=& \psi_{ij} \left( R^{-1} 
{\bf r} , R^{-1} \sigma \right) = \phi_i \left( R^{-1} {\bf r} \right) 
\chi_j \left( R^{-1} \sigma \right)
= \left[ {\hat{R}} \phi(r) \right] \left[ {\hat{R}} \chi(\sigma) 
\right]\cr
&=& \sum_{K\ell} \phi_k ( {\bf r} ) \chi_{\ell} (\sigma) \left[ 
D_{ki}(R) U_{\ell j}(R) \right] = \sum_{K\ell} \psi_{k\ell} ( r , 
\sigma ) D^{\#}_{k\ell ,ij} (R).
\end{eqnarray}
Thus, the spin orbital $\psi_{ij}({\bf r} , \sigma)$ transforms as the 
direct product of $D(R)$ and $U(R)$, as $D^{\#}_{k\ell ,ij}(R) = 
D_{ki}(R)U_{\ell j}(R)$.  In order to proceed, we must establish the 
relationship between $U(R)$ and the spatial transformation $R$.  To 
do this, we will establish a relationship between $U(R)$ and the 
coordinate transformation $O(R)$ corresponding to $R$.

\subsubsection{The Relation Between $\underline{O}(R)$ 
and $\underline{U}(R)$}

The transformation $\underline{O}(R)$ on spatial coordinates {\bf r} 
and the transformation $\underline{U}(R)$ on spin coordinates $\sigma$ 
are closely related.  There are fundamental reasons for this, however, 
for our purposes we merely need the correct correspondence, and we 
choose to use a mathematical device$^9$ that quickly establishes the 
correspondence.

The most general form for an element in $SU(2)$ is
\begin{equation}
U = \pmatrix{ \kappa + i \lambda & \mu + i \nu\cr
- \mu + i \nu & \kappa - i \lambda\cr}
\label{chap16-eqno114}
\end{equation}
where $\kappa$, $\lambda$, $\mu$, and $\nu$ are real numbers, such 
that
\begin{equation}
\kappa^2 + \lambda^2 + \mu^2 + \nu^2 = 1.
\label{chap16-eqno115}
\end{equation}
The most general form of a traceless Hermitian matrix is
\begin{equation}
H = \pmatrix{z & x + iy\cr
x - iy & -z\cr}
\label{chap16-eqno116}
\end{equation}
Consider the similarity transformation $H^{\prime} = UHU^{\dag}$.  
Since $H^{\dag} = UH^{\dag}U^{\dag} = H^{\prime}$, the resulting 
$H^{\prime}$ is Hermitian.  In addition, since $U^{\dag}U = 1$, we 
have that $Tr(H^{\prime}) = Tr(UHU^{\dag}) = Tr(HU^{\dag}U) = Tr(H)$, 
and hence, $H^{\prime}$ is traceless.

Thus, $H^{\prime}$ also has the form
\begin{equation}
H^{\prime} = \pmatrix{z^{\prime} & x^{\prime} + iy^{\prime}\cr
x^{\prime} - iy & -z^{\prime}\cr}.
\end{equation}

Since $\det(H^{\prime}) = \det(UHU^{\dag}) = (\det U) (\det H)(\det 
U^{\dag})$ and $(\det U)(\det U^{\dag}) = 1$.  We see that the 
determinant $H$ is invariant under $U$.  Thus,
\begin{equation}
x^{\prime 2} + y^{\prime 2} + z^{\prime 2} = x^2 + y^2 + z^2.
\label{chap16-eqno117}
\end{equation}
But for any correspondence, as in (117), there exists an element of 
$SO(3)$ which transforms $xyz$ to $x^{\prime}y^{\prime}z^{\prime}$.  
Thus, we have established a correspondence between every element of 
$SU(2)$, say $U$, and some element of $SO(3)$, call it $O\{U\}$.

Consider the product of transformations $U_1U_2$, then
\begin{equation}
H^{\prime \prime} = \left( U_1 U_2 \right) H \left( U^{\dag}_2 
U^{\dag}_1 \right) = U_1 U_2 HU_2^{\dag} U^{\dag}_1 = U_1 
H^{\prime}U^{\dag}_1.
\end{equation}
Thus, $O\{U_1U_2\} = O\{U_1\}O\{U_2\}$.  That is, the elements 
$O\{U_i\}$ multiply in the same way as the $U_i$.

Now consider a specific element of $SU(2)$,
\begin{equation}
B_z \equiv U_2 \left( {1 \over 2} \varphi \right) = \pmatrix{e^{{1 
\over 2}i\varphi} & 0\cr
0 & e^{-{1 \over 2}i\varphi}\cr}
\label{chap16-eqno118}
\end{equation}
Then,
\begin{equation}
H^{\prime} = \pmatrix{ z , & e^{i\varphi}(x+iy)\cr
e^{-i \varphi}(-iy) , & -z\cr}
\end{equation}
and thus, $x^{\prime} = x \cos \varphi - y \sin \varphi$, 
$y^{\prime} = x \sin \varphi + y \cos \varphi$, and $z^{\prime} = 
z$.  Hence, $O\{B_z\} = O_z(\varphi)$, the rotation by 
$\varphi$ about the $z$ axis, (105).

Now consider another element of $SU(2)$,
\begin{equation}
B_x \equiv U_x \left( {1 \over 2} \theta \right) = 
\pmatrix{\cos {1 \over 2} \theta & i \sin {1 \over 2} \theta\cr
i \sin {1 \over 2} \theta & \cos {1 \over 2} \theta\cr}
\end{equation}
We find here that $x^{\prime} = x , y^{\prime} = y \cos \theta - z 
\sin \theta$, and $z^{\prime} = y \sin \theta + z \cos \theta$, and 
hence, $O\{B_x\} = O_x(\theta)$, the rotation by $\theta$ about the 
$x$ axis, (106).  Similarly,
\begin{equation}
B_y \equiv U_y \left( {1 \over 2} \eta \right) = 
\pmatrix{\cos {1 \over 2} \eta & - \sin {1 \over 2} \eta\cr
\sin {1 \over 2} \eta & \cos {1 \over 2} \eta\cr}
\end{equation}
leads to $O\{B_y\} = O_y(\eta)$, the rotation through an angle $\eta$ 
by the $y$ axis, (107).

Since every proper rotation corresponds to some product of the 
rotation $O\{B_x\}$, $O\{B_y\}$, and $O\{B_z\}$, then there is some 
element $U\epsilon SU(2)$ correspondence to every element 
$O(R)\epsilon SO(3)$.

Thus far, we have established that every element of $SU(2)$ 
corresponds to a unique element of $SO(3)$, and that every element of 
$SO(3)$ corresponds to some element of $SU(2)$, but not necessarily a 
unique element of $SU(2)$.  Now we wish to determine if more than one 
element of $SU(2)$ corresponds to the same element of $SO(2)$.  That 
is, can we have
\begin{equation}
O \left\{ U_1 \right\} = O \left\{ U_2 \right\}
\label{chap16-eqno119a}
\end{equation}
and
\begin{equation}
U_1 \not= U_2.
\label{chap16-eqno119b}
\end{equation}
If (119) is true, then $O\{U_1^{-1}U_2\} = e$, the identity.  Thus, 
we look for a $U \not= e$ such that $O(U) = e$. Applying (114) to 
(116), we find
\begin{equation}
z^{\prime} = \left( \kappa^2 + \lambda^2 \right) z - \left( \mu^2 + 
\nu^2 \right) z + (x ~ {\rm and} ~ y ~{\rm terms} )
\label{chap16-eqno120}
\end{equation}
From (120), we must have $\mu = \nu = 0$, hence $U$ must be of the 
form of $B_z$ in (118).  Thus, from (105) we must have $\varphi = 2 
\pi n$, and from (118) we have just two possible cases
\begin{equation}
e = \pmatrix{1 & o\cr
0 & 1\cr}
\end{equation}
and
\begin{equation}
S = \pmatrix{-1 & 0\cr
0 & -1\cr}
\end{equation}
Thus, each element of $SO(3)$ corresponds to two elements of 
$SU(2)$, $U$ and $SU$.  Note that $S$ commutes with all $U \epsilon 
SU(2)$.  The group ($e,S$) is a subgroup of $SU(2)$.

Consider $B_z$ and $O\{B_z\}$.  We see that as $\varphi$ increases from 
0 to $2\pi$, $B_z$ goes from $e$ to $S$, but $O\{B_z\}$ goes from $e$ 
through various rotations and back to $e$.  Then as $\varphi$ goes 
from $2 \pi$ to $4\pi$, $B_z$ goes from $S$ to $e$, while $O\{B_z\}$ 
again goes through a sequence of rotations $e$ to $e$.  Thus, if we 
regard a physical rotation as a function of the intermediate 
positions, we can distinguish between $O\{U\}$ and $O\{SU\}$.

So far, we have considered only the relation between $U(R)$ and 
proper rotations $O(R)$.  Consider now the inversion $I$.  Since
\begin{equation}
O(I) = \pmatrix{-1 & 0 & 0\cr
0 & -1 & 0\cr
0 & 0 & -1\cr}
\end{equation}
we see from (120) that $\kappa = \lambda = 0$, but then we cannot find 
a $\mu$ and $\nu$ such that $x$ and $y$ simple change sign.  
Consequently, there is no element $U \epsilon SU(2)$ corresponding to 
$O(I)$.  Any improper rotation can be written as $IR$ where $R$ is a 
proper rotation.  Thus,
\begin{equation}
(IR) \left( R^{-1} \right) = I,
\label{chap16-eqno121}
\end{equation}
where $R^{-1}$ is a proper rotation.  If there were any improper 
rotation $IR$ such that $O(IR)$ corresponded to some $U \epsilon 
SU(2)$, then by (121) there would have to be $U \epsilon SU(2)$ 
corresponding to $O(I)$.  Since this is not the case, the set of 
functions $O\{U\}$ corresponding to $U \epsilon SU(2)$ contains only 
proper rotations.

\subsection{Double Point Groups}

In an earlier section, we found that the spin orbital $\psi_{ij}({\bf 
r},\sigma) = \phi_i({\bf r}) \chi_j(\sigma)$ transforms as the direct 
product $D^{\#}_{k\ell , ij}(R) = D_{ki}(R)U_{\ell j}(R)$ where $D$ 
is a representation for the spatial symmetry group.  We found that for 
each spatial transformation $O(R)$ there are two spin transformations 
$U(R)$ and $U(SR)$ so that, for example, a rotation of $2\pi$ 
radians, leads to $D^{\#}_{k\ell , ij}(2\pi) = D_{ki}(e)U_{\ell 
j}(2\pi) = - D^{\#}_{k\ell , ij}(e)$, while a rotation of $4\pi$ 
leads to $D^{\#}(4\pi) = +D^{\#}(e)$.  As a result, the $D^{\#}(R)$ 
do not form a representation of the spatial symmetry group $G$.  
However, we can generalize this symmetry group $G$ to a new group 
${\cal G}^{\#}$ such that $D^{\#}(R)$ is a representation of ${\cal 
G}^{\#}$.  This is done as follows.  Starting with the group ${\cal 
G}^{\#} = \{ e,R_2,R_3,\cdots \}$ we define ${\cal G}^{\#}$ as the 
direct group ${\cal G}^{\#} = \{e,S,R_2,SR_2,R_3,SSR_3, \cdots\}$.  
Denoting $R^{\#}$ as a general element of ${\cal G}^{\#}$, and 
considering this element to operate on spatial and spin 
coordinates $({\bf r},\sigma)$ we can write $R^{\#}=O(R)\times R$, 
where the left part $O(R)$ of the ordered product operates on spatial 
coordinates only, and the $R$ operates on the spin coordinates only.

As we found earlier, $R^{\#} = S$, leads to $O(S) = T_{2\pi} = e$, 
where $T_{2\pi}$ denotes a rotation of $2\pi$ radians. Thus,
\begin{equation}
T^{\#}_{2\pi} = T_{2\pi} \times S = e \times S.
\label{chap16-eqno122}
\end{equation}
Using (122), we obtain $T^{\#}_{4\pi} = T^{\#}_{2\pi} 
T^{\#}_{2\pi} = (T_{2\pi} \times S)(T_{2\pi} \times S) = T_{4\pi} 
\times S^2 = e \times e = e^{\#}$.  Thus, $T^{\#}_{4\pi} = e^{\#}$.

\subsubsection{The ${\cal G}^{\#}$ Groups}

For a rotation $C_n$, we define $D^{\#}_n = C_n \times U_n$ where 
$U_n$ is the spin transformation corresponding to $C_n$.  Thus, 
$(C^{\#}_n)^n = C^n_n \times U^n_n = T_{2\pi} \times U^n_n - 
T_{2\pi} \times S = T^{\#}_{2\pi}$ since $S$ is the spin 
transformation corresponding to $T_{2\pi}$.  Thus, $(C^{\#}_n)^n = e 
\times S$.  Consequently, $(C^{\#}_n)^{2n} = (e \times S)(e \times 
S) = e \times S^2 = e \times e = e^{\#}$ and hence, 
$(C^{\#}_n)^{-k} = (C_n^{\#})^{2n-k} = 
T^{\#}_{2\pi} (C^{\#}_n)^{n-k}$.  This is to be compared with  
$(C_n)^{-k}=(C_n)^{n-k}$ for spatial symmetry groups.

Since $T_{2\pi} = e$ commutes with all spatial transformations, and 
since $S$ commutes with all spin transformations, we see that 
$T^{\#}_{2\pi}$ commutes with all elements of ${\cal G}^{\#}$.

Since there is no transformation of $U(R)$ corresponding to the 
spatial inversion $I$, the spatial inversion leaves $U(R)$ 
invariant.  Thus, we define $I^{\#} = I \times e$.  Since $I^2 = e$, 
we obtain $(I^{\#})^2 = (I \times e)(I \times e) = I^2 \times e = 
e^{\#}$.  

Consider now a reflection, say $\sigma_{yz} = C_{2x}I = IC_{2x}$.  We 
define $\sigma^{\#}_{yz} = C^{\#}_{2x}I^{\#}$ leading to 
$\sigma^{\#}_{yz} =(C_{2x} \times U_{2x})(I \times e) = (C_{2x}I 
\times U_{2x})$.  Since $I$ and $C_2$ commute, we see that 
$\sigma^{\#}_{yz} = (IC_{2x} \times U_{2x}) = (I \times e)(C_{2x} 
\times U_{2x}) = I^{\#}C^{\#}_{2x}$.  Thus, 
\begin{equation}
\left( \sigma^{\#}_{yz} \right)^2 = C^{\#}_{2x} 
\underbrace{I^{\#}I^{\#}}_{e^{\#}} C^{\#}_{2x} = \left( C^{\#}_{2x} 
\right)^2 = T^{\#}_{2\pi}
\end{equation}
leading to $(\sigma^{\#}_{yz})^4  e^{\#}$ and $ 
(\sigma^{\#}_{yz})^3 = T^{\#}_{2\pi} \sigma^{\#}_{yz}$.  Note that the 
above relations are independent of the orientation of the reflection 
plane.

Next we will consider the structure of specific double point groups.

\subsubsection{Specific Double Point Groups}

In our further discussions, we will drop the $\#$.  All operations 
are considered elements of ${\cal G}^{\#}$ and the $\#$ will 
generally be deleted from the group elements.  In addition, $S$ will 
denote $e \times S$ or $T^{\#}_{2\pi}$ of the previous section.  
Since $S$ commutes with all elements of ${\cal G}^{\#}$, it is in a 
class by itself.

If the group ${\cal G}$ contains some element $R$ reversing a $C_2$ 
axis, $RC_2R^{-1} + C_2^{-1}$, then in ${\cal G}^{\#}$, we have 
$RC_2^{\#}R^{-1} = C_2^{\#-1} = SC_2$.  Consequently, $C_2$ and $SC_2$ 
are in the same class for ${\cal G}^{\#}$.  Similarly, if the group 
${\cal G}$ contains some element $R$ reversing a mirror plane 
$\sigma$, then $\sigma$ and $S\sigma$ will be in the same class for 
${\cal G}^{\#}$.

For classes containing higher order rotations, the presence of $S$ 
doubles the number of classes.  Thus, if ${\cal G}$ contains an 
operation reversing the sence of a $C_n$ axis, $RC_nR^{-1} = 
C_n^{-1}$, then $C_n^{\#} = C_n$ and $C_n^{\#-1} = SC_n^{-1}$ will be 
in one class for ${\cal G}^{\#}$, while $C_n^{-1}$ and $C_n$ will be 
in another class.  For groups ${\cal G}$ with the inverison $I$, the 
group ${\cal G}^{\#}$ will contain $I$ and $SI$ in separate classes.

Since $S$ commutes with all elements of the group, we have by Schur's 
lemma that $S$ is represented by a multiple of the unit matrix.  
Since $S^2 = e$, this multiple must be $\pm 1$. If it is $+1$, then 
the representation of ${\cal G}^{\#}$ just corresponds to a 
representation of ${\cal G}$.  In addition, we get new representation 
of ${\cal G}^{\#}$ which do not correspond to those of ${\cal G}$. 
These new representations are all degenerate and are denoted as 
$E_{1/2}$, $E_{3/2}$, etc., where the subscript can be thought of ass 
the quantum number along some axis.

The groups {\bf C}$_n^{\#}$ and {\bf S}$_n^{\#}$ are cyclic of 
order $2n$, and thus, all irreducible representations are 
one-dimensional.

For {\bf C}$_{2v}^{\#}$, we have the classes $\{e\}$, $\{S\}$,
$\{C_{2z},SC_{2z}\}$, $\{\sigma_{xz},S\sigma_{xz}\}$, and
$\{\sigma_{yz},\sigma_{yz}\}$ and the character table is shown in
Table \ref{chap16-tab20}.

For {\bf C}$_{3v}^{\#}$, we have the classes $\{e\}$, $\{{\cal S}\}$,
$\{C_3,{\cal S}C_3^2\}$, $\{C^2_3, {\cal S}C_3\}$, and
$\{3\sigma_v,3{\cal S}\sigma_v\}$, and the character table is shown in
Table \ref{chap16-tab21}.

For {\bf D}$_{2h}^{\#}$, we have the classes $\{e\}$, $\{ {\cal S}\}$,
$\{C_{2z},{\cal S}C_{2z}\}$, $\{C_{2y},{\cal S}C_{2y}\}$,
$\{C_{2x},{\cal S}C_{2x}\}$, and $\{i\}$, $\{{\cal S}i\}$,
$\{\sigma_{xy},{\cal S}\sigma_{xy}\}$, $\{\sigma_{xz},{\cal
S}\sigma_{xz}\}$, $\{\sigma_{yz},{\cal S}\sigma_{yz}\}$, and the
character table, as shown in Table \ref{chap16-tab22}.

Character tables for the double or extended point groups can be found 
in reference 10.

\begin{table}
\caption{Character table for $C^{\#}_{2v}$.}
\label{chap16-tab20}
\begin{tabular}{cccccc}\\ \hline

 & $e$ & $S$ & $2C_{2z}$ & $2 \sigma_{xz}$ & $2 \sigma_{yz}$\cr

$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$B_1$ & 1 & 1 & $-1$ & 1 & $-1$\cr
$B_2$ & 1 & 1 & $-1$ & $-1$ & 1\cr
$E_{1/2}$ & 2 & $-2$ & 0 & 0 & 0\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Character table for $C^{\#}_{3v}$.}
\label{chap16-tab21}
\begin{tabular}{cccccc}\\ \hline

& $e$ & $S$ & $2C_3$ & $2C^2_3$ & $6\sigma_v$\cr

$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & 1 & $-1$\cr
$E$ & 2 & 2 & $-1$ & $-1$ & 0\cr
$E_{1/2}$ & 2 & $-2$ & 1 & $-1$ & 0\cr
$E_{3/2}$ & 2 & $-2$ & $-2$ & 2 & 0\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Character table for $D^{\#}_{2h}$.}
\label{chap16-tab22}
\begin{tabular}{ccccccccccc}\\ \hline

& $e$ & $S$ & $2C_{2z}$ & $2C_{2y}$ & $2C_{2x}$ & $i$ & $Si$ & $2 
\sigma_{xy}$ & $2\sigma_{xz}$ & $2\sigma_{yz}$\cr

$A_g$ & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\cr
$B_{1g}$ & 1 & 1 & 1 & $-1$ & $-1$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$B_{2g}$ & 1 & 1 & $-1$ & 1 & $-1$ & 1 & 1 & $-1$ & 1 & $-1$\cr
$B_{3g}$ & 1 & 1 & $-1$ & $-1$ & 1 & 1 & 1 & $-1$ & $-1$ & 1\cr
$E_{1/2g}$ & 2 & $-2$ & 0 & 0 & 0 & 2 & $-2$ & 0 & 0 & 0\cr
$A_u$ & 1 & 1 & 1 & 1 & 1 & $-1$ & $-1$ & $-1$ & $-1$ & $-1$\cr
$B_{1u}$ & 1 & 1 & 1 & $-1$ & $-1$ & $-1$ & $-1$ & $-1$ & 1 & 1\cr
$B_{2u}$ & 1 & 1 & $-1$ & 1 & $-1$ & $-1$ & $-1$ & 1 & $-1$ & 1\cr
$B_{3u}$ & 1 & 1 & $-1$ & $-1$ & 1 & $-1$ & $-1$ & 1 & 1 & $-1$\cr
$E_{1/2u}$ & 2 & $-2$ & 0 & 0 & 0 & $-2$ & 2 & 0 & 0 & 0\cr
\hline
\end{tabular}
\end{table}

\subsection{Coupling of Spatial and Spin Functions}

So far, in discussing polyatomic molecules, we have neglected the 
coupling of the spin with the spatial part of the wavefunction.  Upon 
including spin interactions, we must mix various functions like (123)
\begin{equation}
\psi_{ij} ( {\bf r} , \sigma ) = \phi_i ( {\bf r} ) \chi_j ( \sigma 
)
\label{chap16-eqno123}
\end{equation}
together to get the exact wavefunction.  If the spatial symmetry 
group is $G$, the resulting total wavefunction belongs to the double 
group ${\cal G}^{\#}$.  Since the basis functions are products of 
spatial and spin terms, as in (123), we need only decompose the spin 
function in terms of ${\cal G}^{\#}$ and take the direct product of 
the spatial and spin terms to find the total symmetry. For atoms, 
this is analogous to combining $L$ and $S$ to find the symmetries $J$ 
for the total wavefunction.
\vfill\eject

\subsubsection{Decomposing the Spin Function}

For total spin $S$, there are $2S+1$ different states with 
projections $M_a = S,S-1, \cdots , -S$ along any axis.  Thus, under a 
rotation of $\phi$ about the axis, the character is
\begin{eqnarray}
\chi^S(\varphi) &=& e^{iS\varphi} + e^{i(S-1)\varphi} + \cdots + 
e^{-iS\varphi}\cr
&=& 1 + 2 \cos \varphi + 2 \cos 2 \varphi + \cdots + 2 \cos S\varphi 
~ {\rm if} ~ S ~ {\rm is ~ integer}\cr
&=& 2 \cos {\varphi \over 2} + 2 \cos {3 \varphi \over 2} + \cdots + 2 
\cos S \varphi ~ {\rm if} ~ S ~ {\rm is ~ half ~ - ~ integer}\cr
&=& {\sin\left( S + {1 \over 2} \right) \over \sin {1 \over 2} 
\varphi}
\end{eqnarray}
Thus, for $D^{\#}_4$ we get the results shown in Table
\ref{chap16-tab23}.  Consequently,
\begin{eqnarray}
S &=& {1 \over 2} \rightarrow E_{{1 \over 2}}\cr
S &=& 1 \rightarrow A_2 + E\cr
S &=& {3 \over 2} \rightarrow E_{{1 \over 2}} + E_{{3 \over 2}}
\end{eqnarray}
The results for such decompositions of spin functions for some
important point groups, are listed in Table \ref{chap16-tab24}.  These
reductions for $S \leq {5 \over 2}$, and for additional point groups,
can be found in reference 11.  For larger $S$, see reference 12.

\begin{table}
\caption{Results for $D^{\#}_4$.}
\label{chap16-tab23}
\begin{tabular}{cccccccc}\\ \hline

&$e$&$S$&$\{C^2_4,SC^2_4\}$&$\{C_4,SC^3_4\}$&
$\{C^3_4,SC_4\}$&$\{2C_2,2SC_2\}$&$\{2C^{\prime}_2,2SC^{\prime}_2\}$\cr

$\phi$ &0 & $2 \pi$ & $\pi$ & $\pi/2$ & $3\pi/2$ & $\pi$ & $\pi$\cr
$S = {1 \over 2}$& 2 & $-2$ & 0 & $\sqrt{2}$ & $-\sqrt{2}$&0&0\cr
$S = 1$ & 3 & 3 & $-1$ & 1 & 1 & 1 & 1\cr
$S = {3 \over 2}$ & 4 & $-4$ & 0 & 0 & 0 & 0 & 0\cr

\hline
\end{tabular}
\end{table}

\subsubsection{Applications}

The lower states of CH$_2$ are ${^1A}_1(\sigma^2)$, ${^3B}_1(\sigma 
\pi)$, and ${^1B}_1(\sigma\pi)$ with {\bf C}$_{2v}$ symmetry.  Combining 
the spatial and spin symmetries, leads to $\sigma^2: {^1A_1} 
\rightarrow A_1$, and $\sigma \pi : {^3B}_1 \rightarrow B_2 + A_1 + A_2$, 
and ${^1B}_1 \rightarrow B_1$.  Thus, including spin orbit coupling, 
does not mix the singlet and triplet states of the same 
configuration $(\sigma\pi)$.  However, it does couple 
${^1A}_1(\sigma^2)$ and ${^3B}_1(\sigma\pi)$. 

The excited states, of formaldehyde, which has {\bf C}$_{2v}$ 
symmetry, are $n \pi^* : {^3A}_2 , {^1A}_2$ and $\pi \pi^* : 
{^3A}_1 , {^1A}_1$.  Actually, in the excited states, the geometry 
distortes to {\bf C}$_s$ symmetry, we ignore this here.  Combining 
spatial and spin symmetries leads to $n \pi^* : {^3A}_2 \rightarrow 
A_1 + B_2 - B_1$ and ${^1A}_2 \rightarrow A_2$ and $\pi \pi^* : 
{^3A}_1 \rightarrow A_2 + B_1 + B_2$ and ${^1A}_1 \rightarrow A_1$.  
Again, there is no mixing of different spin states of the same spatial 
configuration.  However, ${^1A}_2(n\pi^*)$ is coupled with 
${^3A}_1(\pi\pi^*)$, while ${^1A}_1(\pi\pi^*)$ is coupled with 
${^3A}_2(n\pi^*)$.  This intermixing of $n\pi^*$ and $\pi\pi^*$ 
states, of different spin via spin orbit interactions, is a general 
result and of importance in understanding intersystem crossing 
rates.  In carrying out direct products of the spatial and spin 
representations, the tables in reference 11 are useful.

Consider, next, the spin functions corresponding to such 
representations. For example, $S = 1$, leads to
\begin{equation}
{{\alpha \alpha \atop {1 \over \sqrt{2}}} \atop \beta \beta}
\left( \alpha \beta + \beta \alpha \right)
\label{chap16-eqno124}
\end{equation}
What are the combinations of these functions corresponding to the 
$A_2$, $B_1$, and $B_2$ representations in {\bf C}$^{\#}_{2v}$?  The 
operators of {\bf C}$_{2v}$ are $e$, $C_{2z}$, $\sigma_{xz}$, and 
$\sigma_{yz}$.  Writing $\sigma_{xz} = i C_{2y}$ and $\sigma_{yz} = i 
C_{2x}$, with $i$ being the inversion operator, we see that the spin 
transformations corresponding to $C_{2z}$, $\sigma_{xz}$, and 
$\sigma_{yz}$ are
\begin{eqnarray}
C_{2z} & \rightarrow B_z = U_z \left( {\pi \over 2} \right) = 
\pmatrix{i & 0\cr
0 & -i\cr}\cr
\sigma_{x} & \rightarrow B_y = U_y \left( {\pi \over 2} \right) = 
\pmatrix{0 & -1\cr
1 & 0\cr}\cr
\sigma_{yz} & \rightarrow B_x = U_x \left( {\pi \over 2} \right) = 
\pmatrix{0 & i\cr
i & 0\cr}
\end{eqnarray}
Thus, recombining the functions (124) as $\chi_1 = ( \alpha \alpha - 
\beta \beta )$, $\chi_2 = ( \alpha \alpha + \beta \beta )$, and 
$\chi_3 + ( \alpha \beta + \beta \alpha )$, ignoring normalization, we 
see that $C_{2z}\chi_1 = - \chi_1,\sigma_{xz}\chi_1 = - \chi_1$, 
$C_{2z}\chi_2 = - \chi_2 ,\sigma_{xz}\chi_2 = \chi_2$, and 
$C_{2z}\chi_3 = + \chi_3 ,\sigma_{xz}\chi_3 = - \chi_3$.  Thus, the 
symmetries are as follows $A_2 : (\alpha \beta + \beta \alpha)$, 
$B_1 : (\alpha \alpha + \beta \beta)$, and $B_2: (\alpha \alpha - 
\beta \beta)$.


\begin{table}
\caption{Decompositions for spin functions.}
\label{chap16-tab24a}
\begin{tabular}{ccccc}\\ \hline

S & $C_s$ & $C_{2h}$ & $C_{2v}$ & $D_{2h}$\cr

0 & $A^{\prime}$ & $A_g$ & $A_1$ & $A_g$\cr
${1 \over 2}$ & $E_{{1 \over 2}}$ & $E_{{1 \over 2}g}$ & 
$E_{{1 \over 2}}$ & $E_{{1 \over 2}g}$\cr 
1 & $A^{\prime}+2A^{\prime\prime}$ & $A_g + 2B_g$ & $A_2 + B_1 + 
B_2$\cr
${3 \over 2}$ & $2E_{{1 \over 2}}$ & $2E_{{1 \over 2}g}$ & $2E_{{1 \over 
2}}$\cr 
2 & $3A^{\prime}+2A^{\prime\prime}$ & $3A_g + 2B_g$ & $2A_1 + A_2 + 
B_1 + B_2$\cr
${5 \over 2}$ & $3E_{{1 \over 2}}$ & $3E_{{1 \over 2}g}$ & $3E_{{1 \over 
2}}$\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Decompositions for spin functions, cont'd.}
\label{chap16-tab24b}
\begin{tabular}{cccc}\\ \hline

S & $D_{3d}(C_{3v})$ & $D_{3h}$ & $D_{4h}(D_4,C_{4v},D_{2d})$\cr

0 & $A_{1g}$ & $A^{\prime}_1$ & $A_{1g}$\cr
${1 \over 2}$ & $E_{{1 \over 2}g}$ & $E_{{1 \over 2}}$ & $E_{{1 \over 
2}g}$\cr
1 & $A_{2g}+E_g$ & $A^{\prime}_2+E^{\prime\prime}$ & $A_{2g} + E_g$\cr
${3 \over 2}$ & $E_{{1 \over 2}g} + E_{{2 \over 2}}$ & $E_{{1 \over 
2}} + E_{{3 \over 2}g}$ & $E_{{1 \over 2}g} + E_{{3 \over 2}g}$\cr
2 & $A_{1g}+2E_g$ & $A_1 + E^{\prime}+E^{\prime\prime}$ & 
$A_{1g}+B_{1g}+B_{2g}+E_g$\cr
${5 \over 2}$ & $2E_{{1 \over 2}}+E_{{3 \over 2}}$ & $E_{{1 \over 
2}}+E_{{3 \over 2}g} + E_{{5 \over 2}g}$ & $E_{{1 \over 2}g} + 2E_{{3 
\over 2}g}$\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{Decompositions for spin functions, cont'd.}
\label{chap16-tab24c}
\begin{tabular}{ccccc}\\ \hline

S & $D_{6h}(D_6,C_{6v})$ & $D_{\infty h}(C_{\infty v})$ & 
$O_h(T_d)$ & $O(3)$\cr

0 & $A_{1g}$ & $\Sigma^+_g$ & $A_{1a}$ & $S_g$\cr
${1 \over 2}$ & $E_{{1 \over 2}g}$ & $E_{{1 \over 2}g}$ & $E_{{1 \over 
2}g}$ & -\cr
1 & $A_{2g}+E_{1g}$ & $\Sigma^-_g \Pi_g$ & $T_{1g}$ & $P_g$\cr
${3 \over 2}$ & $E_{{1 \over 2}g} + E_{{3 \over 2}g}$ & $E_{{1 \over 
2}g} + E_{{3 \over 2}g}$ & $G_{{3 \over 2}g}$\cr
2 & $A_{1g} + E_{1g} + E_{2g}$ & $\Sigma^+_g+\Pi_g+\Delta_g$ & 
$E_g+T_{2g}$ & $D_g$\cr
${5 \over 2}$ & $E_{{1 \over 2}g} + E_{{3 \over 2}g} + E_{{5 \over 
2}g}$ & $E_{{1 \over 2}g} + E_{{3 \over 2}g} + E_{{5 \over 
2}g}$ & $E_{{5 \over 2}g} + G_{{5 \over 2}g}$ & -\cr
\hline
\end{tabular}
\end{table}

\section{Appendices}

\subsection{The Orthogonality Theorem}

\subsubsection{Introduction}

For orthogonality of representation matrices
\begin{equation}
\sum_{R \epsilon G} D^{\mu}_{i\ell} (R) D^{\nu*}_{jm} (R) = {g \over 
d^{(\mu)}} \delta_{\mu \nu} \delta_{ij} \delta_{\ell m}
\end{equation}
and
\begin{equation}
\sum_{\mu ij} d^{\mu} D^{\mu}_{ij}(R) D^{\mu*}_{ij}(R^{\prime}) = 
gd_{R,R^{\prime}}
\end{equation}

For orthogonality of characters
\begin{equation}
\sum^k_i g_i \chi_i^{(\mu)} \chi_i^{(\nu)} = g \delta^{\mu \nu}
\end{equation}
where $i$ is summed over all $k$ classes
\begin{equation}
\sum^r_{\nu} \chi_i^{(\nu)} \chi_j^{(\nu)} = {g \over g_j} \delta_{ij}
\end{equation}
where $\nu$ is summed over all $r$ irreducible representations.

For decomposition of a representation
\begin{equation}
\chi_i = \sum_{\mu} a_{\mu} \chi_i^{(\mu)}
\end{equation}
where
\begin{equation}
a_{\mu} = {1 \over g} \sum_i g_i \chi_i^{*(\mu)} \chi_i
\end{equation}
is the number of times the $\mu$ irreducible representation occurs in 
the given representation.

Also, $r - k$, i.e., the number of classes of a group equals the 
number of irreducible representations, and
\begin{equation}
g = \sum_{\nu} \left[ d^{(\nu)} \right]^2
\end{equation}
With each fact, we can obtain the degrees of the irreducible 
representations of a group.  Adding orthogonality of characters, and 
some knowledge of the group, allows us to construct a character table.

\subsubsection{Schur's Lemmas}

We derive here the orthogonality theorem so crucial in our applications 
of the theory of the representations of groups.  First, we establish 
some important relationships referred to as Schur's lemmas.  We will 
generally use the Einstein summation condition in this section.

Let $\{\psi_i; i = 1 ,\cdots , d\}$ be a basis for a $d$-dimensional 
representation of $G$, $R \psi_i = \psi_j D_{ji}(R)$ or ${\hat{R}} 
\underline{\psi} = \underline{\psi} \underline{D}$. 

Assume that $D$ is reducible.  This means that we can transform 
$\{\psi_i\}$ to a smaller set $\{\phi_i;i=1,\cdots , d^{\prime}\}$, 
where $d^{\prime} < d$, that is also a basis for a representation
\begin{equation}
R \phi_i = \phi_j D_{ji} (R)
\label{chap16app-eqno1a}
\end{equation}
or
\begin{equation}
{\hat{R}} \underline{\phi} = \underline{\phi} 
\underline{D}^{\prime}
\label{chap16app-eqno1b}
\end{equation}
We will write the transformation from $\{\psi_i\}$ to $\{\phi_i\}$ as
\begin{equation}
\phi_i = \psi_j A_{ji}
\label{chap16app-eqno2a}
\end{equation}
or
\begin{equation}
\underline{\phi} = \underline{\psi} \underline{A},
\label{chap16app-eqno2b}
\end{equation}
where $A$ is a rectanglar matrix containing $d$ rows and $d^{\prime}$ 
columns.  The transformed function $R \phi_i$ can be decomposed in 
terms of $\{\psi_j\}$ in two ways.  Expanding $\phi_i$ using (2) and 
then operating with ${\hat{R}}$, leads to
${\hat{R}} \phi_i = {\hat{R}} ( \psi_j A_{ji} ) = ( 
{\hat{R}} \psi_j ) A_{ji} = \psi_k D_{kj} A_{ji}$
or
${\hat{R}} \underline{\phi} = {\hat{R}} ( \underline{\psi} 
\underline{A} ) = \psi ( \underline{DA} )$.
On the other hand, applying ${\hat{R}}$ to $\psi$ first and then 
expanding the result in terms of $\{\psi_j\}$, leads to
\begin{equation}
\left( {\hat{R}} \psi_j \right) = \phi_j D^{\prime}_{ji} = \psi_k 
A_{kj} D^{\prime}_{ji}
\end{equation}
or
\begin{equation}
{\hat{R}} \underline{\phi} = \phi \underline{D}^{\prime} = \psi 
\underline{AD}^{\prime}
\label{chap16app-eqno3}
\end{equation}
Since both expansions describe the same function ${\hat{R}}\phi_i$, and 
since the $\{\psi_i\}$ are linearly independent, we obtain
\begin{equation}
\underline{D} (R) \underline{A} = \underline{AD}^{\prime} (R)
\label{chap16app-eqno4a}
\end{equation}
or
\begin{equation}
D_{ij}(R) A_{jk} = A_{ij} D^{\prime}_{jk}(R).
\label{chap16app-eqno4b}
\end{equation}
Equation (4) must be true for all $R$, placing a severe restriction 
upon the form of $A$, which is independent of $R$.  Schematically, we 
can represent these two sequences, as in Figure \ref{chap16app-fig1}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16app-fig1}
\end{figure}

It is easy to misinterpret Figure \ref{chap16app-fig1}.  Starting from
the point $R\phi$, Figure \ref{chap16app-fig1} says that $R \phi =
\phi D^{\prime}$ and $\phi = \psi A$, leading then to (3), $R \phi =
\psi AD^{\prime}$.  Thus, we start at the final point and go
backwards, leading to $\psi AD^{\prime} = \psi DA$ and hence, to (4).

For any irreducible representation $\{D(R)\}$, there exists an $A$ 
such that (1) is satisfied for all $R$.  Conversely, we now start with 
two sets of matrices $\{D(R)\}$ and $\{D^{\prime}(R)\}$.  We assume 
that $\{D\}$ forms a representation of $G$ and that there exists a 
$d$ by $d^{\prime}$ matrix $A$, such that the matrix equation (4) is 
satisfied for all $R \epsilon G$.  Multiplying (4) by $\psi_i$ and 
summing over $i$, leads to
\begin{equation}
\psi_i D_{ij}(R)A_{jk} = \psi_i A_{ij} D^{\prime}_{jk} (R)
\label{chap16app-eqno5a}
\end{equation}
or
\begin{equation}
\underline{\psi DA} = \underline{\psi AD}^{\prime}
\label{chap16app-eqno5b}
\end{equation}
which must be satisfied for the $d$-dimensional space $\{\psi_i\}$.  
But defining a new set of functions $\{\theta_j;j=1,\cdots 
,d^{\prime}\}$ by the relation $\theta_j = \psi_iA_{ij}$, we see 
that (5) leads to
\begin{equation}
{\hat{R}} \theta_k = \theta_j D^{\prime}_{jk}(R)
\label{chap16app-eqno6}
\end{equation}
for all $R \epsilon G$.  If $A \not= 0$, (6) says that $\{\theta_j\}$ 
is a basis for all $d^{\prime}$-dimensional representation of $G$.  
Thus, if $d^{\prime} < d$, this means that the representation is 
$\{D(R)\}$ is irreducible.

Two special cases of $\underline{A}$ must now be considered.  If 
$\det \underline{A} = 0$, implying that $d^{\prime} = d$, the function 
of $\underline{\theta} = \underline{\psi A}$ are redundant, i.e., the 
new basis functions $\theta_i = \psi_jA_{ji}$ are not linearly 
independent.  In this case, we can find a subset of $\{\theta_i\}$ 
containing only linearly independent basis functions, say $\{ 
\theta^{\prime}_j\}$.  Defining $\underline{\theta}^{\prime} = \psi 
\underline{A}$, we find that (6) still applies and hence, 
$\{\theta^{\prime}_j\}$ is a basis for a reduced representation.

The other special case is $\underline{A} = 0$.  In this case, $\psi 
\underline{A} = 0$ and hence, no functions are included in the set 
$\{ \theta_i \}$.  Consequently, (6) is trivial and we have not 
obtained a basis for a reduced representation.

In summary, if (4) is satisfied by a nonzero rectangular matrix $A$ 
with $d^{\prime} < d$ for all $R$, then the representation $\{D(R)\}$ 
is reducible.

\begin{description}
\item[Lemma I]  If $\{ \underline{D} \}$ and $\{ \underline{D}^{\prime}\}$ 
are two irreducible representations of $G$ having different 
dimensions, and if $\underline{A}$ satisfies $\underline{D}(R) 
\underline{A} = \underline{AD}^{\prime}(R)$ for all $R \epsilon G$, 
then it follows that $\underline{S} = 0$.

\item[Lemma II]  If $\{ \underline{D} \}$ and $\{ \underline{D}^{\prime}\}$ 
are two irreducible representations of $G$ having the same dimension 
of if $\underline{A}$ satisfies $\underline{D}(R) 
\underline{A} = \underline{AD}^{\prime}(R)$ for all $R \epsilon G$, 
then either $\underline{D}$ and $\{ \underline{D}^{\prime}\}$ are 
equivalent or $\underline{A} = 0$.

\item[Lemma III]  If $\{ \underline{D} \}$ is an irreducible representations 
of $G$, and if $\underline{AD}(R) = \underline{D}(R) 
\underline{A}$ for all $R \epsilon G$, 
then $\underline{A} = \lambda \underline{1}$, where $\lambda$ is a 
constant and $\underline{1}$ is the unit matrix.
\end{description}

Before proceeding to prove these lemmas, we should examine their 
meaning.  Lemmas I and II imply that given a basis $\{\psi_i\}$ for an
irreducible representation $\{D\}$ and a basis $\{\phi_i\}$ for a 
different inequivalent, irreducible representation $\{D^{\prime}\}$, 
there is no transformation $\underline{A}$ connecting these bases.  
For example, given a $g$ basis function $\phi_g$ and a $u$ basis 
function $\phi_u$ for H$_2$, there is no rotation, inversion, or 
reflection of the coordinate system that can transform $\phi_g$ 
into $\phi_u$.  This means that the space spanned by all the 
eigenfunctions of the Hamiltonian can be partitioned into subspaces, 
each of which form bases for different irreducible representations.  
Of $A \not= 0$, then assumptions of lemma III imply that 
$\underline{\psi}$ and $\underline{\phi} = \underline{\psi A}$ both 
form basis for the same irreducible representation.

As we saw earlier, a basis formation usually leads to a new set of 
matrices $\{D^{\prime}\}$ related by $\underline{D}(R) 
\underline{A} = \underline{AD}^{\prime}(R)$.  However, in lemma III 
we insist that the transformed basis leads to the same representation 
matrices, that is, $D^{\prime}(R) = D(R)$.  The conclusion of lemma 
III is that, aside from the multiplicative constant $\lambda$, the 
basis functions of $\underline{\psi}$ and of $\underline{\phi}$ must 
be identical.  Lemma III also implies that the only matrices commuting 
with all matrices of an irreducible representation must be 
proportional to the unit matrix.

\subsubsection{Lemma Proofs}

To prove lemma I, note that we found that if $d^{\prime} < d$ and 
$\underline{A} \not= 0$, then (4) for all $R$ implied that 
$\underline{D}$ is reducible.  Since this contradicts the assumption 
that $\underline{D}$ is irreducible, then we must have 
$\underline{A} = 0$. 

We previously showed that (4) for all $R$ implies that the basis $\{ 
\psi\}$ for $\{D\}$ and the basis $\{\phi\}$ for $\{D^{\prime}\}$ are 
related by $\underline{\phi} = \underline{\psi A}$ if $\underline{A} \not= 
0$.  That is, the $d$ functions of $\{\phi\}$ are linear combinations 
of the $d$ functions of $\{\psi\}$.  Thus, from Section 16.4, the 
representations $\{D\}$ and $\{D^{\prime}\}$ are equivalent.  If 
$\{D\}$ and $\{D^{\prime}\}$ are equivalent, then there exists an 
$\underline{A} \not= 0$ such that $\underline{\phi} = \underline{\psi 
A}$ and hence, we obtain $\underline{DA} = \underline{AD}^{\prime}$.  
If $D$ and $D^{\prime}$ are not equivalent, then it must be that 
$\underline{A} = 0$, providing lemma II.

We did not consider the probability that $\underline{A} \not= 0$ and 
$\det A = 0$.  The reason is that $\det \underline{A} = 0$ and 
$\underline{A} \not= 0$ would imply that $\{D^{\prime}\}$ is reducible, 
which contradicts the assumption that $D^{\prime}$ is irreducible.

To prove lemma III, note that since $\underline{AD} = \underline{DA}$ 
for all $D(R)$ of the representation, we know that either 
$\underline{\psi}$ and $\underline{\phi} = \underline{\psi A}$ lead to 
the same representation matrices $\{D(R)\}$ or $\underline{A} = 0$.  
If $\det A = 0$ for the first case, then it follows from the 
discussion that the representation $\{D\}$ is reducible.  Since this 
violates the assumption of lemma III, we see that the two choices 
are $\det \underline{A} \not= 0$ and $\underline{A} = 0$.

If $\det \underline{A} \not= 0$, then the secular equation 
$\det(\underline{A} - \lambda \underline{1}) = 0$ has a solution for a 
particular value of $\lambda$.  Defining a new matrix 
$\underline{A}^{\prime} \equiv \underline{A} - \lambda 
\underline{1}$, we find that
\begin{equation}
\underline{A}^{\prime} \underline{D} = \underline{DA}^{\prime}
\label{chap16app-eqno7}
\end{equation}
for all $R \epsilon G$.  From the arguments given, we know that (7) 
implies $\det A^{\prime} \not= 0$ or $A^{\prime} = 0$.  Since we 
constructed $A^{\prime}$ in such a way that $\det A^{\prime} = 0$, 
then it must be that $\underline{A}^{\prime} = 0$ and hence, that
$\underline{A} = \lambda \underline{1}$.

We are now ready to derive the orthogonality theorem.  Consider a 
representation $\{D(R)\}$ of $G$ and define a matrix $\underline{A}$ as
\begin{equation}
\underline{A} = \sum_{R} \underline{D} (R) \underline{XD} \left( 
R^{-1} \right)
\label{chap16app-eqno8}
\end{equation}
where $\underline{X}$ is an arbitrary $d$ by $d$ matrix  This 
matrix $\underline{A}$ has the property that for any $S \epsilon G$,
\begin{equation}
\underline{D} (S) \underline{AD} \left( S^{-1} \right) = \sum_{R} 
\underbrace{\underline{D}(S)\underline{D}(R)}_{\underline{D}(SR)} 
\underline{X} \underbrace{\underline{D}\left(R^{-1}\right) 
\underline{D} \left(S^{-1}\right)}_{\underline{D} \left[ \left( SR 
\right)^{-1}\right]}
\end{equation}
Since $SR = T$ is also in $G$, we obtain
\begin{equation}
\underline{D} (S) \underline{AD} \left( S^{-1} \right) = \sum_{R} 
\underline{D} (T) \underline{XD} \left( T^{-1} \right)  \sum_{T} 
\underline{D} (T) \underline{XD} \left( T^{-1} \right) = \underline{A}
\end{equation}
where the rearrangement theorem has been used in rearranging the 
sum.  Therefore, $\underline{D}(S)\underline{A} = \underline{AD}(S)$ 
for all $S \epsilon G$ and hence, by lemma III, we know that
\begin{equation}
\underline{A} = \lambda \underline{1}
\label{chap16app-eqno9}
\end{equation}
where $\lambda$ is not yet determined, as it depends upon 
$\underline{X}$.  So far $\underline{X}$ is arbitrary, but now we take 
it to be
\begin{equation}
X_{pq} = \delta_{p \ell} \delta_{qm}
\label{chap16app-eqno10}
\end{equation}
that is, only the $\ell m$ element of $\underline{X}$ is nonzero.  
Next, we want to evaluate $\lambda$, which we denote as $\lambda_{\ell 
m}$ to indicate which $\underline{X}$ it is associated with.  Using 
(9) and (10), (8) becomes
\begin{equation}
A_{ij} = \sum_{R} D_{i\ell} (R) D_{mj} \left( R^{-1} \right) = 
\lambda_{\ell m} \delta_{ij}
\label{chap16app-eqno11}
\end{equation}
Setting $i = j$ in (11) and summing over all $i$, leads to
\begin{equation}
\lambda_{\ell m} = \sum_{R} \sum_{i} D_{mi} \left( R^{-1} \right) 
D_{i \ell} (R) = \sum_{R} D_{m\ell} \left( R^{-1}R \right) = \sum_{R} 
D_{m\ell} (e) = \sum_{R} \delta_{m\ell} = g \delta_{\ell m}.
\end{equation}
Thus, 
\begin{equation}
\lambda_{\ell m} = \delta_{\ell m} {g \over d}
\end{equation}
and hence, from (8) and (10), leads to
\begin{equation}
\sum_{R} D_{i\ell} (R) D_{mj} \left( R^{-1} \right) = {g \over d} 
\delta_{ij} \delta_{\ell m}
\label{chap16app-eqno12}
\end{equation}
where $g$ is the order of the group $G$ and $d$ is the degree of the 
irreducible representation $\{D(R)\}$.

Now consider a new matrix $\underline{A}$
\begin{equation}
\underline{A} = \sum_{R} \underline{D}^{(\mu)} (R) 
\underline{XD}^{(\nu)} \left( R^{-1} \right)
\end{equation}
involving two different irreducible representations $\mu$ and $\nu$.  
Then, just as before, $\underline{D}^{(\mu)} (S) 
\underline{AD}^{(\nu)}(S^{-1})=\underline{A}$ and hence, 
$\underline{D}^{(\mu)} (S)\underline{A} = \underline{AD}^{(\nu)}(S)$ 
for all $S \epsilon G$.  Thus, by lemma I and II, we have 
$\underline{A} = 0$, if $\mu \not= \nu$, leading to
\begin{equation}
\sum_{R} D^{(\mu)}_{i \ell} (R) D^{(\nu)}_{mj} \left( R^{-1} 
\right) = 0
\label{chap16app-eqno13}
\end{equation}
where $\mu \not= \nu$.  Combining (12) and (13) leads to
\begin{equation}
\sum_{R} D^{(\mu)}_{i \ell} (R) D^{(\nu)}_{mj} \left( R^{-1} 
\right) = {g \over d_{\mu}} \delta^{\mu\nu} \delta_{ij} 
\delta_{\ell m}
\label{chap16app-eqno14}
\end{equation}
We will generally use orthonormal basis functions $\langle \psi_i | 
\psi_j \rangle = \delta_{ij}$ and consequently, the 
representation matrices will be unitary $\underline{D}(R^{-1}) = 
\underline{D}^{\dag}(R)$.  Thus, (14) becomes
\begin{equation}
\sum_{R} D^{(\mu)}_{i \ell} (R) D^{(\nu)*}_{jm} (R) = {g \over 
d_{\mu}} \delta^{\mu \nu} \delta_{ij} \delta_{\ell m}
\label{chap16app-eqno15}
\end{equation}
In (14) and (15), the subscripts of 
$D$ correspond to the delta functions on the right side of the 
equation.  This is to emphasize the relationships, which are easily 
forgotten.

\subsubsection{Deductions from the Orthogonality Theorem}

Consider the quantities
\begin{equation}
\Lambda_{\mu ij,R} \equiv \sqrt{{d_{\mu} \over g}} D^{\mu}_{ij} (R)
\end{equation}
where $\mu ij$ is considered as one index $\lambda$.  The 
orthogonality theorem (15) states that
\begin{equation}
\sum_{R} \Lambda_{\lambda,R} \lambda^*_{\eta,R}  = \delta_{\lambda 
\eta}.
\label{chap16app-eqno16}
\end{equation}
That is, considering the set of quantities $\{ \Lambda_{\lambda R},R 
\epsilon G\}$ as a $g$ dimensional vector, 
$\underline{\Lambda}_{\lambda}$, the vectors with different $\lambda$ 
are orthogonal.  Since the $\underline{\Lambda}_{\lambda}$ are 
orthogonal, the number of different vectors, i.e., different values 
of $\lambda$,
\begin{equation}
\sum_{\mu} \left( d^{\mu} \right)^2
\end{equation}
must not be greater than $g$,
\begin{equation}
\sum_{\mu} \left( d^{\mu} \right)^2 \leq g.
\label{chap16app-eqno17}
\end{equation}
However, we can always construct $g$ orthonormal vectors in a $g$ 
dimensional space.  Hence, if the inequality were to hold in (17), we 
could define further orthogonal $\underline{\Lambda}_{\lambda}$ 
vectors until
\begin{equation}
\sum_{\mu} \left( d^{\mu} \right)^2 = g
\label{chap16app-eqno18}
\end{equation}
In this case, the new $\Lambda_{\lambda R}$ would lead to new 
quantities $D^{\mu}_{ij}(R)$ and we would obtain new irreducible 
representations.  Hence, (18) must hold.

The above orthogonality theorem refers only to orthogonality between 
the rows of $\Lambda_{\lambda,R}$.  However, writing (16) in matrix 
notation, $\underline{\Lambda \Lambda}^{\dag} = 1$, we see that 
$\underline{\Lambda}^{\dag} = \underline{\lambda}^{-1}$.  At this 
point, it was important to have (18).  Hence, we have 
$\underline{1} = \underline{\lambda}^{-1} \underline{\lambda} = 
\underline{\Lambda}^{\dag} \underline{\lambda}$ or
\begin{equation}
\sum_{k} \Lambda^*_{ki} \Lambda_{kj} = \delta_{ij}.
\end{equation}
Therefore, (16) leads to
\begin{equation}
\sum_{\lambda} \Lambda_{\lambda R} \Lambda_{\lambda S} = \delta_{RS}.
\end{equation}
Substituting for $\Lambda$ above, we get the orthogonality relation 
for the columns
\begin{equation}
\sum_{\mu ij} D^{\mu} D^{\mu}_{ij} (R) D^{\mu}_{ij} \left( R^{\prime} 
\right)^* = g \delta_{R,R^{\prime}}
\end{equation}

From these orthogonality theorems for representation matrices, we can 
easily obtain orthogonality theorems for characters.  Starting with 
(15), setting $i = \ell$ and $j = m$, and then summing over $i$ and 
$j$, we obtain
\begin{equation}
\sum_{R} \chi^{(\mu)} (R) \chi^{*(\nu)} (R) = g 
\delta^{\mu \nu}
\label{chap16app-eqno19}
\end{equation}
Since $\chi^{(\mu)}(R)$ is the same for all elements of the same 
class, (19) becomes
\begin{equation}
\sum^{k}_{i=1} g_i \chi_i^{(\mu)} \chi^{*(\nu)} = g 
\delta^{\nu\mu},
\label{chap16app-eqno20}
\end{equation}
where $g_i$ is the number of elements in class $i$ and $k$ is the 
total number of classes.  If there are $k$ classes in $G$ and we 
consider $\chi^{\mu}_i$ for fixed $\mu$ as a $k$-dimensional vector, 
this orthogonality theorem leads to $r \leq k$.  Here $r$ is the 
number of different irreducible representations.

We can now proceed, as before, to define vectors $\Lambda_{\mu i} = 
\sqrt{g_i} \chi^{\mu}_i$ and use the unitarity of the $\Lambda$ 
matrix to derive from (20) that
\begin{equation}
\sum^{r}_{\mu=1} \chi_i^{(\mu)} \chi_j^{*(\mu)} = {g \over g_i} 
\delta_{ij}
\end{equation}
and $r = k$.

Using (20), we can find which irreducible representations occur in 
any given representation.  An arbitrary representation can be 
decomposed as
\begin{equation}
D(R) = \sum_{\nu} a_{\nu}D^{\nu}(R)
\end{equation}
where $A_{\nu} \geq 0$ is an integer equal to the number of times 
the $\nu$ irreducible representation occurs in $\{D(R)\}$, thus, 
obtaining
\begin{equation}
\chi(R) = \sum_{\nu} a_{\nu} \chi^{\nu}(R)
\end{equation}
Multiplying by $\chi^{(\mu)}(R)$ and summing over $R$, we obtain
\begin{equation}
\sum_{R} \left[ \chi^{(\mu)}(R) \right]^* \chi(R) = \sum_{\nu} 
a_{\nu} \underbrace{\sum_{R} \left[ \chi^{(\mu)}(R) \right]^* 
\chi^{(\nu)}(R)}_{g\delta_{\mu\nu}} = ga_{\nu}
\end{equation}
Therefore,
\begin{equation}
a_{\mu} = {1 \over g} \sum_{i} g_i \left[ \chi_i^{(\mu)} \right]^* 
\chi_i
\label{chap16app-eqno21}
\end{equation}

Equation (21) is very useful for decomposing reducible representations 
into irreducible components.  In addition, (21) tells us a 
representation is irreducible if, and only if,
\begin{equation}
\sum_{i} g_i \left| \chi_i \right|^2 = g.
\end{equation}

Recall the regular representation for which we use the group elements 
themselves as basis functions.  The regular representation is 
$g$-dimensional, so that the identity is
\begin{equation}
\pmatrix{1 & & & 0\cr
& 1 & &\cr
& & 1 &\cr
0 & & & .\cr}
\end{equation}
However, for the regular representation, no other element of $G$ has 
a diagonal element since $RR = R \rightarrow R = e$.  Therefore, 
$\chi(e) = g$ and $\chi(R) = 0$ if $R \not= e$.  Using
\begin{equation}
\chi(R) = \sum a_{\nu} \chi^{\nu} (R)
\end{equation}
and letting $R = e$, we obtain
\begin{equation}
g = \sum a_{\nu} d^{(\nu)}.
\end{equation}
But
\begin{equation}
a_{\nu} = {1 \over g} \sum_{R} \chi^{(\nu)} (R) \chi(R) = {1 \over g} 
\chi^{\nu} (e) \chi(e) = d^{\nu}.
\end{equation}
which constitutes an independent derivation of (18).

\subsubsection{The Rearrangement Theorem}

Consider a group $G = \{ R_1 , R_2 , \cdots , R_g\}$, and multiply 
each element of the group, on the right, say, by the same element 
$R_i$, giving $R_1R_2 = R_1^{\prime}$, $R_2R_i = R^{\prime}_2$, and 
$R_g R_i = R^{\prime}_g$.  We find that the new set
\begin{equation}
\left\{ R_1^{\prime} , R^{\prime}_2 , \cdots , R_g^{\prime} 
\right\}
\label{chap16app-eqno22}
\end{equation}
contains exactly the same elements as the old set.  As a result, a sum
\begin{equation}
\sum_{R \epsilon G} RR_i
\end{equation}
over all elements $R$ of a group can be replaced by a sum
\begin{equation}
\sum_{R^{\prime}\epsilon G} R^{\prime}
\end{equation}
over the rearranged set $\{ R^{\prime} = RR_i\}$.  Consequently,
\begin{equation}
\sum_{R} R = \sum_{R} RR_i = \sum_{R} R_i^{\prime} = 
\sum_{R^{\prime}_i} R^{\prime}_i
\label{chap16app-eqno23}
\end{equation}
This result, called the rearrangement theorem, was used in deriving 
the orthogonality theorem.

The proof is straightforward.  Assume two different elements of 
$\{R\}$ leading to the same element of $R^{\prime}$, $R^{\prime}_j = 
R_k^{\prime}$.  Then, $R_jR_i = R_kR_i$, and post-multiplication by 
$R_i^{-1}$ yields $R_j = R_k$, contradicting the assumption.  Thus, 
all elements of (22) are different.  But all elements in (22) are in 
$G$ and the number of elements of (22) is the same as that in $G$.  
Thus, since the elements of (22) are all different, we have 
$\{R^{\prime}_i , R^{\prime}_e , \cdots , R_g \} = G$.

The rearrangement theorem is for finite groups.  For continuous 
groups, e.g., the two or three dimensional rotation groups, the sums 
in (23) must be replaced by integrations.  However, this can be done in 
such a way as to obtain analogous theorems.  For example, if 
$R(\varphi)$ is a rotation through angle $\phi$ about some axis, then
\begin{equation}
\int\limits^{2\pi}_{0} d \varphi {\hat{R}} ( \varphi ) = 
\int\limits^{2\pi}_{0} d \varphi {\hat{R}} ( \varphi + \alpha )
\end{equation}
where $\alpha$ is any real number.

\subsection{Coordinate Transformation}

In this appendix, we will consider coordinate transformations and 
their effect upon functions and operators.

\subsubsection{Transformation of Coordinate Systems}

The electron wavefunction of a molecule $\Psi( {\bf r}_1 , {\bf 
r}_2 , \cdots )$ is defined as a function of the coordinates of the 
various electrons and nuclei. These coordinates are described in terms 
of position vectors in a three-dimensional Euclidean vector space.  
The various symmetry operations effect particular rearrangements, or 
transformations, on these position vectors, and it is the description 
of these transformations that is the subject here.

In three-dimensional real Euclidean space, we very often represent a 
vector {\bf r} by its components, $x$, $y$, and $z$, along three 
mutually perpendicular axes $e_x$, $e_y$, and $e_z$, where $e_i$ 
represents a unit vector in the direction $i$.  Thus, ${\bf r} = 
xe_x + ye_y + ze_z$, which we will write as ${\bf r} = x_ie_i$, where 
the presence of the same index twice on the same side of the equation 
indicates that the index is to be summed over.  This is known as the 
Einstein summation convention.  If we now rotate our coordinate 
system so that the new coordinate axes are $e^{\prime}_x$, 
$e^{\prime}_e$, and $e^{\prime}_z$, then our old vector {\bf r} has 
new components, $x^{\prime}$, $y^{\prime}$, and $z^{\prime}$, along 
these new axes, and we write ${\bf r} = x^{\prime}_i e^{\prime}_i$.

However, if we know the relationship between the coordinate axes 
$\{e_i\}$ and $\{e^{\prime}_i\}$, we can find the relationship 
between $\{x_i\}$ and $\{x^{\prime}_i\}$.  In this section, we will 
study these relationships, but without limiting ourselves to three 
dimensions.

Consider an $N$-dimensional space and some vector {\bf r} in this 
space.  We can write ${\bf r} = x_ie_i$, where we will take $\{e_i\}$ 
as an orthonormal basis.  If $\{e^{\prime}_i\}$ is another 
orthonormal basis, then
\begin{equation}
{\bf r} = x_i e_i = x^{\prime}_j e^{\prime}_j
\label{chap16app-eqno24}
\end{equation}
Let these coordinate axes be related by the matrix $A$,
\begin{equation}
e^{\prime}_j = A_{ji} e_i ,
\label{chap16app-eqno25}
\end{equation}
where $A_{ji}$ is the direction consine between the old unit vector 
$e_i$ and the new vector $\{e^{\prime}_j\}$.  Substituting (25) into 
(24), leads to ${\bf r} = x_i e_i = x^{\prime}_j A_{ji} e_i$, and since 
the $e_i$ are linearly independent, we obtain $x_i = x^{\prime}_j 
A_{ji} = {\tilde{A}}_{ij} x^{\prime}_j$.  In matrix notation, 
changing the coordinate system by $\underline{e}^{\prime} = 
\underline{Ae}$, leads to a change in the vector components by 
$\underline{x} = \underline{\tilde{A}x}^{\prime}$ and hence,
\begin{equation}
\underline{x}^{\prime} = \underline{\tilde{A}}^{-1} \underline{x}
\label{chap16app-eqno26}
\end{equation}
Thus, the matrices relating coordinate axes and vector components are 
not the same, one is the transpose-inverse of the other.  On the other 
hand, we will find that for real vector spaces, the $\underline{A}$ are 
orthogonal matrices so that $\underline{\tilde{A}} = 
\underline{A}^{-1}$ and hence, $\underline{\tilde{A}}^{-1} = 
\underline{A}$, so that the coordinate and components do transform 
the same way.

\subsubsection{Successive Transformations}

If the coordinate system $\{e_i\}$ is first transformed with the 
matrix $\underline{A}_1$ to obtain $\{e^{\prime}_i\}$, then this 
coordinate system is transformed with matrix $\underline{A}_2$ to 
obtain $\{e^{\prime \prime}_i\}$, we obtain 
$\underline{e}^{\prime\prime} = \underline{A}_2 
\underline{e}^{\prime} = \underline{A}_2 \underline{A}_1 
\underline{e}$.  Hence, the matrix $\underline{A}$ transforming 
directly from $\{e_i\}$ to $\{e^{\prime\prime}_i\}$ is
\begin{equation}
\underline{A} = \underline{A}_2 \underline{A}_1
\label{chap16app-eqno27}
\end{equation}
Note, in particular, that the matrices multiply to the right, that 
is, $\underline{A}_2 \underline{A}_1$ means that we first apply 
$\underline{A}_1$ and then $\underline{A}_2$.  The vector components 
transform as $\underline{x}^{\prime} = \underline{\tilde{A}}^{-1} 
\underline{x}$, leading to
\begin{equation}
\underline{x}^{\prime\prime} = \underline{\tilde{A}}_2^{-1} 
\underline{x}^{\prime} = \underline{\tilde{A}}_2^{-1} 
\underline{\tilde{A}}^{-1} \underline{x} = 
\left( \underline{\tilde{A}}_1 \underline{\tilde{A}}_2 \right)^{-1} 
\underline{x}
\end{equation}
But
\begin{eqnarray}
\left( \underline{\tilde{A}}_1 \underline{\tilde{A}}_2 \right)_{ij} 
&=& \left( \underline{\tilde{A}}_1 \right)_{ik} \left( \underline{\tilde{A}}_2 
\right)_{kj}\cr
&=& \left( \underline{A}_1 \right)_{ki} \left( \underline{A}_2 
\right)_{jk}\cr
&=& \left( \underline{A}_2 \right)_{jk} \left( \underline{A}_1 
\right)_{ki}\cr
&=& \left( \underline{A}_2 \underline{A}_1 \right)_{ji}\cr
&=& \left( \underline{\tilde{A}} \right)_{ij}
\end{eqnarray}
and hence, $\underline{x}^{\prime\prime} = \underline{\tilde{A}}^{-1} 
\underline{x}$, as expected from (26) and (27).

\subsubsection{Orthogonal Transformations}

We can take the basis vectors of a real Euclidean space as real and 
orthogonal, i.e.,
\begin{equation}
e_i \cdot e_j = \delta_{ij}
\label{chap16app-eqno28}
\end{equation}
A rotation, inversion, or reflection preserves lengths and relative 
angles and hence, leads to new basis vectors satisfying
\begin{equation}
e_i^{\prime} \cdot e^{\prime}_j = \delta_{ij}
\label{chap16app-eqno29}
\end{equation}
Substituting (25) into (29), leads to
$\delta_{ij} = \left( A_{ik} e_k \right) \cdot \left( A_{j \ell} 
e_{\ell} \right) = \left( e_k \cdot e_{\ell} \right) A_{ik} a_{j\ell}$
and using (28), we obtain
\begin{equation}
\delta_{ij} = A_{ik} A_{jk}
\label{chap16app-eqno30}
\end{equation}
or in matrix notation,
\begin{equation}
\underline{1} = \underline{A}\underline{\tilde{A}}
\label{chap16app-eqno31}
\end{equation}
That is, $\underline{\tilde{A}}$ is the inverse of $A$
\begin{equation}
\underline{\tilde{A}} = \underline{A}^{-1}
\label{chap16app-eqno32}
\end{equation}
Matrices with this property (32), or equivalently (30), are said to be 
orthogonal matrices.  From (30) we see that orthgonal matrices have 
orthogonal rows.  Starting with (32) and multiplying by 
$\underline{A}$ on the right, we get $\underline{\tilde{A}A} = 
\underline{1}$, or $A_{ki}A_{kj} = \delta_{ij}$ and hence, the 
columns of an orthogonal matrix are also orthogonal.

Since $\underline{\tilde{A}} = \underline{A}^{-1}$, then 
$\underline{A} = \underline{\tilde{A}}^{-1}$, and hence, (26) 
becomes $\underline{x}^{\prime} = \underline{Ax}$.  That is, for an 
orthogonal transformation, the coordinates $\underline{x}$ and basis 
vectors, transform the same way, $\underline{e}^{\prime} = 
\underline{Ae}$ and $\underline{x}^{\prime} = \underline{Ax}$.

\subsubsection{Examples}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{$\sigma_{xz}$ reflection.}
\label{chap16app-fig2}
\end{figure}

In three dimensions, consider the reflections in the $xz$-axis,
$\sigma_{xz}$.  Schematically, the transformation is as indicated in
Figure \ref{chap16app-fig2} and hence, $e^{\prime}_x = e_x$,
$e^{\prime}_y = - e_y$, and $e^{\prime}_z = e_z$.

Therefore, the orthogonal matrix, representing the $\sigma_{xz}$ 
reflection, is
\begin{equation}
\underline{A} = 
\pmatrix{1 & 0 & 0\cr
0 & -1 & 0\cr
0 & 0 & 1\cr}
\end{equation}
Similarly, reflection in the plane bisecting the $x$ and $y$ axes is 
represented by
\begin{equation}
\underline{A} =
\pmatrix{0 & 1 & 0\cr
1 & 0 & 0\cr
0 & 0 & 1\cr}
\end{equation}
As indicated in Figure \ref{chap16app-fig3}, inversion through the
origin, $i$, leads to $e^{\prime}_x = e_x$, $e^{\prime}_y = - e_y$,
and $e^{\prime}_z = - e_z$, and hence,
\begin{equation}
\underline{A} =
\pmatrix{-1 & 0 & 0\cr
0 & -1 & 0\cr
0 & 0 & -1\cr}
\end{equation}


\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{Inversion}
\label{chap16app-fig3}
\end{figure}

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{Rotation of the coordinate system}
\label{chap16app-fig4}
\end{figure}

Consider now the rotation through an angle $\theta$ about the $z$
axis, as in Figure \ref{chap16app-fig4}.

Then, $e^{\prime}_x = e_x \cos \theta + e_y \sin \theta$, $e^{\prime}_y = 
e_y \cos \theta - e_x \sin \theta$, and $e^{\prime}_z = e_z$, and 
hence,
\begin{equation}
\underline{A} = 
\pmatrix{ \cos \theta & \sin \theta & 0\cr
- \sin \theta & \cos \theta & 0\cr
0 & 0 & 1\cr}
\label{chap16app-eqno33}
\end{equation}
For example, the rotation of ninety degrees, or $\pi/4$ radians, 
i.e., a C$_4$ rotation, would be represented mathematically as, 
ignoring $e_z$ for the moment,
\begin{eqnarray}
\left( {e^{\prime}_x \atop e^{\prime}_y} \right) &=
\pmatrix{\cos 90^{\circ} & \sin 90^{\circ}\cr
- \sin 90^{\circ} & \cos 90^{\circ}\cr}
\pmatrix{e_x\cr
e_y\cr}\cr
&=& \pmatrix{0 & 1\cr
-1 & 0\cr}
\pmatrix{e_x\cr
e_y\cr}\cr
&=& \pmatrix{e_y\cr
-e_x\cr}
\end{eqnarray}
or, $e^{\prime}_x - e_y$, $e^{\prime}_y = - e_x$, and $e^{\prime}_z = 
e_z$.

\subsubsection{Matrix Representations of Symmetry Operators}

Consider some operator, say ${\tilde{T}}$, defined over some 
$N$-dimensional space.  With every vector {\bf x} in this space, 
${\tilde{T}}$ associates a vector {\bf y}, i.e. $T$ maps the space 
into itself, ${\bf y} = {\tilde{T}} {\bf x}$.    This relationship is 
independent of whatever basis might be used to describe the vectors of 
this space.

Now we pick a coordinate system $\{e_i\}$, leading to
\begin{equation}
y_i e_i = {\tilde{T}} \left( x_i e_i \right) = x_i {\tilde{T}} \left( 
e_i \right)
\label{chap16app-eqno34}
\end{equation}
since $x_i$ is just a number.  Thus, if we know the effect of 
${\tilde{T}}$ on the $N$ basis functions, we know the effect of 
${\tilde{T}}$ on any vector of the $N$-dimensional space.

Since ${\tilde{T}}(e_i)$ is some new vector of the space, we can 
expand it in terms of the basis vectors as
\begin{equation}
{\tilde{T}} \left( e_i \right) = e_j T_{ji}
\label{chap16app-eqno35}
\end{equation}
Substituting into (34) then leads to $y_ie_i = x_i T_{ji}e_j$ and, 
since the $e_j$ are linearly independent, we obtain $y_j = 
T_{ji}x_i$.  Consequently, with the single $N$ by $N$ matrix 
$\underline{T}$ we can find the effect of ${\tilde{T}}$ upon any of 
the infinite number of vectors of the space, as specified by the 
vector components $\underline{x}$.

In obtaining (34), we used
\begin{equation}
{\tilde{T}} \left( x_i e_i \right) = x_i {\tilde{T}} \left( e_i 
\right)
\label{chap16app-eqno36}
\end{equation}
This is actually an assumption.  Operators satisfying (36) for all 
vectors $\underline{x}$ of a space, are called linear operators.

We will be interested in transformations ${\tilde{T}}$ corresponding
to such operations as rotations, reflections, and inversions.  The
corresponding matrices are of a form similar to those already
discussed, with an important exception.  Consider rotation through an
angle $\theta$ in the $x$-$y$ plane as indicated in Figure
\ref{chap16app-fig5}.


\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{Rotation of a vector.}
\label{chap16app-fig5}
\end{figure}

To obtain the form of $r^{\prime}_i$, it is simplest to consider 
separately the three cases where only one component of {\bf r} is 
nonzero and then to superimpose the results.  The components of the 
new vector are thus, $r^{\prime}_x = r_x \cos \theta - r_y \sin 
\theta$, $r^{\prime}_y = r_y \cos \theta + r_x \sin \theta$, and 
$r^{\prime}_z - r_z$.  Hence,
\begin{equation}
T = \pmatrix{\cos \theta & - \sin \theta & 0\cr
\sin \theta & \cos \theta & 0\cr
0 & 0 & 1\cr}
\label{chap16app-eqno37}
\end{equation}

Comparing with (33), we see that (37) is the inverse of (33), they
become the same if we change the sign of $\theta$ in (33).  The reason
is that rotation of the coordinate system and rotation of a vector,
are inverse operations as indicated in Figure \ref{chap16app-fig6}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{(a) Rotation of a vector by an angle $+\theta$, (b) Rotation
of the coordinate system by an angle $-\theta$.  Rotation of the
coordinate system by $- \theta$ leads to the same final components of
the vector {\bf r} as rotating the vector through an angle of $+
\theta$.  This is a point which causes some confusion.}
\label{chap16app-fig6}
\end{figure}


\subsubsection{Successive Transformations}

The definition of the $T$ matrix in (35) is a bit strange, since we 
use $e_jT_{ji}$ rather than $T_{ij}e_j$, as might be expected from 
(25).  The reason for this choice is found by examining the effect of 
successive transformations.   Let ${\hat{T}}(e_i) = e_j T_{ji}$ and 
${\hat{S}}(e_j) = e_kS_{kj}$.  Then
\begin{equation}
{\hat{S}}{\hat{T}} (e_i) = {\hat{S}}\left[ e_j T_{ji} \right] = 
\left[ {\hat{S}} e_j \right] T_{ji} = \left[ e_k S_{kj} \right] 
T_{ji} = e_k \left[ S_{kj}T_{ji} \right] = e_k \left( 
{\underline{ST}} \right)_{ki}
\end{equation}
Thus, the transformation matrix for the product of two operations is 
just the product of the corresponding transformation matrices in the 
same order.  Defining ${\hat{T}}(e_i) = T_{ij}e_j$ would have led 
to ${\hat{S}}{\hat{T}}(e_i) = (TS)_{ik}e_k$.

\subsubsection{Effect of Coordinate Transformations}

Given that ${\bf y} = {\hat{T}}({\bf x})$ yields $y_i = T_{ij}x_j$ 
for coordinate systems $\{e_i\}$, we want to find the effect of 
transforming to some new coordinate system $\underline{e}^{\prime} = 
\underline{\tilde{B}}^{-1} \underline{e}$.  We use 
$\underline{\tilde{B}}^{-1}$ instead of $\underline{A}$ for later 
convenience; for orthogonal transformations these matrices are the 
same.  Expressing the vectors in terms of the new coordinate system, 
we obtain
\begin{equation}
{\bf y} = y^{\prime}_{\ell} e^{\prime}_{\ell} = T \left( x^{\prime}_i 
e^{\prime}_i \right) = x^{\prime}_i T \left( e^{\prime}_i \right) = 
x^{\prime}_i B^{-1}_{ji} T \left( e_j \right) = x^{\prime}_i 
B^{-1}_{ji} e_k T_{kj} = x^{\prime}_i B^{-1}_{ji} T_{kj} B_{\ell k} 
e^{\prime}_{\ell}
\end{equation}
Therefore, $y^{\prime}_{\ell} = B_{\ell k} T_{kj} B^{-1}_{ji}
x^{\prime}_i = T^{\prime}_{\ell i} x^{\prime}_i$, or in matrix
notation $\underline{T}^{\prime} = \underline{BTB}^{-1}$.  If
$\underline{B}$ is orthogonal, i.e., both coordinate systems are real
and orthogonal, then $\underline{T}^{\prime} =
\underline{BT{\tilde{B}}}$.  We call $\underline{BTB}^{-1}$ a
similarity transformation on $\underline{T}$ since
$\underline{\tilde{T}} = \underline{BTB}^{-1}$ may be interpreted
schematically as in Figure \ref{chap16app-fig7}, i.e.,
$\underline{B}^{-1}$ transforms the new coordinate system to the old
one.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16app-fig7}
\end{figure}

In the old coordinate system, $\underline{T}$ is defined and is used 
to transform the vector space; then the transformed vector space is 
taken back to the new coordinate system via $\underline{B}$.

For example, consider a reflection in the $yz$ plane, $\sigma_{yz}$.  
The associated transformation matrix is
\begin{equation}
\underline{T} = 
\pmatrix{-1 & 0 & 0\cr
0 & 1 & 0\cr
0 & 0 & 1\cr}.
\end{equation}
Now let us rotate the coordinate system by $\pi/4$ radians about the
$y$ axis, as in Figure \ref{chap16app-fig8}.

\begin{figure}
%\includegraphics[scale=0.75]{fg16-}
\caption{}
\label{chap16app-fig8}
\end{figure}

The coordinate transformation matrix $\underline{B}$ is 
$e^{\prime}_z = e_x$, $e^{\prime}_y = e_y$, and $e_x^{\prime} = - 
e_z$, and hence,
\begin{equation}
\underline{B} = 
\pmatrix{0 & 0 & 1\cr
0 & 1 & 0\cr
1 & 0 & 0\cr}
\end{equation}
and
\begin{equation}
\underline{B}^{-1} = \underline{\tilde{B}} = \pmatrix{0 & 0 & 1\cr
0 & 1 & 0\cr
-1 & 0 & 0\cr}.
\end{equation}
Consequently,
\begin{eqnarray}
T^{\prime} &=& \pmatrix{0 & 0 & -1\cr 0 & 1 & 0\cr 1 & 0 & 0\cr}
\pmatrix{-1 & 0 & 0\cr 0 & 1 & 0\cr 0 & 0 & 1\cr}
\pmatrix{0 & 0 & 1\cr 0 & 1 & 0\cr -1 & 0 & 0\cr}\cr
&=& \pmatrix{0 & 0 & -1\cr 0 & 1 & 0\cr 1 & 0 & 0\cr}
\pmatrix{0 & 0 & -1\cr 0 & 1 & 0\cr -1 & 0 & 0\cr}\cr
&=& \pmatrix{1 & 0 & 0\cr 0 & 1 & 0\cr 0 & 0 & -1\cr}
\end{eqnarray}
That is, the new coordinate system $T^{\prime}$ corresponds to a 
reflection in the $x$' $y$' plane, whereas it was a reflection in the 
$yz$ plane for the old coordinate system.

Now consider the operator C$_{nz}$ corresponding to a rotation about 
the $z$ axis of $\theta = 2\pi/n$ radians.  The transformation 
matrix, $\underline{T}$, for C$_{nz}$ is
\begin{equation}
T = \pmatrix{\cos \theta & - \sin \theta & 0\cr \sin \theta & \cos 
\theta & 0\cr 0 & 0 & 1\cr}.
\end{equation}
Therefore, the transformation marix, $\underline{T}^{\prime}$, in the 
new coordinate system is
\begin{eqnarray}
\underline{T}^{\prime} = \underline{BTB}^{-1} &=& 
\pmatrix{0 & 0 & -1\cr 0 & 1 & 0\cr 1 & 0 & 0\cr} 
\pmatrix{\cos \theta & - \sin \theta & 0 \cr \sin \theta & \cos 
\theta & 0\cr 0 & 0 & 1\cr} 
\pmatrix{0 & 0 & 1\cr 0 & 1 & 0\cr -1 & 0 & 0\cr}\cr
&=& \pmatrix{0 & 0 & -1\cr 0 & 1 & 0\cr 1 & 0 & 0\cr}
\pmatrix{0 & - \sin \theta & \cos \theta\cr 0 & \cos \theta & \sin 
\theta\cr -1 & 0 & 0\cr}\cr
\underline{T}^{\prime} &=& \pmatrix{1 & 0 & 0\cr 0 & \cos \theta & 
\sin \theta\cr 0 & - \sin \theta & \cos \theta\cr}
\end{eqnarray}
Consequently, $\underline{T}^{\prime}$ corresponds to a rotation 
by $- \theta$ about the $x$' axis in the new coordinate system, 
whereas in the old coordinate system, $\underline{T}$ corresponded to 
a rotation by $\theta$ about the $z$ axis.

In summary, if one changes the coordinate system by 
$\underline{e}^{\prime} = \underline{Ae}$, the new components of the 
vectors are $\underline{x}^{\prime} = \underline{\tilde{A}}^{-1} 
\underline{x}$, or $\underline{e}^{\prime} = \underline{eB}^{-1}$ 
and $\underline{x}^{\prime} = \underline{Bx}$.  If the operator 
${\hat{T}}$ leads to $T(e_i) = e_jT_{ji}$, then the components 
transform as $\underline{y} = \underline{Tx}$.

Finally, in the new coordinate system, $\underline{e}^{\prime} = 
\underline{eB}^{-1}$, the transformation matrix is, 
$\underline{T}^{\prime} = \underline{BTB}^{-1}$.

\subsubsection{Effect of Symmetry Operations}

In the previous section, we considered vectors and the effect on a 
vector space of a coordinate transformation.  Now we discuss 
transformations of functions.

Consider the function $\psi({\bf r}) \equiv \psi(x,y) = 2x-a$
\begin{equation}
% missing figure!
\end{equation}
where the dashed line indicates the nodal plane.  Rotating the 
function by ninety degrees, we get $\psi^{\prime} ({\bf r}) \equiv 
\psi^{\prime}(x,y) = 2y-a$
\begin{equation}
% missing figure!
\end{equation}
Now rotate the coordinate system by ninety degrees to get 
$e^{\prime}_x$ and $e^{\prime}_y$.  Then, in terms of $x^{\prime}$ 
and $y^{\prime}$, we have $\psi^{\prime} ( {\bf r}^{\prime}) = 
\psi^{\prime}(x^{\prime},y^{\prime}) = 2x^{\prime} -a$
\begin{equation}
% missing figure!
\end{equation}
Thus, the transformed function evaluated at the transformed 
coordinate ${\bf r}^{\prime}$ is equal to the untransformed 
function $\psi$ evaluated at the untransformed coordinate {\bf r}, 
$\psi^{\prime}({\bf r}^{\prime})=\psi({\bf r})$.

We will let {\bf T} denote the transformation of the coordinate space 
taking {\bf r} into ${\bf r}^{\prime}$, so that the ${\bf 
r}^{\prime} = {\bf Tr}$.  Then if {\bf T} operates on $\psi$ to yield 
$\psi^{\prime}$, we have $\psi^{\prime}({\bf r}^{\prime}) = \psi({\bf 
r})$ or, since ${\bf r} = {\bf T}^{-1}{\bf r}^{\prime}$, 
$\psi^{\prime}({\bf r}^{\prime}) = \psi({\bf T}^{-1}{\bf 
r}^{\prime})$.  That is, to evaluate $\psi^{\prime}$ at ${\bf 
r}^{\prime}$, we rotate backwards by {\bf T} to get ${\bf r} = {\bf 
T}^{-1} {\bf r}^{\prime}$ and evaluate $\psi$ at this point. In order 
to show that $\psi^{\prime}$ is obtained from $\psi$ by {\bf T}, we 
write $\psi^{\prime} = O_{T}\psi$, where $O_T$ is an operator that 
acts on functions corresponding to the operator {\bf T} that acts 
on the coordinate space in terms of which $\psi$ is defined.  Note that
$\psi^{\prime}({\bf r}^{\prime}) = O_T \psi({\bf r}^{\prime}) = 
\psi({\bf r}) = \psi ( {\bf T}^{-1} {\bf r}^{\prime})$ or 
denoting ${\bf r}^{\prime}$ by {\bf s}, $\psi^{\prime}({\bf s}) = O_T 
\psi({\bf s} = \psi({\bf T}^{-1}{\bf s})$.  The point to all this is 
that when we operate on a function $\psi({\bf r})$ with an operator, 
say $O_T$, the resulting function $\psi^{\prime}({\bf s})$ is 
obtained by replacing $\psi({\bf r})$ by $\psi({\bf T}^{-1}{\bf s})$.

This often confuses neophytes because we usually call the new 
variable {\bf r} rather than {\bf s}, and we replace $\psi({\bf r})$ 
by $\psi({\bf T}^{-1}{\bf r})$.

Consider applying successive transformations, {\bf T} and then {\bf 
S}, $\psi^{\prime\prime}({\bf r}^{\prime\prime}) = O_S\psi^{\prime}({\bf 
r}^{\prime\prime}) = \psi({\bf S}^{-1}{\bf 
r}^{\prime\prime}) = \psi^{\prime}({\bf r}^{\prime})$ and 
$\psi^{\prime}({\bf r}^{\prime}) = O_T \psi({\bf r})^{\prime} = 
\psi({\bf T}^{-1}{\bf r}^{\prime}) = \psi({\bf r})$.  Thus, 
$\psi^{\prime\prime}( {\bf r}^{\prime\prime}) = \psi({\bf T}^{-1} 
{\bf r}^{\prime}) = \psi( {\bf T}^{-1} {\bf S}^{-1} {\bf 
r}^{\prime\prime})$, since ${\bf r}^{\prime} = {\bf S}^{-1} 
{\bf r}^{\prime\prime}$.  But, ${\bf T}^{-1}{\bf S}^{-1} = ({\bf 
ST})^{-1}$.  Thus,
$\psi^{\prime\prime} ( {\bf r}^{\prime\prime} ) = O_S 
\psi^{\prime} ( {\bf r}^{\prime\prime} ) = O_S O_T \psi 
( {\bf r}^{\prime\prime} ) = \psi [ ( {\bf ST} )^{-1} 
{\bf r}^{\prime\prime} ]$.  
Hence, the product of $O_S$ and $O_T$ is equivalent to the 
transformation {\bf ST}, just as it should be.  We will usually use 
the common, ambiguous notation where the $O$ in $O_R$ is omitted; i.e., 
we write $O_R\psi$ as $R \psi$.  As an example, consider the 
function $\psi(\rho,\phi) = \rho e^{i\phi}$, and let $R(\alpha)$ be a 
counter-clockwise rotation about the origin through an angle 
$\alpha$.  That is, $R$ takes $(\rho,\phi)$ into 
$(\rho,\phi+\alpha)$.  Then, $\psi^{\prime} (\rho^{\prime}, 
\phi^{\prime}) = R(\alpha) 
\psi^{\prime}(\rho^{\prime},\phi^{\prime})= 
\psi(\rho,\phi^{\prime} - \alpha) = \rho e^{i(\phi^{\prime}-\alpha)} = 
e^{-i\alpha} \psi(\rho^{\prime} , \phi^{\prime})$
\begin{equation}
% missing figure!
\end{equation}
Thus, if we now drop the primes, $R(\alpha)\psi(\rho,\phi) = 
e^{-i\alpha} \psi(\rho,\phi)$.  Note that the minus sign in 
$e^{-i\alpha}$ results from the function $e^{i\phi}$ with the plus 
sign.

Next we wish to determine how function operators transform under 
coordinate transformations.  Consider the operator $H(x)$, which 
relates $\psi(x)$ to $\phi(x), \phi(x) = H(x) \psi(x)$.  Then,
\begin{equation}
O_R \phi(x) = \phi \left( R^{-1}x \right) = H \left( R^{-1} x \right) 
\psi \left( R^{-1} x \right)
\label{chap16app-eqno38}
\end{equation}
and
\begin{equation}
O_R \phi(x) = O_R H ( x ) \psi (x) = O_R H(x) O_R^{-1} O_R 
\psi(x)
\label{chap16app-eqno39}
\end{equation} 
here we have inserted $O_R^{-1}O_r = 1$.  Recall that operators 
operate on everything to their right.  Now we denote the composite 
operator $O_R(H(x)O_R^{-1}$ as $H^{\prime}(x)$, as $H^{\prime}(x) 
\equiv O_RH(x)O_R^{-1}$.  Thus, equating (38) and (39), we obtain 
$H(R^{-1}x)\psi (R^{-1}x) = H^{\prime}(x) O_R \psi(x) = H^{\prime}(x) 
\psi(R^{-1}x)$.  That is, $[H(R^{-1}x) - 
H^{\prime}(x)]\psi(R^{-1}x) = 0$.  Since this is true for any $\psi$, 
then the coefficient is zero, or $O_RH(x)O_R^{-1} = H(R^{-1}x)$.  That 
is, to transform an operator $H$, we must pre-operate with $O_R$ and 
post-operate with $O_R^{-1}$.  Note that $H^{\prime}(x) = H(R^{-1}x)$ 
has the form of a similarity transformation on $H(x)$.  If it turns out 
that $H(R^{-1}x) = H(x)$, then we say that $H$ is invariant under the 
transformation $R$.  In this case, $O_R H(x)O_R^{-1} = H(x)$ or 
$O_RH(x)=H(x)O_R$.  That is, $O_R$ commutes with $H(x)$.

\subsection{Symmetric Group Character Tables}

\begin{table}
\caption{}
\label{chap16app-tab1}
\begin{tabular}{cccc}\\ \hline
$S_2$ & & $e$ & (12)\cr

& & 1 & 1\cr

& & 1 & $-1$\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab2}
\begin{tabular}{cccccc}\\ \hline
$S_3$ & & & $e$ & 3(12) & 2(123)\cr

& & & 1 & 1 & 1\cr

& & & 2 & 0 & $-1$\cr
& & & 1 & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab3}
\begin{tabular}{cccccccc}\\ \hline

$S_4$ & & & $e$ & 6(12) & 8(123) & 6(1234) & 3(12)(34)\cr

& & & 1 & 1 & 1 & 1 & 1\cr

& & & 3 & 1 & 0 & $-1$ & $-1$\cr

& & & 2 & 0 & $-1$ & 0 & 2\cr

& & & 3 & $-1$ & 0 & 1 & $-1$\cr

& & & 1 & $-1$ & 1 & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab4}
\begin{tabular}{cccccccccc}\\ \hline

$S_5$ & & & $e$ & 10 & 20 & 30 & 15 & 20 & 5\cr
& & & & (12) & (123) & (1234) & (12)(34) & (123)(45) & (1234)(56)\cr

& & & 1 & 1 & 1 & 1 & 1 & 1 & 1\cr
& & & 4 & 2 & 1 & 0 & 0 & $-1$ & $-1$\cr

& & & 5 & 1 & $-1$ & $-1$ & 1 & 1 & 0\cr

& & & 6 & 0 & 0 & 0 & $-2$ & 0 & 1\cr

& & & 5 & $-1$ & $-1$ & 1 & 1 & $-1$ & 0\cr

& & & 4 & $-2$ & 1 & 0 & 0 & 1 & $-1$\cr

& & & 1 & $-1$ & 1 & $-1$ & 1 & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab5a}
\begin{tabular}{ccccccccccc}\\ \hline

$S_6$ & & & & $e$ & 15 & 40 & 90 & 45 & 120 & 144\cr
& & &  & & (12) & (123) & (1234) & (12)(34) & (123)(45) & (12345)\cr 
& & & & 1 & 1 & 1 & 1 & 1 & 1 & 1\cr
& & & & 5 & 3 & 2 & 1 & 1 & 0 & 0\cr
& & & & 9 & 3 & 0 & $-1$ & 1 & 0 & $-1$\cr
& & & & 10 & 2 & 1 & 0 & $-2$ & $-1$ & 0\cr
& & & & 5 & 1 & $-1$ & $-1$ & 1 & 1 & 0\cr
& & & & 16 & 0 & $-2$ & 0 & 0 & 0 & 1\cr
& & & & 5 & $-1$ & $-1$ & 1 & 1 & $-1$ & 0\cr
& & & & 10 & $-2$ & 1 & 0 & $-2$ & 1 & 0\cr
& & & & 9 & $-3$ & 0 & 1 & 1 & 0 & $-1$\cr
& & & & 5 & $-3$ & 2 & $-1$ & 1 & 0 & 0\cr
& & & & 1 & $-1$ & 1 & $-1$ & 1 & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab5b}
\begin{tabular}{cccccccc}\\ \hline

$S_6$ & & & & 120 & 90 & 15 & 40\cr
& & & & (123456) & (1234)(56) & (12)(34)(56) & (123)(456)\cr
& & & & 1 & 1 & 1 & 1\cr
& & & & $-1$ & $-1$ & $-1$ & $-1$\cr
& & & & 0 & 1 & 3 & 0\cr
& & & & 1 & 0 & $-2$ & 1\cr
& & & & 0 & $-1$ & $-3$ & 2\cr
& & & & 0 & 0 & 0 & $-2$\cr
& & & & 0 & $-1$ & 3 & 2\cr
& & & & $-1$ & 0 & 2 & 1\cr
& & & & 0 & 1 & $-3$ & 0\cr
& & & & 1 & $-1$ & 1 & $-1$\cr
& & & & $-1$ & 1 & $-1$ & 1\cr
\hline
\end{tabular}
\end{table}

\subsection{Common Point Group Character Tables}

The following conventions are used in naming irreducible 
representations; $A$ and $B$ for a one-dimensional irreducible 
representation, $E$ for a two-dimensional irreducible representation, 
and $T$ for a three-dimensional irreducible representation.  $A$ or $B$ 
indicates a representation that is symmetric or antisymmetric, 
respectively.  With respect to the principal axis, which is the 
highest order rotation axis, $C_n$ or $S_n$.  Occasionally, $F$ is used 
in place of $T$.

A subscript of 1 or 2 generally indicates a representation that is 
symmetric or antisymmetric, respectively, for the $C_2$ normal to the 
principal axis or else symmetric or antisymmetric for the $\sigma_v$ 
containing the principal axis.  A subscript of $g$ or $u$ indicates a
representation that is symmetric or antisymmetric with respect to 
inversion.  A prime or double prime indicates a representation that 
is symmetric or antisymmetric with respect to the $\sigma_h$ 
perpendicular to the principal axis.

\begin{table}
\caption{}
\label{chap16app-tab6}
\begin{tabular}{cc}\\ \hline

C$_1$ & $e$\cr
$A$ & 1\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab7}
\begin{tabular}{cccc}\\ \hline

C$_2$ & $e$ & C$_2(z)$\cr

$A$ & 1 & 1 & $z$\cr
$B$ & 1 & $-1$ & $x,y$\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab8}
\begin{tabular}{ccccc}\\ \hline

C$_3$ & $e$ & C$_3$(z) & C$_3^2$\cr

$A$ & 1 & 1 & 1 & $z$\cr
$E^+$ & 1 & $\omega$ & $\omega^2$ & $x-iy$\cr
$E^-$ & 1 & $\omega^2$ & $\omega^4$ & $x+iy$\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab9}
\begin{tabular}{cccccc}\\ \hline

C$_4$ & $e$ & C$_4$(z) & C$_4^2$ & C$_4^3$\cr

A & 1 & 1 & 1 & 1 & $z$\cr
B & 1 & $-1$ & 1 & $-1$\cr
E$^+$ & 1 & $i$ & $-1$ & $-i$ & $x-iy$\cr
E$^-$ & 1 & $-i$ & $-$1 & $+i$ & $x+iy$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{$\omega = e^{i2\pi/6}$.}
\label{chap16app-tab10}
\begin{tabular}{cccccccc}\\ \hline

C$_6$ & $e$ & C$_6$(z) & C$_6^2$ & C$_6^3$ & C$_6^4$ & C$_6^5$\cr

A & 1 & 1 & 1 & 1 & 1 & 1 & $z$\cr
B & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
E$^+_1$ & 1 & $\omega$ &  $\omega^2$ & $\omega^3$ & $\omega^4$ & 
$\omega^5$ & $x-iy$\cr  
E$^-_1$ & 1 & $\omega^5$ & $\omega^4$ & $\omega^3$ & $\omega^2$ & 
$\omega^1$ & $x+iy$\cr    
E$^+_2$ & 1 & $\omega^2$ & $\omega^4$ & 1 & $\omega^2$ & $\omega^4$ & 
$(x-iy)^2$\cr     
E$^-_2$ & 1 & $\omega^4$ & $\omega^2$ & 1 & $\omega^4$ & $\omega^2$ & 
$(x+iy)^3$\cr    

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{For a planar molecule, $x$ is taken perpendicular to the plane.}
\label{chap16app-tab11}
\begin{tabular}{cccc}\\ \hline

C$_s$ & $e$ & $\sigma (yz)$\cr

$A^{\prime}$ & 1 & 1 & $z, y, x_g$\cr
$A^{\prime \prime}$ & 1 & $-1$ & $x, z_g, y_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab12}
\begin{tabular}{cccc}\\ \hline

C$_i$ & $e$ & $i$\cr

$A_g$ & 1 & 1 & $x_g , y_g , z_g$\cr
$A_u$ & 1 & $-1$ & $x, y, z$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{$z$ is taken as the C$_2$ axis.}
\label{chap16app-tab13}
\begin{tabular}{cccccc}\\ \hline

C$_{2h}$ & $e$ & C$_2$(z) & $\sigma_h$ & $i$\cr

A$_g$ & 1 & 1 & 1 & 1 & $z_g$\cr
A$_u$ & 1 & 1 & $-1$ & $-1$ & $z$\cr
B$_g$ & 1 & $-1$ & $-1$ & 1 & $x_g , y_g$\cr
B$_u$ & 1 & $-1$ &1 & $-1$ & $x , y$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{$\omega = e^{i2\pi/3}$.}
\label{chap16app-tab14}
\begin{tabular}{cccccccc}\\ \hline

C$_{3h}$ & $e$ & C$_3$ & C$_3^{-1}$ & $\sigma_h$ & S$_3$ & 
S$_3^{-1}$\cr

A$^{\prime}$ & 1 & 1 & 1 & 1 & 1 & 1 & z$_g$\cr
A$^{\prime \prime}$ & 1 & 1 & 1 & $-1$ & $-1$ & $-1$ & z\cr
E$^{\prime}_+$ & 1 & $\omega$ & $\omega^2$ & 1 & $\omega$ & 
$\omega^2$ & x$-$iy\cr
E$^{\prime}_-$ & 1 & $\omega^2$ & $\omega$ & 1 & $\omega^2$ & 
$\omega$ &  $x+iy$\cr
E$^{\prime \prime}_+$ & $\omega$ & $\omega^2$ & $-1$ & $-\omega$ & 
$-\omega^2$ & $x_g-iy_g$\cr
E$^{\prime \prime}_-$ & $\omega^2$ & $\omega$ & $-1$ & $-\omega^2$ & 
$-\omega$ & x$_g$+iy$_g$\cr

\hline
\end{tabular}
\end{table}


% this eliminates the ``too many unprocessed floats'' error:
\clearpage

\begin{table}
\caption{For planar molecules, x is taken perpendicular to the
molecular plane and z is taken as the C$_2$ axis.}
\label{chap16app-tab15}
\begin{tabular}{cccccc}\\ \hline

C$_{2v}$ & $e$ & 2C$_2$(z) & $\sigma_v$(xz) & $\sigma_v$(yz)\cr

A$_1$ & 1 & 1 & 1 & 1 & z\cr
A$_2$ & 1 & 1 & $-1$ & $-1$ & z$_g$,xy\cr
B$_1$ & 1 & $-1$ & 1 & $-1$ & x,y$_g$\cr
B$_2$ & 1 & $-1$ & $-1$ & 1 & y,x$_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{For molecules with a single C$_n$ axis, $n \geq 3$, the z
  axis is the principal axis.} 
\label{chap16app-tab16}
\begin{tabular}{ccccc}\\ \hline

C$_{3v}$ & $e$ & 2C$_3$(z) & $3 \sigma_v$\cr

A$_1$ & 1 & 1 & 1 & z\cr
A$_2$ & 1 & 1 & $-1$ & z$_g$\cr
E & 1 & $-1$ & 0 & x, y; x$_g$, y$_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab17}
\begin{tabular}{ccccccc}\\ \hline

C$_{4v}$ & $e$ & 2C$_4$(z) & C$_4^2$ & $2 \sigma_v$(xz,yz) & $2 
\sigma_d$\cr

A$_1$ & 1 & 1 & 1 & 1 & 1 & z\cr
A$_2$ & 1 & 1 & 1 & $-1$ & $-1$ & z$_g$\cr
B$_1$ & 1 & $-1$ & 1 & 1 & $-1$\cr
B$_2$ & 1 & $-1$ & 1 & $-1$ & 1\cr
E & 2 & 0 & $-2$ & 0 & 0 & x, y; x$_g$, y$_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab18}
\begin{tabular}{cccccccc}\\ \hline

C$_{6v}$ & $e$ & 2C$_6$(z) & 2C$_6^2$ & C$_6^3$ & $3 \sigma_v$ & $3 
\sigma_d$\cr

A$_1$ & 1 & 1 & 1 & 1 & 1 & 1 & z\cr
A$_2$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & z$_g$\cr
B$_1$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
B$_2$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1\cr
E$_1$ & 2 & 1 & $-1$ & $-2$ & 0 & 0 & x,y; x$_g$, y$_g$\cr
E$_2$ & 2 & $-1$ & $-1$ & 2 & 0 & 0\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab19}
\begin{tabular}{ccccccc}\\ \hline

C$_{\infty v}$ & $e$ & 2C$_{\phi}$ & 2C$^2_{\phi}$ & $\cdots$ & 
$\infty \sigma_v$\cr

$\Sigma^+$ & 1 & 1 & 1 & $\cdots$ & 1 & z\cr
$\Sigma^-$ & 1 & 1 & 1 & $\cdots$ & $-1$ & z$_g$\cr
$\Pi$ & 2 & $2 \cos \phi$ & $2 \cos 2 \phi$ & $\cdots$ & 0 & x, y; 
x$_g$, y$_g$\cr
$\Delta$ & 2 & $2 \cos 2 \phi$ & $2 \cos 4 \phi$ & $\cdots$ & 0 & x, y; 
x$^2-$y$^2$\cr
$\Phi$ & 2 & $2 \cos 3 \phi$ & $2 \cos 6 \phi$ & $\cdots$ & 0\cr
$\Gamma$ & 2 & $2 \cos 4 \phi$ & $2 \cos 8 \phi$ & $\cdots$ & 0\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{B$_1$, B$_2$, and B$_3$ go with $z$, $y$, 
and $x$, respectively, backwards from what might be expected.}
\label{chap16app-tab20}
\begin{tabular}{cccccc}\\ \hline

D$_2$ & $e$ & C$_2$(z) & C$_2$(y) & C$_2$(x)\cr

A & 1 & 1 & 1 & 1\cr
B$_1$ & 1 & 1 & $-1$ & $-1$ & $z, z_g$\cr
B$_2$ & 1 & $-1$ & 1 & $-1$ & $y, y_g$\cr
B$_3$ & 1 & $-1$ & $-1$ & 1 & $x, x_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab21}
\begin{tabular}{ccccc}\\ \hline

D$_3$ & $e$ & 2C$_3$ & 3C$_2$\cr

A$_1$ & 1 & 1 & 1\cr
A$_2$ & 1 & 1 & $-1$ & z; z$_g$\cr
E & 2 & $-1$ & 0 & x, y; x$_g$, y$_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab22}
\begin{tabular}{ccccccc}\\ \hline

D$_4$ & $e$ & 2C$_4$(z) & C$_4^2$ & 2C$_2$(x,y) & 2C$^{\prime}_2$\cr

A$_1$ & 1 & 1 & 1 & 1 & 1\cr
A$_2$ & 1 & 1 & 1 & $-1$ & $-1$ & z, z$_g$\cr
B$_1$ & 1 & $-1$ & 1 & 1 & $-1$\cr
B$_2$ & 1 & $-1$ & 1 & $-1$ & 1\cr
E & 2 & 0 & $-2$ & 0 & 0 & x, y; x$_g$, y$_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab23}
\begin{tabular}{cccccccc}\\ \hline

D$_6$ & $e$ & 2C$_6$(z) & C$_6^2$ & C$_6^3$ & 3C$_2$ & 2C$^{\prime}_2$\cr

A$_1$ & 1 & 1 & 1 & 1 & 1 & 1\cr
A$_2$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & z, z$_g$\cr
B$_1$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
B$_2$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1\cr
E$_1$ & 2 & 1 & $-1$ & $-2$ & 0 & 0 & x,y; x$_g$, y$_g$\cr
E$_2$ & 2 & $-1$ & $-1$ & 2 & 0 & 0 & xy, $x^2-y^2$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab24}
\begin{tabular}{cccccccccc}\\ \hline

D$_{2h}$ & $e$ & 2C$_2$(z) & C$_2$(y) & C$_2$(x) & $i$ & 
$\sigma_{xy}$ & $\sigma_{xz}$ & $\sigma_{yz}$ & ${\bf D}_{2h} = {\bf 
D}_2 \times {\bf C}_i$\cr

A$_g$ & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\cr
B$_{1g}$ & 1 & 1 & $-1$ & $-1$ & 1 & 1 & $-1$ & $-1$ & $z_g$\cr
B$_{2g}$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$ & $y_g$\cr
B$_{3g}$ & 1 & $-1$ & $-1$ & 1 & 1 & $-1$ & $-1$ & 1 & $x_g$\cr
A$_u$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & $-1$ & $-1$\cr
B$_{1u}$ & 1 & 1 & $-1$ & $-1$ & $-1$ & $-1$ & 1 & 1 & $z$\cr
B$_{2u}$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1 & $-1$ & 1 & $y$\cr
B$_{3u}$ & 1 & $-1$ & $-1$ & 1 & $-1$ & 1 & 1 & $-1$ & x\cr
\hline
\end{tabular}\\
For planar molecules, the $x$ axis is perpendicular to the plane and
$z$ is taken to cut the most atoms.  If this does ot distinguish
between $y$ and $z$, then $z$ is taken to cut the most bonds.
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab25}
\begin{tabular}{cccccccc}\\ \hline
{\bf D}$_{3h}$ & $e$ & $2C_3(z)$ & $3C_2$ & $\sigma_h(xy)$ & 
$2S_3(z)$ & $3\sigma_v$\cr

$A^{\prime}_1$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A^{\prime}_2$ & 1 & 1 & $-1$ & 1 & 1 & $-1$ & $z_g$\cr
$A^{\prime \prime}_1$ & 1 & 1 & 1 & $-1$ & $-1$ & $-1$\cr
$A^{\prime \prime}_2$ & 1 & 1 & $-1$ & $-1$ & $-1$ & 1 & $z$\cr
$E^{\prime}$ & 2 & $-1$ & 0 & 2 & $-1$ & 0 & $x,y$\cr
$E^{\prime \prime}$ & 2 & $-1$ & 0 & $-2$ & 1 & 0 & $x_g, y_g$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab26a}
\begin{tabular}{ccccccc}\\ \hline
{\bf D}$_{4h}$ & $e$ &  $2C_4(z)$ & $C^2_4$ & $2C_2(x,y)$ & 
$2C^{\prime}_2$ & {\bf D}$_{4h} = {\bf D}_4 \times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & 1 & $-1$ & $-1$ & $z_g$\cr
$B_{1g}$ & 1 & $-1$ & 1 & 1 & $-1$\cr
$B_{2g}$ & 1 & $-1$ & 1 & $-1$ & 1\cr
$E_g$ & 2 & 0 & $-2$ & 0 & 0 & $x_g , y_g$\cr
$A_{1u}$ & 1 & 1 & 1 & 1 & 1\cr
$A_{2u}$ & 1 & 1 & 1 & $-1$ & $-1$ & $z$\cr
$B_{1u}$ & 1 & $-1$ & 1 & 1 & $-1$\cr
$B_{2u}$ & 1 & $-1$ & 1 & $-1$ & 1\cr
$E_u$ & 2 & 0 & $-2$ & 0 & 0 & $x,y$\cr
\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab26b}
\begin{tabular}{ccccccc}\\ \hline

{\bf D}$_{4h}$ & $i$ &  $2S_4(z)$ & $\sigma_h (x,y)$ & 
$2\sigma_v(xz,yz)$ & $2\sigma^{\prime}_v$ & 
{\bf D}$_{4h} = {\bf D}_4 \times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & 1 & $-1$ & $-1$ & $z_g$\cr
$B_{1g}$ & 1 & $-1$ & 1 & 1 & $-1$\cr
$B_{2g}$ & 1 & $-1$ & 1 & $-1$ & 1\cr
$E_g$ & 2 & 0 & $-2$ & 0 & 0 & $x_g , y_g$\cr
$A_{1u}$ & $-1$ & $-1$ & $-1$ & $-1$ & $-1$\cr
$A_{2u}$ & $-1$ & $-1$ & $-1$ & 1 & 1 & $z$\cr
$B_{1u}$ & $-1$ & 1 & $-1$ & $-1$ & 1\cr
$B_{2u}$ & $-1$ & 1 & $-1$ & 1 & $-1$\cr
$E_u$ & $-2$ & 0 & $-2$ & 0 & 0 & $x,y$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab27a}
\begin{tabular}{cccccccc}\\ \hline
{\bf D}$_{6h}$ & $e$ &  $2C_6(z)$ & $2C_6^2$ & $C^3_6$ & $3C_{2x}$ & 
$3C^{\prime}_{2y}$ & {\bf D}$_{6h} = {\bf D}_6 \times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & $z_g$\cr
$B_{1g}$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
$B_{2g}$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1\cr
$E_{1g}$ & 2 & 1 & $-1$ & $-2$ & 0 & 0 & $x_g , y_g ; xz, yz$\cr
$E_{2g}$ & 2 & $-1$ & $-1$ & 2 & 0 & 0 & $xy, x^2-y^2$\cr
$A_{1u}$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A_{2u}$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & $z$\cr
$B_{1u}$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
$B_{2u}$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1\cr
$E_{1u}$ & 2 & 1 & $-1$ & $-2$ & 0 & 0 & $x,y$\cr
$E_{2u}$ & 2 & $-1$ & $-1$ & 2 & 0 & 0\cr 

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab27b}
\begin{tabular}{cccccccc}\\ \hline

{\bf D}$_{6h}$ & $i$ &  $2S_3(z)$ & $2S_6$ & $\sigma_h(x,y)$ & 
$3\sigma_v(yz)$ & $3 \sigma^{\prime}_v(xz)$ & 
{\bf D}$_{6h} = {\bf D}_6 \times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & 1 & 1 & $-1$ & $-1$ & $z_g$\cr
$B_{1g}$ & 1 & $-1$ & 1 & $-1$ & 1 & $-1$\cr
$B_{2g}$ & 1 & $-1$ & 1 & $-1$ & $-1$ & 1\cr
$E_{1g}$ & 2 & 1 & $-1$ & $-2$ & 0 & 0 & $x_g , y_g ; xz, yz$\cr
$E_{2g}$ & 2 & $-1$ & $-1$ & 2 & 0 & 0 & $xy, x^2-y^2$\cr
$A_{1u}$ & $-1$ & $-1$ & $-1$ & $-1$ & $-1$ & $-1$\cr
$A_{2u}$ & $-1$ & $-1$ & $-1$ & $-1$ & 1 & 1 & $z$\cr
$B_{1u}$ & $-1$ & 1 & $-1$ & 1 & $-1$ & 1\cr
$B_{2u}$ & $-1$ & 1 & $-1$ & 1 & 1 & $-1$\cr
$E_{1u}$ & $-2$ & $-1$ & 1 & 2 & 0 & 0 & $x,y$\cr
$E_{2u}$ & $-2$ & 1 & 1 & $-2$ & 0 & 0\cr 

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab28}
\begin{tabular}{cccccccccc}\\ \hline
{\bf D}$_{\infty h}$ & $e$ & $2C_{\phi}$ & $\cdots$ & $\infty C_2$ & 
$i$ & $2S_{\phi}$ & $\cdots$ & $\infty \sigma_v$ & ${\bf D}_{\infty 
h} = {\bf C}_{\infty v} \times {\bf C}_i$\cr

$\Sigma^+_g$ & 1 & 1 & & 1 & 1 & 1 & & 1\cr
$\Sigma^+_u$ & 1 & 1 & & $-1$ & $-1$ & $-1$ & & 1 & $z$\cr
$\Sigma^-_g$ & 1 & 1 & & $-1$ & 1 & 1 & & $-1$ & $z_g$\cr
$\Sigma^-_u$ & 1 & 1 & & 1 & $-1$ & $-1$ & & $-1$\cr
$\Pi_g$ & 2 & $2 \cos \phi$ & & 0 & 2 & $-1 \cos \phi$ & & 0 & $x_g , 
y_g$\cr
$\Pi_u$ & 2 & $2 \cos \phi$ & & 0 & $-2$ & $2 \cos \phi$ & & 0 & 
$x,y$\cr
$\Delta_g$ & 2 & $2 \cos 2 \phi$ & & 0 & 2 & $2 \cos 2 \phi$ & & 0 & 
$xy, x^2-y^2$\cr
$\Delta_u$ & 2 & $2 \cos 2 \phi$ & & 0 & $-2$ & $-2 \cos 2 \phi$ & & 
?0\cr
$\Phi_g$ & 2 & $2 \cos 3 \phi$ & & 0 & 2 & $-2 \cos 3 \phi$ & & 0\cr
$\Phi_u$ & 2 & $2 \cos 3 \phi$ & & 0 & $-2$ & $2 \cos 3 \phi$ & & 0\cr
$\Gamma_g$ & 2 & $2 \cos 4 \phi$ & & 0 & $-2$ & $-2 \cos 4 \phi$ & & 
?0\cr
$\Gamma_u$ & 2 & $2 \cos 4 \phi$ & & 0 & $-2$ & $-2 \cos 4 \phi$ & & 
?0\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab29}
\begin{tabular}{ccccccc}\\ \hline
{\bf D}$_{2d}$ & $e$ & $2S_4(z)$ & $S_4^2 = C^{\prime \prime}_2$ & 
$2C_2(x,y)$ & $2 \sigma_d$\cr

$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$ & $z_g$\cr
$B_1$ & 1 & $-1$ & 1 & 1 & $-1$\cr
$B_2$ & 1 & $-1$ & 1 & $-1$ & 1 & $z,xy$\cr
$E$ & 2 & 0 & $-2$ & 0 & 0 & $x,y; x_g, y_g$\cr

\hline
\end{tabular}
\end{table}

\clearpage

\begin{table}
\caption{}
\label{chap16app-tab30}
\begin{tabular}{cccccccc}\\ \hline

${\bf D}_{3d}$ & $e$ & $2C_3$ & $3C_2$ & $i$ & $2S_6$ & 
$3\sigma_d$ & ${\bf D}_{3d} = {\bf D}_3 \times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & $-1$ & 1 & 1 & $-1$ & $z_g$\cr
$E_g$ & 2 & $-1$ & 0 & 2 & $-1$ & 0 & $x_g ,y_g$\cr
$A_{1u}$ & 1 & 1 & 1 & $-1$ & $-1$ & $-1$\cr  
$A_{2u}$ & 1 & 1 & $-1$ & $-1$ & $-1$ & 1 & $z$\cr
$E_u$ & 2 & $-1$ & 0 & $-2$ & 1 & 0 & $x,y$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab31}
\begin{tabular}{ccccc}\\ \hline
{\bf T} & $e$ & $4C_3$ & $4C_3^{-1}$ & $3C_2$\cr

$A$ & 1 & 1 & 1 & 1\cr
$E^+$ & 1 & $\omega$ & $\omega^2$ & 1\cr
$E^-$ & 1 & $\omega^2$ & $\omega$ & 1\cr
$T$ & 3 & 0 & 0 & $-1$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab32}
\begin{tabular}{ccccccc}\\ \hline
${\bf T}_d$ & $e$ & $8C_3$ & $3C_{2z}$ & $6S_{4z}$ & $6 \sigma_d$\cr

$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$E$ & 2 & $-1$ & 2 & 0 & 0 & $x^2-y^2,2z^2-x^2-y^2$\cr
$T_1(F_1)$ & 3 & 0 & $-1$ & 1 & $-1$ & $x_g,y_g,z_g$\cr
$T_2(F_2)$ & 3 & 0 & $-1$ & $-1$ & 1 & $x,y,z;xy,yz,xz$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab33}
\begin{tabular}{ccccccc}\\ \hline
{\bf O} & $e$ & $8C_3$ & $3C^{\prime \prime}_{2z}$ & $6C_4$ & 
$6C_2$\cr

$A_1$ & 1 & 1 & 1 & 1 & 1\cr
$A_2$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$E$ & 2 & $-1$ & 2 & 0 & 0 & $x^2-y^2,2z^2-x^2-y^2$\cr
$T_1(F_1)$ & 3 & 0 & $-1$ & 1 & $-1$ & $x,y,z;x_g,y_g,z_g$\cr
$T_2(F_2)$ & 3 & 0 & $-1$ & $-1$ & 1 & $xy,yz,xz$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab34a}
\begin{tabular}{ccccccc}\\ \hline
{\bf O}$_h$ & $e$ & $8C_3$ & $3C_{2z}^{\prime\prime}$ & $6C_{4z}$ & 
$6C_2$ & ${\bf O}_h={\bf O}\times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$E_g$ & 2 & $-1$ & 2 & 0 & 0 & $x^2-y^2,2z^2-x^2-y^2$\cr
$T_{1g}$ & 3 & 0 & $-1$ & 1 & $-1$ & $x_g,y_g,z_g$\cr
$T_{2g}$ & 3 & 0 & $-1$ & $-1$ & 1 & $xy,yz,xz$\cr
$A_{1u}$ & 1 & 1 & 1 & 1 & 1\cr
$A_{2u}$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$E_g$ & 2 & $-1$ & 2 & 0 & 0\cr
$T_{1u}$ & 3 & 0 & $-1$ & 1 & $-1$ & $x,y,z$\cr
$T_{2u}$ & 3 & 0 & $-1$ & $-1$ & 1\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{}
\label{chap16app-tab34b}
\begin{tabular}{ccccccc}\\ \hline
{\bf O}$_h$ & $i$ & $8S_6$ & $3 \sigma_{xy}$ & $6S_{4z}$ & 
$6 \sigma^{\prime}$ & ${\bf O}_h={\bf O}\times {\bf C}_i$\cr

$A_{1g}$ & 1 & 1 & 1 & 1 & 1\cr
$A_{2g}$ & 1 & 1 & 1 & $-1$ & $-1$\cr
$E_g$ & 2 & $-1$ & 2 & 0 & 0 & $x^2-y^2,2z^2-x^2-y^2$\cr
$T_{1g}$ & 3 & 0 & $-1$ & 1 & $-1$ & $x_g,y_g,z_g$\cr
$T_{2g}$ & 3 & 0 & $-1$ & $-1$ & 1 & $xy,yz,xz$\cr
$A_{1u}$ & $-1$ & $-1$ & $-1$ & $-1$ & $-1$\cr
$A_{2u}$ & $-1$ & $-1$ &1 & 1 & 1\cr
$E_g$ & $-2$ & 1 & $-2$ & 0 & 0\cr
$T_{1u}$ & $-3$ & 0 & 1 & $-1$ & 1 & $x,y,z$\cr
$T_{2u}$ & $-3$ & 0 & 1 & 1 & $-1$\cr

\hline
\end{tabular}
\end{table}

\begin{table}
\caption{These results are derived in Section 16.5.}
\label{chap16app-tab35}
\begin{tabular}{cccccccccccc}\\ \hline
O(3) & L & $e$ & $C_2$ & $C_3$ & $C_4$ & $C_6$ & $i$ & $\sigma$ & 
$S_3$ & $S_4$ & $S_6$\cr

$S_g$ & 0 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1 & 1\cr
$P_u$ & 1 & 3 & $-1$ & 0 & 1 & 2 & $-3$ & 1 & $-2$ & $-1$ & 0\cr
$D_g$ & 2 & 5 & 1 & $-1$ & $-1$ & 1 & ?5 & 1 & 1 & $-1$ & $-1$\cr
$F_u$ & 3 & 7 & $-1$ & 1 & $-1$ & $-1$ & $-7$ & 1 & 1 & 1 & $-1$\cr
$G_g$ & 4 & 9 & 1 & 0 & 1 & $-2$ & ?9 & 1 & $-2$ & 1 & 0\cr
$H_u$ & 5 & 11 & $-1$ & $-1$ & 1 & $-1$ & $-11$ & 1 & 1 & $-1$ & 1\cr
$I_g$ & 6 & 13 & 1 & 1 & $-1$ & 1 & 13 & 1 & 1 & $-1$ & 1\cr
$K_u$ & 7 & 15 & $-1$ & 0 & $-1$ & 2 & $-15$ & 1 & $-2$ & 1 & 0\cr
$L_g$ & 8 & 17 & 1 & $-1$ & 1 & 1 & 17 & 1 & 1 & 1 & $-1$\cr
$M_u$ & 9 & 19 & $-1$ & 1 & 1 & $-1$ & $-19$ & 1 & 1 & $-1$ & $-1$\cr
$N_g$ & 10 & 21 & 1 & 0 & $-1$ & $-2$ & 21 & 1 & $-2$ & $-1$ & 0\cr
$O_u$ & 11 & 23 & $-1$ & $-1$ & $-1$ & $-1$ & $-23$ & 1 & 1 & 1 & 1\cr
$Q_g$ & 12 & 25 & 1 & 1 & 1 & 1 & 25 & 1 & 1 & 1 & 1\cr
\hline
\end{tabular}
\end{table}
